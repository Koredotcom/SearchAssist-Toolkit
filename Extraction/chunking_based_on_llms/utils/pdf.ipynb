{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "import fitz\n",
    "import pandas as pd\n",
    "import os\n",
    "from langchain.docstore.document import Document\n",
    "from llm_client import LLMClient\n",
    "from PIL import Image\n",
    "from io import BytesIO\n",
    "import base64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_b64_image(image_path):\n",
    "    image = Image.open(image_path).convert(\"RGB\")\n",
    "    buffered = BytesIO()\n",
    "    image.save(buffered, format=\"JPEG\", quality=20)  # quality=20 is a workaround (WAR)\n",
    "    b64_string = base64.b64encode(buffered.getvalue()).decode(\"utf-8\")\n",
    "    return b64_string\n",
    "\n",
    "def is_graph(image_path):\n",
    "    # Placeholder function for graph detection logic\n",
    "    # Implement graph detection algorithm here\n",
    "    neva = LLMClient(\"neva_22b\")\n",
    "    b64_string = get_b64_image(image_path)\n",
    "    res = neva.multimodal_invoke(b64_string, creativity = 0, quality = 9, complexity = 0, verbosity = 9).content\n",
    "    print(res)\n",
    "    if \"graph\" in res or \"plot\" in res or \"chart\" in res:\n",
    "        return True\n",
    "    else:\n",
    "        return False\n",
    "\n",
    "def process_graph(image_path):\n",
    "    # Placeholder function for graph processing logic\n",
    "    # Implement graph processing algorithm here\n",
    "    # Call DePlot through the API\n",
    "    deplot = LLMClient(\"deplot\")\n",
    "    b64_string = get_b64_image(image_path)\n",
    "    res = deplot.multimodal_invoke(b64_string)\n",
    "    deplot_description = res.content\n",
    "    mixtral = LLMClient(model_name=\"mixtral_8x7b\")\n",
    "    response = mixtral.chat_with_prompt(system_prompt=\"Your responsibility is to explain charts. You are an expert in describing the responses of linearized tables into plain English text for LLMs to use.\", \n",
    "                             prompt=\"Explain the following linearized table. \" + deplot_description)\n",
    "    full_response = \"\"\n",
    "    for chunk in response:\n",
    "        full_response += chunk\n",
    "    print(full_response)\n",
    "    return full_response\n",
    "\n",
    "def extract_text_around_item(text_blocks, bbox, page_height, threshold_percentage=0.1):\n",
    "    before_text, after_text = \"\", \"\"\n",
    "    vertical_threshold_distance = page_height * threshold_percentage\n",
    "    horizontal_threshold_distance = bbox.width * threshold_percentage  # Assuming similar threshold for horizontal distance\n",
    "\n",
    "    for block in text_blocks:\n",
    "        block_bbox = fitz.Rect(block[:4])\n",
    "        vertical_distance = min(abs(block_bbox.y1 - bbox.y0), abs(block_bbox.y0 - bbox.y1))\n",
    "        horizontal_overlap = max(0, min(block_bbox.x1, bbox.x1) - max(block_bbox.x0, bbox.x0))\n",
    "\n",
    "        # Check if within vertical threshold distance and has horizontal overlap or closeness\n",
    "        if vertical_distance <= vertical_threshold_distance and horizontal_overlap >= -horizontal_threshold_distance:\n",
    "            if block_bbox.y1 < bbox.y0 and not before_text:\n",
    "                before_text = block[4]\n",
    "            elif block_bbox.y0 > bbox.y1 and not after_text:\n",
    "                after_text = block[4]\n",
    "                break\n",
    "\n",
    "    return before_text, after_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_text_blocks(text_blocks):\n",
    "    char_count_threshold = 500  # Threshold for the number of characters in a group\n",
    "    current_group = []\n",
    "    grouped_blocks = []\n",
    "    current_char_count = 0\n",
    "\n",
    "    for block in text_blocks:\n",
    "        if block[-1] == 0:  # Check if the block is of text type\n",
    "            block_text = block[4]\n",
    "            block_char_count = len(block_text)\n",
    "\n",
    "            if current_char_count + block_char_count <= char_count_threshold:\n",
    "                current_group.append(block)\n",
    "                current_char_count += block_char_count\n",
    "            else:\n",
    "                if current_group:\n",
    "                    grouped_content = \"\\n\".join([b[4] for b in current_group])\n",
    "                    grouped_blocks.append((current_group[0], grouped_content))\n",
    "                current_group = [block]\n",
    "                current_char_count = block_char_count\n",
    "\n",
    "    # Append the last group\n",
    "    if current_group:\n",
    "        grouped_content = \"\\n\".join([b[4] for b in current_group])\n",
    "        grouped_blocks.append((current_group[0], grouped_content))\n",
    "\n",
    "    return grouped_blocks\n",
    "\n",
    "def parse_all_tables(filename, page, pagenum, text_blocks, ongoing_tables):\n",
    "    table_docs = []\n",
    "    table_bboxes = []\n",
    "    ctr = 1\n",
    "    try:\n",
    "        tables = page.find_tables(horizontal_strategy = \"lines_strict\", vertical_strategy = \"lines_strict\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error during table extraction: {e}\")\n",
    "        \n",
    "        return table_docs, table_bboxes, ongoing_tables\n",
    "    if tables:\n",
    "        for tab in tables:\n",
    "            if tab.header.external:\n",
    "                # Check if this table is a continuation of a table from a previous page\n",
    "                previous_table = ongoing_tables.get(pagenum - 1, None)\n",
    "                if previous_table:\n",
    "                    # Merge the current table with the previous part\n",
    "                    combined_df = pd.concat([previous_table['dataframe'], tab.to_pandas()])\n",
    "                    ongoing_tables[pagenum] = {\"dataframe\": combined_df, \"bbox\": bbox}\n",
    "                continue\n",
    "            if not tab.header.external:\n",
    "                pandas_df = tab.to_pandas()\n",
    "                tablerefdir = os.path.join(os.getcwd(), \"vectorstore/table_references\")\n",
    "                if not os.path.exists(tablerefdir):\n",
    "                    os.makedirs(tablerefdir)\n",
    "                df_xlsx_path = os.path.join(tablerefdir, f\"table{ctr}-page{pagenum}.xlsx\")\n",
    "                pandas_df.to_excel(df_xlsx_path)\n",
    "                bbox = fitz.Rect(tab.bbox)\n",
    "                table_bboxes.append(bbox)\n",
    "\n",
    "                # Find text around the table\n",
    "                before_text, after_text = extract_text_around_item(text_blocks, bbox, page.rect.height)\n",
    "\n",
    "                table_img = page.get_pixmap(clip=bbox)\n",
    "                table_img_path = os.path.join(tablerefdir, f\"table{ctr}-page{pagenum}.jpg\")\n",
    "                \n",
    "                # table_img.save(table_img_path)\n",
    "                # img = Image.open(table_img_path)\n",
    "                # img.show()\n",
    "                # Convert the Pixmap to a PIL Image\n",
    "                pil_image = Image.frombytes(\"RGB\", [table_img.width, table_img.height], table_img.samples)\n",
    "\n",
    "                # Save the image with higher DPI for better quality\n",
    "                dpi_factor = 100  # Adjust this factor as needed to improve quality\n",
    "                pil_image.save(table_img_path, dpi=(300 * dpi_factor, 300 * dpi_factor))\n",
    "                # Open and display the image\n",
    "                img = Image.open(table_img_path)\n",
    "                img.show()\n",
    "                description = process_graph(table_img_path)\n",
    "                ctr += 1\n",
    "\n",
    "                caption = before_text.replace(\"\\n\", \" \") + description + after_text.replace(\"\\n\", \" \")\n",
    "                if before_text == \"\" and after_text == \"\":\n",
    "                    caption = \" \".join(tab.header.names)\n",
    "\n",
    "\n",
    "                table_metadata = {\n",
    "                    \"source\": f\"{filename[:-4]}-page{pagenum}-table{ctr}\",\n",
    "                    \"dataframe\": df_xlsx_path,\n",
    "                    \"image\": table_img_path,\n",
    "                    \"caption\": caption,\n",
    "                    \"type\": \"table\",\n",
    "                    \"page_num\": pagenum\n",
    "                }\n",
    "                all_cols = \", \".join(list(pandas_df.columns.values))\n",
    "                \n",
    "                doc = Document(page_content=\"This is a table with the caption: \" + caption + f\"\\nThe columns are {all_cols}\", metadata=table_metadata)\n",
    "                table_docs.append(doc)\n",
    "                \n",
    "                print(table_docs)\n",
    "    return table_docs, table_bboxes, ongoing_tables\n",
    "\n",
    "def parse_all_images(filename, page, pagenum, text_blocks):\n",
    "    image_docs = []\n",
    "    image_info_list = page.get_image_info(xrefs=True)\n",
    "    page_rect = page.rect  # Get the dimensions of the page\n",
    "\n",
    "    for image_info in image_info_list:\n",
    "        xref = image_info['xref']\n",
    "        if xref == 0:\n",
    "            continue  # Skip inline images or undetectable images\n",
    "\n",
    "        img_bbox = fitz.Rect(image_info['bbox'])\n",
    "        # Check if the image size is at least 5% of the page size in any dimension\n",
    "        if img_bbox.width < page_rect.width / 20 or img_bbox.height < page_rect.height / 20:\n",
    "            continue  # Skip very small images\n",
    "\n",
    "        # Extract and save the image\n",
    "        extracted_image = page.parent.extract_image(xref)\n",
    "        image_data = extracted_image[\"image\"]\n",
    "        imgrefpath = os.path.join(os.getcwd(), \"vectorstore/image_references\")\n",
    "        if not os.path.exists(imgrefpath):\n",
    "            os.makedirs(imgrefpath)\n",
    "        image_path = os.path.join(imgrefpath, f\"image{xref}-page{pagenum}.png\")\n",
    "        with open(image_path, \"wb\") as img_file:\n",
    "            img_file.write(image_data)\n",
    "\n",
    "        # Find text around the image\n",
    "        before_text, after_text = extract_text_around_item(text_blocks, img_bbox, page.rect.height)\n",
    "        # skip images without a caption, they are likely just some logo or graphics\n",
    "        if before_text == \"\" and after_text == \"\":\n",
    "            continue\n",
    "\n",
    "        # Process the image if it's a graph\n",
    "        image_description = \" \"\n",
    "        if is_graph(image_path):\n",
    "            image_description = process_graph(image_path)\n",
    "\n",
    "        # Combine the texts to form a caption\n",
    "        caption = before_text.replace(\"\\n\", \" \") + image_description + after_text.replace(\"\\n\", \" \")\n",
    "\n",
    "        image_metadata = {\n",
    "            \"source\": f\"{filename[:-4]}-page{pagenum}-image{xref}\",\n",
    "            \"image\": image_path,\n",
    "            \"caption\": caption,\n",
    "            \"type\": \"image\",\n",
    "            \"page_num\": pagenum\n",
    "        }\n",
    "        image_docs.append(Document(page_content=\"This is an image with the caption: \" + caption, metadata=image_metadata))\n",
    "    return image_docs\n",
    "\n",
    "def get_pdf_documents(filepath):\n",
    "    all_pdf_documents = []\n",
    "    ongoing_tables = {}\n",
    "    try:\n",
    "        f = fitz.open(filepath)\n",
    "    except Exception as e:\n",
    "        print(f\"Error opening or processing the PDF file: {e}\")\n",
    "        return []\n",
    "\n",
    "    for i in range(len(f)):\n",
    "        page = f[i]\n",
    "        page_docs = []\n",
    "\n",
    "        # Process text blocks\n",
    "        initial_text_blocks = page.get_text(\"blocks\", sort=True)\n",
    "\n",
    "        # Define thresholds for header and footer (10% of the page height)\n",
    "        page_height = page.rect.height\n",
    "        header_threshold = page_height * 0.1\n",
    "        footer_threshold = page_height * 0.9\n",
    "\n",
    "        # Filter out text blocks that are likely headers or footers\n",
    "        text_blocks = [block for block in initial_text_blocks if block[-1] == 0 and not (block[1] < header_threshold or block[3] > footer_threshold)]\n",
    "\n",
    "        # Group text blocks by character count\n",
    "        grouped_text_blocks = process_text_blocks(text_blocks)\n",
    "\n",
    "        # Extract tables and their bounding boxes\n",
    "        table_docs, table_bboxes, ongoing_tables = parse_all_tables(filepath, page, i, text_blocks, ongoing_tables)\n",
    "        page_docs.extend(table_docs)\n",
    "\n",
    "        # Extract and process images\n",
    "        image_docs = parse_all_images(filepath, page, i, text_blocks)\n",
    "        page_docs.extend(image_docs)\n",
    "\n",
    "        # Process grouped text blocks\n",
    "        text_block_ctr = 0\n",
    "        for heading_block, content in grouped_text_blocks:\n",
    "            text_block_ctr +=1 \n",
    "            heading_bbox = fitz.Rect(heading_block[:4])\n",
    "            # Check if the heading or its content overlaps with table or image bounding boxes\n",
    "            if not any(heading_bbox.intersects(table_bbox) for table_bbox in table_bboxes):\n",
    "                bbox = {\"x1\": heading_block[0], \"y1\": heading_block[1], \"x2\": heading_block[2], \"x3\": heading_block[3]}\n",
    "                text_doc = Document(page_content=f\"{heading_block[4]}\\n{content}\", metadata={**bbox, \"type\": \"text\", \"page_num\": i, \"source\": f\"{filepath[:-4]}-page{i}-block{text_block_ctr}\"})\n",
    "                page_docs.append(text_doc)\n",
    "\n",
    "        all_pdf_documents.append(page_docs)\n",
    "\n",
    "    f.close()\n",
    "    return all_pdf_documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "from difflib import SequenceMatcher\n",
    "\n",
    "def remove_duplicate_paragraphs(text):\n",
    "    # Split the text into paragraphs\n",
    "    paragraphs = text.split(\"\\n\\n\")\n",
    "    \n",
    "    # Remove duplicates while preserving the order\n",
    "    unique_paragraphs = []\n",
    "    seen_paragraphs = set()\n",
    "    for i in range(len(paragraphs) - 1):\n",
    "        # Compare current paragraph with the next one\n",
    "        similarity = SequenceMatcher(None, paragraphs[i], paragraphs[i+1]).ratio()\n",
    "        \n",
    "        # If similarity is less than 0.9 (adjust as needed), consider them as different\n",
    "        if similarity < 0.9:\n",
    "            if paragraphs[i] not in seen_paragraphs:\n",
    "                unique_paragraphs.append(paragraphs[i])\n",
    "                seen_paragraphs.add(paragraphs[i])\n",
    "    \n",
    "    # Add the last paragraph\n",
    "    if paragraphs[-1] not in seen_paragraphs:\n",
    "        unique_paragraphs.append(paragraphs[-1])\n",
    "    \n",
    "    # Join the unique paragraphs back into a single string\n",
    "    result_text = \"\\n\\n\".join(unique_paragraphs)\n",
    "    \n",
    "    return result_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "pdf_filepath = r\"\"\n",
    "\n",
    "# Call the function to extract documents from the PDF\n",
    "pdf_documents_dl = get_pdf_documents(pdf_filepath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize an empty string to store the concatenated documents\n",
    "result_string = \"\"\n",
    "\n",
    "# Iterate through the extracted documents\n",
    "for page_documents in pdf_documents_dl:\n",
    "    for document in page_documents:\n",
    "        # Concatenate the page content to the result string\n",
    "        result_string += document.page_content + \"\\n\\n\"\n",
    "\n",
    "# Print the concatenated string\n",
    "print(result_string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpse = remove_duplicate_paragraphs(result_string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "def df_to_table_string(df):\n",
    "    # Get the maximum width of each column\n",
    "    col_widths = [max(df[col].astype(str).map(len).max(), len(col)) for col in df.columns]\n",
    "    \n",
    "    # Format the column headers\n",
    "    header = \" | \".join([f\"{col:<{col_widths[i]}}\" for i, col in enumerate(df.columns)])\n",
    "    \n",
    "    # Create a separator line\n",
    "    separator = \"-+-\".join(['-' * width for width in col_widths])\n",
    "    \n",
    "    # Format the rows\n",
    "    rows = []\n",
    "    for index, row in df.iterrows():\n",
    "        rows.append(\" | \".join([f\"{str(row[col]):<{col_widths[i]}}\" for i, col in enumerate(df.columns)]))\n",
    "    \n",
    "    # Combine header, separator, and rows\n",
    "    table_string = f\"{header}\\n{separator}\\n\" + \"\\n\".join(rows)\n",
    "    \n",
    "    return table_string\n",
    "\n",
    "# Example usage\n",
    "data = pd.read_excel(r\"\")\n",
    "print(data)\n",
    "df = pd.DataFrame(data)\n",
    "print(df_to_table_string(df))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pdf",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
