{
    "spaces/AAAABcXBTWI/threads/Gwf0J-aJjRQ": [
        "SearchAssist was suppose to release a new version on 14th but release got cancelled and was said that it will release this weekend but looks like it didn't happen this weekend also. Do we have a release date for R1.4.0?"
    ],
    "spaces/AAAABcXBTWI/threads/wlYHEXiUVH8": [
        "Hi Sandeep,\n\nRelease is planned latest by 31st October."
    ],
    "spaces/AAAABcXBTWI/threads/VRv5vY9cdcE": [
        "Surendra, thanks for the prompt response."
    ],
    "spaces/AAAABcXBTWI/threads/t2dbDEtXoso": [
        "Hi all, Colgate is immensely interested in SearchAssist. They are a google shop. Do we have a roadmap related to google products? Of particular interest is how can we target and index a specific folder within GDrive and not the entire org. GDrive?",
        "Hi Martin, Filtering specific folder within Gdrive is part of roadmap and will be available by Dec ‚Äò23"
    ],
    "spaces/AAAABcXBTWI/threads/gF9CDINa718": [
        "Is the entire XO platform HIPAA compliant?"
    ],
    "spaces/AAAABcXBTWI/threads/79N4oDOuACU": [
        "Is there a logging facility for tracking which of your URLs pulled pages in real-time on the roadmap?",
        "Hi David, It's not on the current roadmap. We'll add it to the roadmap"
    ],
    "spaces/AAAABcXBTWI/threads/NpTYc78249A": [
        "Are there any issues with https://searchassist-pilot.kore.ai. I have had crawl running for ~2 hours and have been only able to get 160 pages.",
        "@Surendra Subhash Salke"
    ],
    "spaces/AAAABcXBTWI/threads/NOg3AbHsUl0": [
        "Above is the job from the REST call in the browser"
    ],
    "spaces/AAAABcXBTWI/threads/YV6YPpG2CmQ": [
        "I had the same experience several days ago. Ended up downloading pages as PDF and using files instead of crawl",
        "Hi Anton, If pages to be crawled are already identified then we can use the URL-csv or sitemap upload feature to save  the crawling time."
    ],
    "spaces/AAAABcXBTWI/threads/sHXjUaGcpWo": [
        "@David Gwartney Can you please share the application with me. I will have it checked.",
        "So I spun up another application and did not have the same issue."
    ],
    "spaces/AAAABcXBTWI/threads/EryA_czJVfE": [
        "Think about security as this could be a teicky one. Showing to admin in logs vs showing it log file or in UI.",
        "Most of the sites we scrape are public so may not be as big as a concern"
    ],
    "spaces/AAAABcXBTWI/threads/D8DJB_TN6nc": [
        "The title is being set by the first part of the path of the URL, is there a way to configure this to be the title or some other DOM element that would be more relevant?",
        "Hi David,\nWe use value of the <title> tag as page_title.\n\nValue can be changed using a workbench stage. Using custom script stage.\n'''\nCtx.new_title= \"some logic to extract title\"\n\nctx.page_title=ctx.new_title\n'''\n\nThe changes will reflect In the search result not in the page listing screen.\n\nHere is a link to the sample painless scripts for reference \n\nhttps://docs.google.com/document/d/1CdSe8cGT_clgL0XVcBao5IDTOX6UjWHx7BVU58uB_Do/edit?usp=drivesdk",
        "@Surendra Subhash Salke Looks like the correct title is being set by javascript. I tried a single URL with Javascript Rendered on and that set the title correctly. Trying now with all of the URLs.",
        "@Surendra Subhash Salke Is there anyway to use CSS Selectors or XPath as part of the web extraction process so we can can only ingest the main part of an HTML page?",
        "The painless scripts have having to craft a RegEx on document type that is more easily handled by a CSS selector and/or XPath query."
    ],
    "spaces/AAAABcXBTWI/threads/yFBlooGYCjc": [
        "Has anyone on the search assist built any scripts are tooling that can generate questions that use the contents of a web page as the source? e.g. Looks the text of this page and generate questions that answers can be derived from the content on the web page.",
        "I have been asked more than once now to create a bot with SearchAssist without any questions know a priori, so the ability to generate questions could be useful.",
        "Please use LLM stage in the workbench to generate questions.",
        "Wait so there is a feature that does that?",
        "https://docs.kore.ai/searchassist/concepts/managing-indices/custom-llm-prompts/"
    ],
    "spaces/AAAABcXBTWI/threads/HqkaZq9hm5Y": [
        "I'm trying to get SearchAssist to crawl a sitemap and getting the error back; Encountered HTTP error while processing the request. It works fine for other sitemaps. I'm not sure how to move forward with this. (The sitemap is; https://promo.mobile.de/b2b/post-sitemap.xml. )\n\nIs there any way I can get to understand what the HTTP error is in a bit more detail?",
        "@Vishwas Tak can you please help Rob",
        "Hi @Rob Le Boutillier , upon some investigation we have found out that the searchassist VMs are unable to access this specific website. The reason being sometimes websites block access from known IP addresses or IP ranges associated with cloud service providers like AWS. As our VMs are hosted on AWS we suspect this is the reason behind the failure in crawling. One possible solution is to whitelist our VM IPs at the website server so that access is not denied."
    ],
    "spaces/AAAABcXBTWI/threads/qdzINondxLQ": [
        "Sure Surendra"
    ],
    "spaces/AAAABcXBTWI/threads/IXkKMcCejts": [
        "@Vishwas Tak \nHow can this be determined within our platform? What debugging tools are planned so that we can determine that this is the root of the problem sooner? Is there a way we can test this externally to the platform prior to running into this problem.",
        "Hmm interesting - it‚Äôs working with the other site maps that are on that domain ‚Ä¶ so it doesn‚Äôt seem to be consistent",
        "Try with curl and if it still fails try changing the user-agent header:\n\ncurl -v -X GET -L --header \"user-agent: Mozilla/5.0\" $url",
        "@David Gwartney where do we configure all this?"
    ],
    "spaces/AAAABcXBTWI/threads/juJJ-NxTU20": [
        "What is the approximate effort required to have search assist capable of indexing/extracting information from web/documents in a new language (bahasa Indonesia, malay)? any rough estimates would help",
        "Hi Varun, What is the language requirement? Search, answer, or both?\n\nFor a search, it takes 4-5 weeks per language.\nFor Answers, as of now, we are planning to support languages only with the GenAI answering. Once the content is accurately extracted, we can modify the prompt to provide answers in the same language as the query. This capability is being built and will take 4 weeks to complete in SearchAssist.",
        "Requirements is for both , in some cases the client would not need a new generated answer but would like what's there in the document already.",
        "Can you elaborate? What languages are we planning to support in 4 weeks from now? ‚ÄúWe are planning to support languages only with the GenAI answering.‚Äù @Surendra Subhash Salke"
    ],
    "spaces/AAAABcXBTWI/threads/Qz1s8lqLue8": [
        "Search: Do we have a Customer facing document which describes best practices for knowledge document creation? IE: don't embed text in graphics, keep tables simple (or no tables), limit formatting of paragraphs,  try to have the answers in the paragraphs following a title, etc.  Limitations of size and number. etc. \n\nI have a BPO partner opp where they are going to need some guidance on this topic before they begin to cleanup old data and create new docs.  Also, they have some knowledge in \"Google Sites\" pages. Would the web crawl work with the Google sites? Are there caveats or known problems?\nThank you for your answers.",
        "@Jordan Bostick the SearchAssist team sent us this last week right?  Can you send in this space so everyone can have access?"
    ],
    "spaces/AAAABcXBTWI/threads/SRgT5GzpI78": [
        "Yes, I can.\nhttps://docs.google.com/presentation/d/18N3zBXFfDzt2zcwIKrTgv2Il2-11KdfZ4d1llQ0PpqU/edit?usp=sharing"
    ],
    "spaces/AAAABcXBTWI/threads/93Ca2mSl9aY": [
        "https://docs.google.com/document/d/1CGgolqixwbYr9GAGVu0DxVHWC4bpfiLteIoS3bi9J1Y/edit?usp=sharing"
    ],
    "spaces/AAAABcXBTWI/threads/pt6JJjPH3eE": [
        "Thank you for sharing @Jordan Bostick, that second document is so helpful!"
    ],
    "spaces/AAAABcXBTWI/threads/Mrpeci6iLlw": [
        "Welcome @Jason Varghese  Glad to help!"
    ],
    "spaces/AAAABcXBTWI/threads/ekBRhhLg3Bk": [
        "Hi team, can someone explain to me how Answers is/will be different from SearchAssist? I was under the impression that SearchAssist will be rebranded as Answers and part of the unified platform.",
        "Yes, it is a rebranding exercise with generative answers as focus as opposed to search results as a focus; in addition to rebranding we are also adding a unified experience within the xo platform without having to go to search assist separately; but there will be a feature backlog to bring all the features of search assist into unified \"search and answers\" module of xo. There is also a school of thought on offering search assist app license separately for customers who just a search interface  - but this is not finalized yet."
    ],
    "spaces/AAAABcXBTWI/threads/iUohv8UiJpw": [
        "Hi Jon, as of now we are not explicitly mentioning the specific reason. All the errors are clubbed into the same message (network error)."
    ],
    "spaces/AAAABcXBTWI/threads/qvLNLceAJX8": [
        "üò≠\n\nDo we have better debugging tooling coming for this?",
        "@Vishwas Tak @Rohit Tambe @Aditi Bhadouria we should not give generic error. Let‚Äôs send the specific issue back to client for them to understand the actual problem"
    ],
    "spaces/AAAABcXBTWI/threads/UGQmOleG0mE": [
        "Thanks Prasanna - Is there a \"roadmap\" of the backlog items and at what point is a 1:1 achieved between SA and Answers? Reason I am asking, I have a lot of customers interested in SA right now...I tell them that this will be \"Answers\" going forward based on what was presented at KK...seems like this is not the case, at least not initially...I want to be able to manage expectations"
    ],
    "spaces/AAAABcXBTWI/threads/_JIFip7Awl8": [
        "Create a story for this and expedite"
    ],
    "spaces/AAAABcXBTWI/threads/wRywFfEiOWA": [
        "Sure @Girish Ahankari"
    ],
    "spaces/AAAABcXBTWI/threads/Cj4HrXlZrrw": [
        "Sure",
        "Sure Girish"
    ],
    "spaces/AAAABcXBTWI/threads/OzZnMCs0FWY": [
        "Before SearchAssist update, API fullSearch are in this format:\n\n{{context.search_assist_service.response.body.template.graph_answer.payload.center_panel.data[0].snippet_content}}\n\nnow\n\n{{context.search_assist_service.response.body.template.graph_answer.payload.center_panel.data[0].snippet_content[0].answer_fragment}}",
        "Hi @Martin Anibal Bonardi \nFor extractive snippets, we do not have inline citations; hence, we use the first payload.\n\nFor generative snippets, we use the second response payload.",
        "OK Thanks!"
    ],
    "spaces/AAAABcXBTWI/threads/C3v6qNDYhz0": [
        "Just want to add my experience, it seems the number of \"snipset_content\" depends on \"maxNumOfResults\": x in your API call to SA. if you want to assemble it in to one response a simple javascript can help with it.",
        "Hi Anton, this may have been a mere coincidence. There is no link between the maxNumOfResult and the number of items in snippet_content."
    ],
    "spaces/AAAABcXBTWI/threads/JWTKsmykZI0": [
        "RE: SearchAssist\nWhat is the level of effort to add and support these languages? \n\nJapanese (I don‚Äôt believe answers capability is supported.)\nArabic\nMalay\nThai\nTurkish\nVietnamese\nChinese\nFilipino",
        "Currently Japanese support feels like keyword search only. It doesn't consider noun, verb etc"
    ],
    "spaces/AAAABcXBTWI/threads/XOYz_6zdy_M": [
        "RE: SearchAssist\nAre we planning to support MSFT OneDrive?",
        "Not currently on the SA roadmap. Adding it to the roadmap and we'll prioritize it accordingly",
        "Hi Andy,\n\nOneDrive Support is in the roadmap."
    ],
    "spaces/AAAABcXBTWI/threads/Qi4nMZYyDkI": [
        "How do we add it to the roadmap?",
        "You can share it as an FR and we'll take it from there",
        "Rohit, where do we submit feature requests (FR)?",
        "You can either create an FR in Jira or submit a support ticket and the support team will then generate a corresponding Feature Request for you."
    ],
    "spaces/AAAABcXBTWI/threads/9J4WyNXDIZw": [
        "Can I just take a minute here to say Thank you!  To Surendra, Rohit and team for being responsive in this channel.  Often these are quick questions and your responses help us keep sales and post sales activities moving forward.  As well as increasing the knowledge of the SE team.  SearchAssist is a very popular request from prospects. Kudos to your team!",
        "Thanks a lot @Tim Burke . You guys are our first customers and critics. We will keep improving by learning from the feedback we get from you guys."
    ],
    "spaces/AAAABcXBTWI/threads/pQFnM2IAqcg": [
        "@Prasanna Arikala @Girish Ahankari"
    ],
    "spaces/AAAABcXBTWI/threads/sZuhfU1EFqs": [
        "@Santhosh Kumar Myadam @Rajavardhan Nalluri"
    ],
    "spaces/AAAABcXBTWI/threads/qd5LkO9NXAc": [
        "@dk sharma @George Murphy @Peter Wulfraat"
    ],
    "spaces/AAAABcXBTWI/threads/dUYAC1tQ3mE": [
        "Related to SearchAssist: We have some leads who want to import the FAQ, Guide Zendesk to SearchAssist, using the integration with OpenAi, to have greater assertiveness in responses, using Generative AI.\n\nI know that the current integration imports the content of the tickets and not the articles.\n\nCorrect?",
        "Yes, currently only tickets are supported"
    ],
    "spaces/AAAABcXBTWI/threads/b0myOJbvBbE": [
        "@Martin Anibal Bonardi  support for crawling the articles will be live on 18th November"
    ],
    "spaces/AAAABcXBTWI/threads/DxlwCWAXGPg": [
        "@Girish Ahankari We have a very strategic high-value deal hopefully closing in this quarter with a BPO and they are doing some deep discovery on SearchAssist patterns and techniques. Some of it is a bit beyond my capability to answer. Who on your team can I ping offline to help me frame some answers to specific questions they are asking?"
    ],
    "spaces/AAAABcXBTWI/threads/zIw6DzwDzn4": [
        "Paste those questions here or share the link to the document with questions, here for us to answer."
    ],
    "spaces/AAAABcXBTWI/threads/Na1T7b3wFW4": [
        "It might be a team effort to answer. Also the questions and answers might be useful for everyone here"
    ],
    "spaces/AAAABcXBTWI/threads/n8cC4lEEctI": [
        "ok, will do. I took an initial pass at some questions as some of this may be their learning curve, but if they have follow-up I will post here"
    ],
    "spaces/AAAABcXBTWI/threads/PAemX-_m1n0": [
        "when I re-read their question, they thought the \"answer generation\" template using OpenAI would look at documents they uploaded in Answer from Documents. they are getting some things confused",
        "@Girish Ahankari here is an example of what they are trying to do\nAs mentioned in my previous mail, we would like to create a bot that can seamlessly switch between two modes:\nJourney-Driven and Gen AI-Driven. The GEN AI driven mode involves fetching responses from uploaded files using Open AI during the Fallback scenario.\n\nI suggested either using \"Link to bot\" in SearchAssist or using Full Search API in Dialog Tasks to pull information out of whatever is defined in SearchAssist indices.\n\nWould you have any other suggestions?"
    ],
    "spaces/AAAABcXBTWI/threads/prz7Y6Lq720": [
        "Which environment should we be using to build our demos in?\n\nsearchassist-pilot.kore.ai or searchassist.kore.ai?",
        "For demos searchassist-pilot.kore.ai can be used",
        "That's what I thought. I'm running into an issue with the Web Crawl... I wasn't sure if it was me or whether I needed to reach out for support. I'm building a demo for Etsy and have the following CSV with URLS... but it fails with the following error.",
        "@Rohit Tambe any ideas?",
        "@Jon McCain this has happened to me before too and it seems like the same problem, the Help Pages are behind a firewall and cannot be crawled.",
        "Interesting. Okay.\n\nThere isn't any login required..  @David Gwartney you're the king of hacking these things... thoughts??",
        "Crawling is failing for individual links also in the shared CSV, seems like the given website is blocking the access. Need to check this,  @Vishwas Tak or @Akhil Sainath Maddala can you please help with this?",
        "Try one of the URLs with curl to see the http response",
        "It is likely failing because the user agent header missing or not a known type",
        "I have a request to add the setting of user agent header",
        "We use a Mozilla web as default user agent",
        "user-agent.¬† ¬†¬†Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/89.0.4389.114 Safari/537.36",
        "I played with curl a little... this command worked. Command, CMD Output, and results attached.\n\ncurl -L -v --cookie \"\" -A \"Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/89.0.4389.114 Safari/537.36\" https://help.etsy.com/hc/en-us/sections/360003399734-Buying-on-Etsy?segment=shopping\n\nCommand Line Output:\n\n¬†% Total ¬† ¬†% Received % Xferd ¬†Average Speed ¬† Time ¬† ¬†Time ¬† ¬† Time ¬†Current\n¬† ¬† ¬† ¬† ¬† ¬† ¬† ¬† ¬† ¬† ¬† ¬† ¬† ¬† ¬† ¬† ¬†Dload ¬†Upload ¬† Total ¬† Spent ¬† ¬†Left ¬†Speed\n¬† 0 ¬† ¬† 0 ¬† ¬†0 ¬† ¬† 0 ¬† ¬†0 ¬† ¬† 0 ¬† ¬† ¬†0 ¬† ¬† ¬†0 --:--:-- --:--:-- --:--:-- ¬† ¬† 0* ¬† Trying 104.16.51.111:443...\n* Connected to help.etsy.com (104.16.51.111) port 443 (#0)\n* schannel: disabled automatic use of client certificate\n* ALPN: offers http/1.1\n* ALPN: server accepted http/1.1\n* using HTTP/1.1\n> GET /hc/en-us/sections/360003399734-Buying-on-Etsy?segment=shopping HTTP/1.1\n> Host: help.etsy.com\n> User-Agent: Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/89.0.4389.114 Safari/537.36\n> Accept: */*\n>\n¬† 0 ¬† ¬† 0 ¬† ¬†0 ¬† ¬† 0 ¬† ¬†0 ¬† ¬† 0 ¬† ¬† ¬†0 ¬† ¬† ¬†0 --:--:-- --:--:-- --:--:-- ¬† ¬† 0* schannel: failed to decrypt data, need more data\n< HTTP/1.1 200 OK\n< Date: Tue, 07 Nov 2023 08:51:25 GMT\n< Content-Type: text/html; charset=utf-8\n< Transfer-Encoding: chunked\n< Connection: keep-alive\n< CF-Ray: 82245593eae65c93-ORD\n< CF-Cache-Status: EXPIRED\n< Cache-Control: max-age=0, public\n< Content-Language: en-us\n< Strict-Transport-Security: max-age=31536000;\n< Vary: Accept, Accept-Encoding\n< Protocol: HTTP/1.1 always\n< x-frame-options: SAMEORIGIN\n< x-request-id: 82245593f34f5c93-ORD\n< x-runtime: 0.444697\n< x-ua-compatible: IE=edge\n< x-xss-protection: 1; mode=block\n< x-zendesk-origin-server: app-server-784447c7dd-mklh7\n< x-zendesk-processed-host-header: help.etsy.com\n< Report-To: {\"endpoints\":[{\"url\":\"https:\\/\\/a.nel.cloudflare.com\\/report\\/v3?s=teYVrHlYGeqLJzOBeOR2T5rpW96O%2BZxpIdR%2FQMTmoyTyYe8TG1d6XaqVteZBNwJmaXfBEIeEFO1ZYEwz1kCcvSh6TeOw51yXOCyE06I7ZEE6a%2Fo22LJQQNwzp7M1vno%3D\"}],\"group\":\"cf-nel\",\"max_age\":604800}\n< NEL: {\"success_fraction\":0.01,\"report_to\":\"cf-nel\",\"max_age\":604800}\n* Added cookie __cfruid=\"b920c52561c38f6d50d1a5b664c7cb10175e85db-1699347085\" for domain help.etsy.com, path /, expire 0< Set-Cookie: __cfruid=b920c52561c38f6d50d1a5b664c7cb10175e85db-1699347085; path=/; domain=.help.etsy.com; HttpOnly; Secure; SameSite=None\n< Server: cloudflare\n<\n{ [1642 bytes data]\n100 42554 ¬† ¬†0 42554 ¬† ¬†0 ¬† ¬† 0 ¬†69035 ¬† ¬† ¬†0 --:--:-- --:--:-- --:--:-- 69081\n* Connection #0 to host help.etsy.com left intact",
        "The next step should be diving in to these HREFs... right?",
        "@Surendra Subhash Salke I just tried setting up a new CSV (attached) with direct links that load in a web browser but don't in Search Assist.\n\nWho can help me with this?\n\nI'm trying to build this and indicate how simple it is. Curl pulls back the pages as I show above... why is our product failing to do so?",
        "Hi John,\n\n @Vishwas Tak is looking into it",
        "I see url header is missing in the csv file",
        "Ahhhh lemme add that...",
        "I thought that was there as an example, etc.",
        "Fixed that but it's still failing",
        "I've tried with all variations of those checkboxes ticked.",
        "Hi @Surendra Subhash Salke We are getting 403 Client Error: Forbidden for url: https://help.etsy.com/hc/en-us. Looks like this is the same issue where the cloud servers are blocked for crawling. We'll have to get our cloud IPs whitelisted.\nMeanwhile, we are working on externalising the root cause of the error to the end user for such failures.",
        "Is this whitelisting something that has to happen on the customer side of things?",
        "I hope not as this makes it nigh impossible to create a demo using a customer's public site",
        "@Jon McCain Yes this needs to be happened at client",
        "We definitely need to find a work around for this.",
        "@Akhil Sainath Maddala @Vishwas Tak \n\nAre you able to run this on / in your instance as a test?\n\ncurl -L -v --cookie \"\" -A \"Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/89.0.4389.114 Safari/537.36\" https://help.etsy.com/hc/en-us/articles/115015521288-How-to-Buy-an-Etsy-Gift-Card",
        "This pulls back the page appropriately.",
        "for me",
        "HTTP/1.1 403 Forbidden\n< Date: Tue, 07 Nov 2023 16:37:25 GMT\n< Content-Type: text/html; charset=UTF-8",
        "We're unable to get the response @Jon McCain",
        "üò≠",
        "In chatting with David he has suggested using proxies so we don't have to be concerned with those ips being blocked.",
        "That would be useful for our demo space"
    ],
    "spaces/AAAABcXBTWI/threads/zzElkBN53Dc": [
        "Can we use external crawler to get data from web sites? A prospect has tested some other tools which are able to pull data better than our SearchAssist crawler."
    ],
    "spaces/AAAABcXBTWI/threads/gmqO8CYtgRY": [
        "@Umang Shah Have been thinking about that myself. It might possible to download the HTML and then serve up on another web server and point Search Assist at that web server. But have not tried that yet."
    ],
    "spaces/AAAABcXBTWI/threads/RSEdElK4-P4": [
        "BTW, Is the particular customer using any web crawling services or is the tools they have home grown?"
    ],
    "spaces/AAAABcXBTWI/threads/VikK8VpoYOQ": [
        "I'm also curious as to how they get around the whitelisting issue we seem to be facing at every turn"
    ],
    "spaces/AAAABcXBTWI/threads/-j_5jNZfLCM": [
        "The client would need to open up our IPs or our Crawler Agent in their firewalls.   Even publicly hosted web sites often have a web firewall (like WordFence for wordpress sites) that can shut down a crawler or DOS attempt, etc. etc."
    ],
    "spaces/AAAABcXBTWI/threads/FFQ-3AU9mag": [
        "In a real deployment (not demo) the client's web team would need to get involved to whitelist us."
    ],
    "spaces/AAAABcXBTWI/threads/ufsixV9p1N8": [
        "Thanks Tim. Fair points.\n\nI'm meeting with David in a bit to review his process for handling this differently, i.e. pulling the pages down, saving as pdf, and uploading them... This is fine for building something that we're not going to dig into the configuration."
    ],
    "spaces/AAAABcXBTWI/threads/eyv0iCiAiUA": [
        "We need to get residential proxies added to search assist to get around these issues. Like this one (only for illustration):\n\nhttps://oxylabs.io/pages/residential-proxies",
        "@David Gwartney Sure, will analyze these options. \n\n @Rohit Tambe - Let us add this to the tracker"
    ],
    "spaces/AAAABcXBTWI/threads/ifPHYrp3uqY": [
        "Or possibly partner with a company that does full blown web scraping such as:\n\nhttps://www.import.io/"
    ],
    "spaces/AAAABcXBTWI/threads/rm5SqOUmAIE": [
        "Sure Santhosh"
    ],
    "spaces/AAAABcXBTWI/threads/Bb-vAuWmTsE": [
        "if a customer wants to use a mix of answers from SearchAssist indices as well as Actions (intents) defined in a linked bot, can they set up the web/mobile channel on the linked bot and interact that way? or do they need to configure the web/mobile channel in SearchAssist itself?",
        "Based on this document you have to setup the Web/Mobile  Client Channel and then setup the BotAction with the calls to the FullSearch using the FallBack Dialog Task... \n\nhttps://docs.google.com/document/d/1AY04sMQ_PBHsCYPRLa0WoaiHHJng7RVq42eHG4H6pUE/edit#heading=h.yk4aifctzhit\n\nSo I believe it's the latter and then they would use the channel configuration from the XO Platform to access BOTH."
    ],
    "spaces/AAAABcXBTWI/threads/jw3kmMEUEng": [
        "you can certainly do it that way, but then what is the point of linking a bot in SearchAssist?",
        "It is the behavior that is not appealing to the user. The Dialog Task is triggered but does not execute until the user clicks on name of the dialog task in the chat window. Unless, there is an option to trigger this immediately that I do not know of. This adds an extra turn to the conversion.",
        "UX aside, if you want to publish a SearchAssist driven web chat to customers, can you do that using the linked bot's web mobile channel or does it have to be set up in SearchAssist here ?",
        "this platform unification can't come soon enough. why do we make everything so hard?",
        "Because it is easy to make things hard....",
        "You only have so much time to get a release out. I have been there a done that.",
        "And the platform is HUGE!",
        "Our release train is a bullet-train",
        "Linking a bot I believe was meant to transition from pure search to chat. Now that we see customers want the other way around we are limited until the unified platform"
    ],
    "spaces/AAAABcXBTWI/threads/1___ciynWoI": [
        "Can someone assist me in determining WHY the Generative AI isn't working in SearchAssist-Pilot for me?",
        "Describe not working?",
        "From chat GPT:\n\n‚ÄúNot working‚Äù typically refers to a state where something, such as a machine, device, or system, is not functioning as intended or expected. It can imply a range of issues, including malfunction, failure, or the inability to perform its intended tasks or operations.‚Äù",
        "Correct. I have OpenAI Configured.",
        "It isn't summarizing and just returning the files",
        "Did you also update the Search Settings/Custom Configurations?",
        "Yup.",
        "Did you try disabling the extractive model?",
        "Sorry, i see it is disabled.....",
        "Yup. It's been off the whole time. :)",
        "No worries",
        "In your custom configs remove that first line for the \"extraction_method\"",
        "Removed, retrained, and still no dice.",
        "@Jon McCain  try adding dev_Enable_DocSnippets = true",
        "and maybe: dev_Enable_Query_Rewrite_Type = query",
        "I've added the Azure OpenAI credentials... THANKS @Alenis Fiallo!!! But, it's still not working.\n\nWho from Product can I invite to look at why the Generative AI isn't working?",
        "Did you ask in our SeachAssist hotline? I can check with you when I get home",
        "We switched to here I thought since this space was created.",
        "This is the right space.",
        "Yes, I‚Äôm sorry I didn‚Äôt notice the group",
        "Check it is enabled and that you trained the app",
        "You can share the app with me @Jon McCain . I'll try helping or pull in the right person if it still doesn't work",
        "Thank you @Aditi Bhadouria. I've shared the bot with you. I look forward to hearing what I've done wrong. üôÇ",
        "@Jon McCain what was wrong? and how did u fix it?",
        "I'm sorry @Navdeep Grover it has been too long since we dug into this... If you're having issues I suspect the best course of action is to post a new question in this group or open a support ticket."
    ],
    "spaces/AAAABcXBTWI/threads/6ExlVcNS5GQ": [
        "You may experience some GAI weirdness today @Jon McCain \nhttps://techcrunch.com/2023/11/09/openai-blames-ddos-attack-for-ongoing-chatgpt-outage/amp/",
        "The forgot to size the services to account for DDOS. ;-)"
    ],
    "spaces/AAAABcXBTWI/threads/7S30L_LbUL4": [
        "How do we know what documents in the repositories to send to the LLM for summarization based upon the utterance?\n\nDoes our engine take the request... find the related documents. Then send the utterance and those documents only to the LLM for summarization?",
        "My understanding is that we pull out the chunks (information), most relevant to the end user utterance / query, from the ingested documents.. score them based on the defined business rules.. select the top 5 scored higher and send over to LLM that summarizes / paraphrases as a response, returned over to the end user.",
        "may have changed as the workflow is moving rapidly, but here is the slide we were using over the past few months to describe it",
        "/smh I have that slide... thanks guys",
        "once you know how to explain it, teach me üòÄ",
        "The lookup functionality is based upon a cosine similarity of the questions posed by the user.",
        "The document data has been chunked and vectorized and pushed to a vector database. We use the open source one Milvus. The input utterance is vectorized and then uses cosine similarity agains that which is in the vector database to return up to 5 chunks (5 is the max. but is configurable to less than 5 in the Answers Snippets).",
        "checkout 'simulation' feature: https://docs.kore.ai/searchassist/personalize-results/answer-snippets/#Simulation_and_Testing",
        "https://www.youtube.com/watch?v=dN0lsF2cvm4",
        "The workflow in this article is what Santosh used to explain it to us in a recent webinar: https://towardsdatascience.com/how-to-chat-with-any-file-from-pdfs-to-images-using-large-language-models-with-code-4bcfd7e440bc",
        "Yup I had saved that and shared it too.",
        "I think we had a recording of the enablement session from Aug 24th, but I can't seem to find it",
        "That's correct. Also, to simplify for everybody's understanding, MPNet is the embeddings model, Milvus is the vector store, cosine vector similarity is the metric used to find the top 5 matching chunks",
        "https://drive.google.com/file/d/1rVWlp-ft5lrj4t727Y-Wmt_W3U3I3NoE/view\nIs this the one you were looking for?",
        "@Tim Burke the links to all of these are in the SE shared drive",
        "@Matt Panaccione I looked, but it is such a honeycomb of organizational methods..., I cannot find it.",
        "You are looking in the folder not the new SE drive that‚Äôs clean and organized"
    ],
    "spaces/AAAABcXBTWI/threads/8LN7LOcytBM": [
        "Hi All, I have a case where in Hong Kong OpenAI & Anthropic LLM is not available..and a Hong Kong prospect is looking for an GenAI answers from documents..how do we address this? Need a solution approach. Appreciate your help"
    ],
    "spaces/AAAABcXBTWI/threads/XBaiD2yoAD8": [
        "@Rakesh Bathini is it just OpenAI direct not available but perhaps Microsoft's Azure OpenAI solution is available?"
    ],
    "spaces/AAAABcXBTWI/threads/COID3PBpbn0": [
        "Azure OpenAI & Anthropic is not available too in HK..And the customer needs LLM on-prem",
        "Got it"
    ],
    "spaces/AAAABcXBTWI/threads/Rdj2oIy_leQ": [
        "If Customer is ready to bear the cost of hosting an opensource LLM, we can host Falcon or LLama2 for them",
        "Okay if customer chooses Falcon or LLama2, how quick can we support this in SearchAsssit for GenAI answering from DocumentAI?"
    ],
    "spaces/AAAABcXBTWI/threads/ONJtuSthc_g": [
        "Note that it is costly as they might need 8 GPUs depending on the model they need"
    ],
    "spaces/AAAABcXBTWI/threads/wQHlT2AQtew": [
        "A prospect is currently trying to set up a Connector from Azure Storage to SearchAssist. Even though the credentials are correct, they get the error that ‚ÄúConnection Authentication failed‚Äù. Who can help?",
        "@Surendra Subhash Salke or @Girish Ahankari"
    ],
    "spaces/AAAABcXBTWI/threads/h88mrtAMtos": [
        "Does it exceed the quota limit ?"
    ],
    "spaces/AAAABcXBTWI/threads/r_iqlDl3K58": [
        "@Umang, Looks like a bug. We faced same issue with sharepoint and servicenow and got fixed this week. Connect with searchassist team Vaishali and Rohan they know how to solve if it‚Äôs the same issue.\n\nhttps://koreteam.atlassian.net/browse/PLAT-23740\n\nhttps://koreteam.atlassian.net/browse/PLAT-23741"
    ],
    "spaces/AAAABcXBTWI/threads/rE5YOr2y1GE": [
        "Is there a Roadmap of LLMs that we are already planning? I got a request from an existing customer to support Palm."
    ],
    "spaces/AAAABcXBTWI/threads/b_gqfStxzfk": [
        "Can we invest and get answers from an Excel file? I have a customer who wants to do a backoff between us and MSFT virtual agents",
        "Not yet. It‚Äôs in roadmap.",
        "When is this available?",
        "I was under the impression we can read from tables...",
        "@Girish Ahankari",
        "@Martin Jahn can we get a sample excel data that you are looking support for? Excel has lots of features. If we can scope the requirements, I can come back with what is possible and the roadmap for more featur support",
        "I will send an email with the excel to you, Girish.",
        "@Girish Ahankari @Martin Jahn Have we established if we're able to support this?"
    ],
    "spaces/AAAABcXBTWI/threads/LJBR0OyIszM": [
        "One of my customers (Carestream Dental) has observed that the feature of going to a document on a certain page seems to be blocked by Adobe Acrobat Reader browser extensions. For instance, if a user tries to open the link hereabove using Chrome and the Chrome Adobe Reader extension is active, then the document opens on the first page, so it fails to drive the user to the relevant section. \n\nIs anyone aware of this/ has experienced this? Is there a workaround?",
        "@Rohit Tambe @Girish Ahankari @Surendra Subhash Salke"
    ],
    "spaces/AAAABcXBTWI/threads/H51ZsqulBYc": [
        "is there any recommended workaround for the file size limit? it's pretty low by modern PDF standards. for instance, I was looking to see if I could load in something like a service manual to show Dell and most of those are at least 20MB",
        "I'm running into same thing Jon and others have seen with web crawl, just gets blocked. So was going to pivot to PDFs, but issues there too",
        "Same requests from various prospects and partners on increasing the limit of file size",
        "You can use the utilities to separate the documents into smaller sizes:\n\nhttps://www.mankier.com/package/poppler-utils",
        "https://www.mankier.com/1/pdfseparate",
        "Are they paid customers or is it for demo purposes only?",
        "I am working currently with team on costing for the large pdf files and will come back on enabling the large files for kore employees first so that you guys can demonstrate.",
        "We can have paid options for large files for customers",
        "I have heard from sales in Japan that we charge for data based on number of pages for Japanese customers. But I haven‚Äôt seen any feature which can count the pages.",
        "Dont share the docs with 3rd party, use this tool https://github.com/Frooodle/Stirling-PDF",
        "SearchAssist team, I was first reporting the challenges with web crawler back in the spring and it seems like none of the issues have been addressed with our crawler approach being blocked. This significantly limits our ability to demo the product and sometimes we don't get past the initial stages because potential customers don't have faith in the product. What is being done to address this, such as the proxy ideas that David mentioned?",
        "@Bharat Rekha please look into this asap",
        "Sure @Girish Ahankari.",
        "Hi @Curtis Swartzentruber, Can you please share me list of issues that you have reported?",
        "sorry, hard to figure out replies with this threaded stuff. just saw this. @Bharat Rekha I added you to an active Space from when I was working on a POC for TTEC around Logitech use cases. this was prior to this Space existing. there are a bunch of web crawler issues I was experiencing then that still have not been addressed.",
        "Hi @Curtis Swartzentruber, Can you please create a support ticket and mention all the list of issues that you are facing related to crawling? This will help us to track better and prioritise the issues. \n\nPlease share the ticket once created."
    ],
    "spaces/AAAABcXBTWI/threads/4Hr5cO56Yjk": [
        "PDF Splitter - https://www.ilovepdf.com/split_pdf"
    ],
    "spaces/AAAABcXBTWI/threads/OYC0HpONyhw": [
        "What controls are available in the SearchAssist product today to find-tune responses from Answer Snippets besides the prompt? Are we able to control how documents are chunked? How chunks are indexed?",
        "I‚Äôd also like to understand our chunking strategy and how we balance between context and similarity."
    ],
    "spaces/AAAABcXBTWI/threads/9xSU6w7WJF4": [
        "Is there any kind of feedback mechanism if the information surfaced is not exactly what is needed or correct?"
    ],
    "spaces/AAAABcXBTWI/threads/Sz8EOI3EQjk": [
        "@Amy Jeschke yes I believe there is a thumbs up or down to give admins feedback on quality of answers"
    ],
    "spaces/AAAABcXBTWI/threads/f5zqEJbfeiQ": [
        "@Amy Jeschke Here is an example from POC we are currently running - bottom right üëç or üëé"
    ],
    "spaces/AAAABcXBTWI/threads/JwqHutg7Qz4": [
        "That's Great @Adam Warshaw. How is that reflected in reporting?"
    ],
    "spaces/AAAABcXBTWI/threads/2z1kIM33Atk": [
        "^^ I believe... (SearchAssist team can chime in) that is is used to TRAIN the NLU on if the response is proper or not.  Its not a feedback mechanism to admin, management, or anyone.  There are not notifications and as far as I know... nothing in Analytics.   Its Training.",
        "This is shown to admin who can take action by improving the relevance ranking"
    ],
    "spaces/AAAABcXBTWI/threads/e-nhQ0OWLJI": [
        "As far as reporting, there is currently a bug (not sure if its just our POC or widespread) where only 24 hours and 7 days populate reporting while when you choose custom nothing populates."
    ],
    "spaces/AAAABcXBTWI/threads/8dyCwEolvGI": [
        "Here is an older snapshot - positive and negative reviews"
    ],
    "spaces/AAAABcXBTWI/threads/GSWBa0lRySQ": [
        "when using searchassist-pilot for demos, the deep link into a doc is being blocked by Chrome. For example: https://searchassist-pilot.kore.ai/searchassistapi/getMediaStream/findly/f-7d258b09-6001-507f-b626-b7f331398751.pdf?n=8783114130&s=InI0a0JHbUVDN01UK3Riem9IK2EvSzd5STdPbUhvMUpJcUZEZHVjZlVwYTg9Ig$$#page=12\n\nit is showing up as Info or Not Secure. (https://support.google.com/chrome/answer/95617?visit_id=638355872889633353-2326478079&p=ui_security_indicator&rd=1#zippy=%2Cinfo-or-not-secure)\nCan we get this endpoint secured properly?",
        "this is specifically out of third-party AgentAssist, in this case Genesys. if I right-click and open in new tab, it opens fine. so it's just direct click that is creating the block.",
        "Whoa, The links are public. Is this a potential breach if someone non-public documents?\n\nAble to open in Incognito Window:",
        "@Curtis Swartzentruber can you please raise a ticket for this with the support team. Team will debug and take it forward accordingly",
        "@Surendra Subhash Salke The links to the documents should have a signed key with time limit on it. It was implemented in the platform as part of the getMediaStream. @ChandraSekhar Poshamolla",
        "Ok prasanna. We will priorities this."
    ],
    "spaces/AAAABcXBTWI/threads/6pmhA28E9Ok": [
        "Hi Andy, we currently offer these customizations through custom configs. Balancing between context and similarity is unique to each use case and type of documents hence there is some level of experimentation involved. But we do have some default settings if it's not defined"
    ],
    "spaces/AAAABcXBTWI/threads/lqvSJlEBvAo": [
        "@Martin Jahn can you please contact the support team and raise a ticket for this issue?",
        "Or alternatively ask the client to get in touch with the support team",
        "@Aditi Bhadouria - thanks. I have created a ticket on customer behalf. 37296"
    ],
    "spaces/AAAABcXBTWI/threads/x7omt2KDG1k": [
        "I am looking for a solution where I can add facets so that I can filter documents results more easily.\nI want to have facets which can filter car manuals based on Car Name, Model year, Model Name etc.\nI am able to use Workbench and use Directory_Name to create facets of different directories which are named after Car Name hence the first problem is solved. I want t know how I can create facet for Model year and Model Name assuming both the information is in the documents uploaded. Do we have something where I can create custom facets and when I select ex 1990 the results shows me the document which is having 1990 basically doing a keyword filtering.",
        "Cc @Surendra Subhash Salke",
        "@Sandeep Singh Rana If the required data is indexed as 2 separate fields, let's say \"modelName\" & 'modelYear'. You can create these 2 new fields under the Index fields section and these new fields can be configured under facets."
    ],
    "spaces/AAAABcXBTWI/threads/YpYJguV2SdI": [
        "Team - I need help with the following queries for SearchAssist across multiple clients:\n\n1) Is there a way to persist updates to the chunks? If documents are recrawled, the chunks get overwritten, and client finds this not a scalable approach, as there will be a lot of manual work every time they want to recrawl.\n\n2) Is there a way to control chunking behavior in general, maybe part of the indexing pipeline?\n\n3) How do we handle language detection? Client has data crawled in english, but wants to allow someone, let say, in german to ask a question and get a response in german. Maybe approach is german input --> detection and translation into english --> english query submitted to SA --> english chunks and detected language sent to LLM --> LLM paraphrases and translates into originating language (german) to be sent back to user.\n\n4) Is there a way to do pre and post processing before sending to LLM's. Sometimes chunks are cut off in the middle of crucial data, and includes data (like lookup data) that might be best served processed on the platform, not the LLM. For example, client asks about a cost of making a phone call from Germany to Syria. The info about country costs are similar across groups of countries. Instead of sending all the groups of countries to the LLM (which takes up a lot of chunk space), let a lookup to the country group happen in preprocessing, let LLM figure out the cost between country groups, and post processing can revert back to the originating countries.\n\n5) Is there a way to batch test many queries against the search engine. Sometimes doing 1 at a time takes too long.\n\n6) Is there an issue with the SA GUI returning responses to the user when testing? Client found that response times from the engine and LLM are fast but response is not returned quickly.\n\n7) Do we support crawling of tables from html files? How well does this work?",
        "I learned so much just reading the questions lol. Great questions.",
        "@Surendra Subhash Salke @Girish Ahankari @Rohit Tambe Can someone answer these - just need what is supported or not supported out of the box"
    ],
    "spaces/AAAABcXBTWI/threads/vsmPWWKF1nM": [
        "@Ingo Brod please add anything else that might help"
    ],
    "spaces/AAAABcXBTWI/threads/s77I7cTaAP8": [
        "When you have a linked bot, is there a way to tweak the preference of supplying an Action result vs a \"knowledge\" result?"
    ],
    "spaces/AAAABcXBTWI/threads/CpPas_ln5uc": [
        "@Gurpreet Singh How urgent are these features required and how urgent should we respond on these?",
        "he is only asking if they are supported or in roadmap"
    ],
    "spaces/AAAABcXBTWI/threads/mlbv7ynpyEY": [
        "#1. We are working on ability to persist the changes and ability for supervisor/Admin to review and accept the override. However, there is a debate within the product team on the usefulness of this tracking as it will be very tough for anyone to review when the documents are large in sets like 10,000 documents +"
    ],
    "spaces/AAAABcXBTWI/threads/qechOcuLCVo": [
        "#2 We are adding control in chunking behaviour in UXO. Base architecture is implemented and will be rolling out various options from Jan‚Äô24. However, Within SearchAssist it might come in Feb‚Äô24. So anyone using UXO will have access to chunking strategies earlier that SA"
    ],
    "spaces/AAAABcXBTWI/threads/qovAPailOGU": [
        "#2 In UXO, we have a provision where chunking strategies can be selected. As of now, only text-based chunking is supported, where you can decide the chunk length and chunk overlap. Other chunking strategies, like summery and tree strategies are in the roadmap.",
        "To configure chunk length for text extraction in SearchAssist, currently it can be done via custom configs- can refer the \"Chunk token size\" in the below doc-\nhttps://docs.google.com/document/d/1kqSH_g0GZ8A6LvLZyCr2EB4Y7FlAj5Rdxo4TekQVunM/edit#heading=h.2ftwesm4zops",
        "Thanks Rohit. I will take a look and share these custom configs",
        "Also, can we use these in the GA version of SA?",
        "Yes",
        "Where do we define the chunk overlap?"
    ],
    "spaces/AAAABcXBTWI/threads/RLIVQpxlL2s": [
        "#3. We have got this FR, but still debating its usefulness and quality of results. Will update on this in Jan‚Äô24. It‚Äôs definitely in Roadmap but date is not arrived at yet.",
        "Is this supported now? A prospect wants to ingest docs in English only and expects the Virtual Assistant / SearchAI to respond in local languages (around 33 in total including English)."
    ],
    "spaces/AAAABcXBTWI/threads/O9z2rUxF2Q4": [
        "@Surendra Subhash Salke for #3, they want translation, which is not planned",
        "yeah Girish, Only a language-agnostic embeddings-based retrieval and answering is planed. No translation yet."
    ],
    "spaces/AAAABcXBTWI/threads/vVj2Q5vbBRQ": [
        "#4, can we get more usecases? Only challenge in such requests is the latency which will get added. But we will comeback to you on this once we get more details"
    ],
    "spaces/AAAABcXBTWI/threads/UCreknSYnto": [
        "#5. While there is no built in tool available. Anyone can use our public API and build automation around it. Also, note that when using Answers via OpenAI/Anthropic, the answers will not be always with same text while they would mean the same. We will add a FR for a built-in tool similar to Batch testing in XO",
        "Is the tool for batch testing still planned to be released, in SearchAI?"
    ],
    "spaces/AAAABcXBTWI/threads/d_gZHyaNsLk": [
        "#6. Can we get more details on the issue? How did client find that the response from Engine and LLM are fast?",
        "will get more details on this. They suspected there was a bug in the GUI causing a delayed response. But I will see how they determined this in more details."
    ],
    "spaces/AAAABcXBTWI/threads/fyZSWMwLFEo": [
        "#7. We do support as a basic support. We are working on improving it. As of now one can only find the data, we do not support aggregations, calculations on the tables. It can only fetch the data from table"
    ],
    "spaces/AAAABcXBTWI/threads/XihJcZsqDUY": [
        "#8. @Curtis Swartzentruber there is an option to show both Action and knowledge result as choices.",
        "yeah, i've seen this work in other apps. in this case a single article result is taking precedence and you only see the Action if you click \"show all results\". for instance the \"weights\" configuration doesn't have an option for Actions. they have Bot Actions enabled in Search Settings. anything else?",
        "@Girish Ahankari need to get back to partner with any advice here",
        "@Rohit Tambe can you look into this please",
        "@Curtis Swartzentruber \nplease refer the below documentation for  configuring bot actions\nhttps://docs.kore.ai/searchassist/user-engagement/bot-actions-2/",
        "@Rohit Tambe once again, not my question. I know how to configure them. the question is whether there is a way to always offer matching Bot Actions as well as knowledge results. what the partner is seeing is a Bot Action they believe should be offered as an option does not show up. only one knowledge answer shows up. This is when using Generative Model with Answer Snippets.",
        "The answer is the Zeroth result on the search result page/VA interface, followed by the Search Results. Bot Actions are part of Search Results, the reason it is under the \"show more results\". currently, we don't have the option to showcase both as zeroth result.",
        "Got it, that's what I needed. Thanks",
        "@Girish Ahankari @Rohit Tambe can we have a feature request to have an option to show both if available OR an option to adjust the weight for Bot Actions in Search Settings to be higher/lower priority relevant to answers from the indices."
    ],
    "spaces/AAAABcXBTWI/threads/XDREV05m9Cc": [
        "Is there a way to query the vector database with a utterance so we can see which chunks are returned?",
        "You can view the chunks qualified for a given query in the answer debug."
    ],
    "spaces/AAAABcXBTWI/threads/E17j0gaL7bc": [
        "Can we can an CRUD API by which we can add chunks/metadata so that we can do our lift to get data into the system?",
        "Currently not supported, adding and updating metadata to chunks is in Roadmap",
        "@David Gwartney you can add chunks via API though @Rohit Tambe i think that‚Äôs what we do for Alaska isn‚Äôt it?",
        "For Alsaka, chunks were ingested via Structured Data using Ingest Data API. Documentation:  https://docs.kore.ai/searchassist/public-apis/searchassist-public-apis/#Ingest_Data_API",
        "I think it would be REALLY beneficial if such solution architectures were documented and presented to the SE organization. @Aayush Mediratta",
        "Sure Jon we‚Äôll document and share it",
        "@Girish Ahankari That is exciting news",
        "Wait, this API was there before and the docs say it only works for structured data. From the docs:\n\nThis API is used to ingest data into the SearchAssist application. Currently, the feature is limited to ingesting only structured data.",
        "@Rohit Tambe Is the documentation out of date?",
        "@David Gwartney yes in this case the chunks are ingested as structured data.",
        "There is no direct api today for chunk ingestion(we will plan in future along with meta data)",
        "However, with ingestion of chunks as structured data we were able to solve the same problem for Alaska airlines"
    ],
    "spaces/AAAABcXBTWI/threads/DpXEcBKlwXI": [
        "Eventually, the client might want to import documents of different languages, and potentially have any language user query against it. But ingesting info in english but making it available for multi languages seems like a useful feature. I will leave it to you obviously to determine the right strategy on priorities. This client is SwissCom and serves users of multi regions and languages, hence the Q's about language. Might be common type of need for euro companies.",
        "I have observed it works for Chinese. ie I upload the English documents into SearchAssist and then make an enquiry in Chinese, it can response the right contents in English from the Document using AI. Not sure how this magic works in our flow"
    ],
    "spaces/AAAABcXBTWI/threads/uAGp8pcxGmg": [
        "The ability to have pre-processing can serve lots of use cases, pre-llm lookups, language translation, etc. etc. curious if that is useful in your opinion or already part of the strategy..."
    ],
    "spaces/AAAABcXBTWI/threads/jYq-JAihxdE": [
        "@Girish Ahankari and Team, thank you for your prompt responses. üôÇ"
    ],
    "spaces/AAAABcXBTWI/threads/-K5IyJ-dUa8": [
        "That works only when using openAI"
    ],
    "spaces/AAAABcXBTWI/threads/YEXGuCW5c0E": [
        "How does it work internally as the chunks in the vector DB is in English? When we search the chunks using Chinese, it should not work unless we make a call to openai to do the translation first. And how do we know a translation is required?"
    ],
    "spaces/AAAABcXBTWI/threads/B93NQYq_pZM": [
        "It may not work if there are lots of documents."
    ],
    "spaces/AAAABcXBTWI/threads/F7wUPaSRPrk": [
        "As the chunks are converted to vectors, input vector and stored vectors are compared"
    ],
    "spaces/AAAABcXBTWI/threads/gO6wt8Kf7dg": [
        "@Surendra Subhash Salke How do we engage the team with respect to tuning of answers with Answer snippets with Search Assist. Working on a deal with Ring Central whereby I ingested 3982 URLs and then the asked 100+ questions and provided a status of the answers as Yes, No, and partial. They want to know to improve answers for those that incorrect.",
        "Actually, could be good topic to run in a webinar since I have real data ingested and the feedback on the correct answers.",
        "When can we have a session on this?",
        "@Surendra Subhash Salke @Girish Ahankari @Santhosh Kumar Myadam Isn't there a document or videos that explains different ways of tuning the search within the platform?",
        "Did you guys create a guideline on what are the different roles for tuning and improving results, kind of skills required and the approximate time it takes based on number of documents + type of document.",
        "It is easier to set expectations that implementation requires  professional services effort",
        "E0 template",
        "@Surendra Subhash Salke I need to have your expertise to do the tuning next week. I will send a separate email with the request to get assistance.",
        "Pls share if there are any docs or videos"
    ],
    "spaces/AAAABcXBTWI/threads/JeLK658Czjc": [
        "Sunny- is the response in Chinese or English?  Was there any special setup? Im also curious how a Chinese query can get a search assist response without translation first. \n\nI understand that openAI is only involved AFTER the search chunks are retrieved. Is this understanding correct?\n\n@Girish Ahankari  - I understand there may be limitations at scale but even for limited documents, how does this work above?"
    ],
    "spaces/AAAABcXBTWI/threads/NHkori3UGQc": [
        "It‚Äôs a vector search. So top vector matches are sent to OpenAI"
    ],
    "spaces/AAAABcXBTWI/threads/NVVt3W_sHbQ": [
        "The current embedding model we are using is English only however when lesser chunks are there may be it‚Äôs finding the top 5 close chunks"
    ],
    "spaces/AAAABcXBTWI/threads/G_JWSAuvYQs": [
        "We are adding the multilingual embeddings in a week or two then it will be more better"
    ],
    "spaces/AAAABcXBTWI/threads/_Il1h7kIMdU": [
        "Coding is done, we are working on load testing"
    ],
    "spaces/AAAABcXBTWI/threads/f7dNdONNrYE": [
        "Can a customer create multiple Apps on SearchAssist even when they¬†have a single UseCase.\n\nA customer who has purchased SearchAssist asked our Sales exec during a call whether¬†they can create multiple¬†Apps so that they can make it easy for their employees¬†to search using guided flows of XO Platform.\nThey want¬†to have FAQs and documents on various products, IT helpdesk related docs, managed on different SearchApps and call the SearchApps from XO using API by guiding¬†through dialog tasks to narrow down search and FAQs. And, our Sales responded that yes they can create multiple apps without any issues.\n\nI can understand it is technically feasible but is it allowed or does it have any risk associated in future examples when Unified XO Platform will be released?",
        "Hello Sandeep, there is no restriction on the number of Apps created.\n\nHowever, this will increase the maintenance for the customer as any changes done in one app needs to be done e in another app too.",
        "What is the license deal here? Have we sold license per App or there is no limit of the number of Apps to be created by the customer?",
        "Hi Girish, thanks for the comments. I will need to check the licensing with Sales but what I know is they have sold Platform which comes with all components like Search And voice. In the new licensing there is no mention of Search App. The new licensing only says Platform and then if you use Search or voice it will be additional sessions which I understood.\n\nbut thank you,  I understood your points on maintenance and from the technical point of view."
    ],
    "spaces/AAAABcXBTWI/threads/b1XWDf1dclY": [
        "We need to have a proper documentation or video tutorials on Custom scripts and Workbench. \nIts difficult to work on Workbench and Custom Scripts without knowledge articles.\n\nSome examples like\n1. How to create facets from scratch\n2. How to add facets from Files content like searching a pattern of data and making it as a facet\n3. How to add facets from Structured data etc\n4. How add facets from FAQ\n5. Any other things other than facets.",
        "Sure, @Aditi Bhadouria can you work with the documentation team on this please all my with @Rohit Tambe"
    ],
    "spaces/AAAABcXBTWI/threads/H8ML2EAHV1I": [
        "Sure Girish"
    ],
    "spaces/AAAABcXBTWI/threads/_Y85u0tj71E": [
        "Can Business Rules be used with Answer Snippets within SearchAsist?",
        "Yes, \n\nIt's still in beta. You can name a business rule starting with \"vi_\". Such rule will be applied only for answer index /snippets. The business rule should be defined on the field which is present in the snippet.",
        "@David Gwartney PFA on how to write business rules on Answer snippets \nhttps://docs.google.com/document/d/1u01vB-d8-Wb-weBkMVOFT8rFACq-_lVKVr5OJ3UCVq4/edit?usp=sharing"
    ],
    "spaces/AAAABcXBTWI/threads/JpTui_OlbkQ": [
        "Team - Do we have a new NLP benchmarking report especially for few shot, model against top competitions (MSFT azure, dialogflow preferred ), if yes, please help with the same"
    ],
    "spaces/AAAABcXBTWI/threads/bBMm-s1tk90": [
        "@Varun Vaidya please ask this in XO platform space",
        "Okay"
    ],
    "spaces/AAAABcXBTWI/threads/BOyOzkcAS_w": [
        "Is there any difference when searching documents pdf, ppt, word files, uploaded to SearchAssist vs searching documents from Sharepoint, drives etc(using SearchAssist connectors). If we have any document which can highlight those points will be very helpful. Thanks",
        "@Sandeep Singh Rana There is no major difference, as all this data is ingested into the same index and then queried over. Please let me know if you're facing any specific issues related to this.",
        "@Aditi Bhadouria , I have seen when we upload docs like PPT or docs etc those files gets downloaded instead of opening on browser. Do we have the same behavior when we use Sharepoint, or other drives.\n\nThe other thing is I have read somewhere that for ServiceNow or Salesforce we support only knowledge bases. \n\nAlso, does it depend on the type of connector we are using that something will be extracted but other will be excluded. Example for some connectors we may not be supporting docs or excel file but for some we may ?",
        "Yes, different MIME types are supported based on what the connector supports. This information is available in the documentation. Please note this has to do with ingestion. Once the data is ingested, there is no difference in searching over it. \n\nRegarding behavior on clicking on the references(Please see the image), if it's a connector/webcrawl same link will be shown that is the source of truth. So user will have to login to Sharepoint/Confluence etc as that document is not publicly accessible. If it's a publicly available domain login is not required. Additionally, for the documents that have been uploaded manually by the user we provide the link for downloading that document in the references as there is no sourceurl attached to it.",
        "@Aditi Bhadouria , thank you very much. Understood!"
    ],
    "spaces/AAAABcXBTWI/threads/z_mAdJn6M_8": [
        "@Rohit Tambe @Aditi Bhadouria can you answer this?"
    ],
    "spaces/AAAABcXBTWI/threads/bEWZNtHyYeQ": [
        "What can be done with SearchAssit SDK. We know a lot about XO platform SDK. \nBut how much modifications can be done with SearcgAssist SDK. Can the customer create  search interface according to his needs  using the SDK?",
        "Sandeep, did you see this? it provides a basic intro https://docs.kore.ai/searchassist/search-experience/interface/"
    ],
    "spaces/AAAABcXBTWI/threads/V2gZkVxjJNU": [
        "Hi Laurence, Yes, I have seen this. My question is how much more we can customize besides this. \nExample can I add any wallpaper as a background when choosing browser based interface.\n\nSecond, can I customize the interface in a way where I can add an other app UI within the search Interface etc. \n\nAny other customization.?",
        "SDKs are reference implementations. U can customize whatever u need",
        "Girish, Thanks! I understood. I am trying to gather all the information as we have a call with Toyota Motors and we have some competition left from Amazon kendra and Yext. This will help me answering questions confidently."
    ],
    "spaces/AAAABcXBTWI/threads/aNNs0S81HLE": [
        "Can the customer build their own connector in SearchAssist to connect to their own DMS to retrieve the documents for Document AI purposes?",
        "Currently, we don't have custom connector support. It is part of the SeachAssist roadmap."
    ],
    "spaces/AAAABcXBTWI/threads/f92IDRJbysg": [
        "Hi Team, Thomson Reuters needs to enable Azure openAI GPT 3.5 Turbo model for searchAssist. With the current documentation for integration we have a mandatory API Version field . Is that still relevant ?",
        "@Rohit Tambe pleaze check",
        "Yes, API version is required for configuration. Please refer the document- https://docs.google.com/document/d/1nJqjbvAM4ov4cj_wI902XimdxTg-SC7oXrjYL4lM9bw/edit. \nwe are working on updating the documentation page."
    ],
    "spaces/AAAABcXBTWI/threads/EeMgILiZMxk": [
        "Hi team, I was asked by a prospective customer \"Is searchAssist compliant with the Web Content Accessibility Guidelines (WCAG)?\" I am aware that platform is compliant with WCAG but not sure of Search Assist. any idea ?",
        "We will comeback on this @Su Hyeok Seong",
        "@Aditi Bhadouria can you take this up please",
        "Is the requirement for the application itself or the end user sdk? \nIf it‚Äôs for the application will need more time to get back to you on that.\nIf it‚Äôs for the sdk it is entirely customisable by the client and hence shouldn‚Äôt be a problem.",
        "this question is about application. and do we provide mobile sdk ?",
        "SearchAssist application is not WCAG compliant. We don't currently have support for mobile SDK.",
        "Thank you Aditi"
    ],
    "spaces/AAAABcXBTWI/threads/bO0q1FT2E_k": [
        "Now that the v2 agent assist widget is required, will we be removing the word \"Beta\" from the widget? Ignore this question üôÇ",
        "Wrong space.  You may want to ask that in XOCC - SmartAssist + AgentAssist (this is SearchAssist)"
    ],
    "spaces/AAAABcXBTWI/threads/HhahFrA7BH4": [
        "Thanks Tim, the 5 million spaces with the word XO in it may have made me misclick üôÇ"
    ],
    "spaces/AAAABcXBTWI/threads/yZARoz-0268": [
        "Can we support 12K documents for a Bank in an extractive model?",
        "@Gopi Polavarapu there is no limit on the number of documents we can support. The challenge is only during ingestion. Once ingested, there is no limit on the documents. We have have to review the type of document and come up with ingestion methodology"
    ],
    "spaces/AAAABcXBTWI/threads/qlJF61uC79U": [
        "Can we provide a document on what is support and what is not?",
        "We are continuously adding more support. However, we have a document with guidelines which are supported. Will share the same in a folder and share the link here tomorrow"
    ],
    "spaces/AAAABcXBTWI/threads/ClJQiFqr_PA": [
        "We are also working on an external utility on top of what was built for Alaska, which can be used by anyone to extract data from the documents and add any logic to it as it will be made available in our git first internally and then might open source it"
    ],
    "spaces/AAAABcXBTWI/threads/85O7amLxNWY": [
        "PNC is coming fast..we need to know what could be done with extractive vs generative"
    ],
    "spaces/AAAABcXBTWI/threads/WrfiIuz0Y6Y": [
        "SearchAssist Language Support\n\nHi team, I've posted this in multiple areas, apologies if you're seeing a duplication but will need some fast answers. \n\nWe have a number of late stage deals in Europe that have language requirements over and above what is already supported in SearchAssist. A few urgent questions we have:\n\n1. We need to know what the language roadmap is for SearchAssist. (Justeat, for example, requires the following languages by June 2024: French Canadian (Quebecois), Dutch, Hebrew.¬†\n2. Can we accelerate language development like Dutch (Both¬†JustEat¬†and¬†Leaseplan¬†require Dutch).\n\n3.¬†Lunar Bank¬†requires Norwegian, Swedish and Danish. What are the timelines to develop these languages?¬†\n\n4. What is our fallback solution where there is no language support in SearchAssist, anything we can do with translation engines?",
        "@Laurence Schoultz we will be adding many languages by end of Jan‚Äô24. We will priorarize the list of languages you mentioned. Some are already part of it. I am sure all the languages you mentioned will be covered by end of June‚Äô24 in our cloud",
        "Thanks @Girish Ahankari",
        "@Girish Ahankari Are these languages included? I created an FR for them as well.  \n\nArabic Japanese Malay Thai Turkish Vietnamese Chinese Filipino  CC: @JD Maloney",
        "Hi @Girish Ahankari , was curious and wanted to know latest status with Japanese language. You mentioned in one of the thread which I am unable to find, that it will around December. Do we have any release this month. We will have Toyota POC from Feb 1st Week and we need it to fully support Japanese."
    ],
    "spaces/AAAABcXBTWI/threads/3B7khLLP0d8": [
        ".doc documents are displayed with PDF icons. fyi",
        "@Andy Pham we will fix this asap"
    ],
    "spaces/AAAABcXBTWI/threads/fwvKTpav8bg": [
        "About Open GPT-4, inside SearchAssist.\nDo we have a roadmap for implementation?\n\nSuperthanks!"
    ],
    "spaces/AAAABcXBTWI/threads/rjrIqa92yYk": [
        "Yes, we should have it by 2nd week of December"
    ],
    "spaces/AAAABcXBTWI/threads/qfksneBpEu8": [
        "Here is the sheet that Santhosh has created to provide a timeline/product version of the differentiating features of RAG \n\nhttps://docs.google.com/spreadsheets/d/1yFhfE8pbUsrGOWIt93SPiuqbTdmF7ePKhTvXZBi4WYA/edit#gid=0"
    ],
    "spaces/AAAABcXBTWI/threads/vCDiMuuG208": [
        "Can‚Äôt access https://searchassist-pilot.kore.ai/ environment. Need immediate assistance for a demo in one hour."
    ],
    "spaces/AAAABcXBTWI/threads/5kJha8MfjTY": [
        "I am currently in there @Andy Pham and don't have any issues?"
    ],
    "spaces/AAAABcXBTWI/threads/QmH9bx5R1Jg": [
        "try https://searchassist-pilot.kore.ai/home/",
        "Looks like we changed the URL. That works! Thank you so much."
    ],
    "spaces/AAAABcXBTWI/threads/N8zQGH1tFvM": [
        "Wait... it doesn't DEFAULT to home via DNS Record?",
        "No, there is some other issue and we've brought the matter to attention and are actively working on it. In the interim, please utilize the following URL: https://searchassist-pilot.kore.ai/home/"
    ],
    "spaces/AAAABcXBTWI/threads/caGB_Geg-ls": [
        "It should. I haven‚Äôt had any issues until today."
    ],
    "spaces/AAAABcXBTWI/threads/bTSA5RcZQuc": [
        "Do we have any plans to support XBRL?",
        "@Andy Pham can you provide more information like who needs it, why do they need it, what can be the business value if we add the support?",
        "@Girish Ahankari As per our brief introductory call, CBRE seek an internal solution for finance, procurement and HR, supporting their current file formats. With a demo on Friday, I expect this question to come up. CC: @Shawn White @Shaun Fiedler"
    ],
    "spaces/AAAABcXBTWI/threads/NFTb_8HX9QA": [
        "Can anyone from the SearchAssist team explain about the dynamic facets features which is in roadmap. How will it work ? I need to know about this because we have a customer meeting and they think the current custom facets is too difficult as it requires coding etc any two three lines of explanation will be sufficient for the dynamic facets.",
        "Dynamic facets refer to the dynamic display of relevant facets or filters based on the search results. Instead of having a static set of facets, the system adapts and shows facets that are relevant to the current search.\nFor example, a product search use case has the below facets configured- product category, color, and capacity.\nQuery: show me an LED TV\nStatic filters: All 3 configured filters will be displayed, and non-relevant (capacity) filter is also shown \nDynamic: Relevant filters only (product category & color) will be shown",
        "Hi Rohit, thank you for the explanation, I understood."
    ],
    "spaces/AAAABcXBTWI/threads/y4LdjDWciUk": [
        "Currently when we create a directory only one folder gets created. Are we going to have a directory structure which allows us to create sub directory? Is it in roadmap or should I raise a feature request?\nWhen a customer wants to upload different versions of same documents having sub directory will help them manage properly and also useful when filtering based on directory.",
        "Hi Sandeep \nPlease create a FR for this. In the meantime, you can create different directories to manage versions, products etc.",
        "Hi Aditi, thank you for your prompt response. I will raise the FR then."
    ],
    "spaces/AAAABcXBTWI/threads/EUUn3UGq6Rc": [
        "With the coming of the Unified XO Platform. Should we be steering customers/partners to leverage SearchAssist when setting up FAQ scenarios rather than what we have available in XO Platform today?",
        "@all I have a call later today where we will be discussing FAQ configuration/setup. What are this teams thoughts on this?",
        "Yes Jon that is correct. We plan on adding the FAQ feature from Knowledge AI in Platform to the Answers section of UXO",
        "Great. Thank you Aditi.\n\nAre there things we should show at ALL in XO or just solely focus on features found in SearchAssist today?",
        "I would say that depends on the use case. On a high level XO is going to retain all its features in UXO. So it‚Äôs always a good idea to showcase those features. Also ‚ÄúAnswers‚Äù in UXO will provide users with more control over the entire RAG pipeline and we have a lot more features planned for the roadmap. You can highlight that as well. You can refer to the product tracker sheet for the details of the same",
        "Can you share that link pls?",
        "https://docs.google.com/spreadsheets/d/1A9AMp6_zhxNZij47TFcLR-iJZSt2R-2DbxAFji45BVM/edit?userstoinvite=krista.king@kore.com&sharingaction=manageaccess&role=writer#gid=640620276"
    ],
    "spaces/AAAABcXBTWI/threads/cERq_vLOVVk": [
        "This issue is fixed."
    ],
    "spaces/AAAABcXBTWI/threads/NjYqcuVDg3g": [
        "I‚Äôm curious to learn what the recommendation is for setting up faqs on the unified xo",
        "@Gurpreet Singh we will be sharing that soon. We‚Äôll update in this space accordingly"
    ],
    "spaces/AAAABcXBTWI/threads/8NT-Yabhnb0": [
        "I'd like to think so, unless a particular language is not supported within SearchAssist."
    ],
    "spaces/AAAABcXBTWI/threads/ILuI9pnR5fQ": [
        "This is a quick summary of the different capabilities of SearchAssist/Answers.",
        "@Santhosh Kumar Myadam thanks for this, very useful. For further clarification, on point 3.4 (Generative Answers), it was my understanding that the original user input also gets sent to GenAI (OpenAI)? If so, is this post PII processing, so all sensitive user info can be redacted/hashed?"
    ],
    "spaces/AAAABcXBTWI/threads/aBAA7jrontk": [
        "Yes, that is correct. In generative model we send the user query to the LLM. While currently, we don't have PII anonymization, it is planned to be available with UXO as part of \"Answers\""
    ],
    "spaces/AAAABcXBTWI/threads/jRjFstWogoY": [
        "I was told their was a deployment today on the pilot environment. When I try to call the full search API the calls fails with a 500 status code:\n\n+ curl --location --request POST https://searchassist-pilot.kore.ai/searchassistapi/public/searchAssist/stream/st-8d57e371-49a3-5543-8682-abd7dbd59041/st-8d57e371-49a3-5543-8682-abd7dbd59041/fullSearch --header 'auth: eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJhcHBJZCI6ImNzLTFjZTZjNThhLTBiN2MtNWI2YS1hNjliLWI5YzI2ZjY0NmM4MyJ9.yjlsQe5adZwazXEopiK7Jt9h7PVD0K094vhsG5slS8Y' --header 'Content-Type: application/json' --data-raw '{ \"query\": \"What functions does MMS provide?\", \"maxNumOfResults\":4 }'\n{\"errors\":[{\"msg\":\"Internal Server Error\",\"code\":500}]}%¬†\n\n\nSame query against the preview works:"
    ],
    "spaces/AAAABcXBTWI/threads/FFrc8GtjoNE": [
        "Hi David , \nThere was a critical fix deployed, \n\nWe can train the app for fix"
    ],
    "spaces/AAAABcXBTWI/threads/G_3huuFHyUI": [
        "What is the IDP callback URI for pilot environment? @Surendra Subhash Salke",
        "https://staging-bots.idp.korebots.com/workflows/callback"
    ],
    "spaces/AAAABcXBTWI/threads/dlIGVgceTvc": [
        "All, I'm accessing SA through a VA and the query response back to the bot contains four \"answer fragments\". However, the message node only presents back the first fragment. Has someone written the code to display all returned fragments?"
    ],
    "spaces/AAAABcXBTWI/threads/Md7GVjAwz58": [
        "Can someone from the SearchAssist team explain the indexing capabilities? For instance, if a user uploads two PDF files‚Äîone with fewer texts and another with extensive content‚Äîwould SearchAssist treat both pages equally? What is the limit or maximum number of texts that can be considered as 'a page' ?",
        "For PDFs, each page of the pdf will be treated as a document. This document count is used as a threshold on the total indexed content.\n\nFor answering, the content from these pages is further broken down into smaller chunks. Chunk size can be configured. We create vector representation of each of these chunks so that we can retrieve them based on semantic similarity. For vectorizing, we use open source LLM embeddings. There is no cost involved here. \n\nFor a given user input, we retrieve the relevant chunks based on vector/semantic similarity. The qualified chunks along with the user input are sent to LLMs for answer generation. LLMs calculate the cost based on size of the prompt in terms of tokens used in request and response. So, for every call we make, LLM will calculates the cost based on the prompt (includes instructions, chunks, user input) and response (answer). \n\nDetermining the right chunk size is an important aspect. Larger chunks usually result in better coverage of the answer. However, larger chunks will result in higher cost and in some cases, the models may not be fully grounded  with larger context sizes. \n\nSmaller chunks may not provide better answer coverage. They will result in lower cost and more grounded. But the answer quality may not be satisfactory. \n\nSo, enterprises will need to experiment for the optimal chunk size based on use case."
    ],
    "spaces/AAAABcXBTWI/threads/EwURo1H3xLo": [
        "It will split into chunk (fragment) .. you can upload to the SearchAssist and use the Chunk editor and got the ideas.. it is not based on number of texts but just the meaning of the content",
        "I thought chunk was for LLM usage (DocumentAI)... would a document search will use the chunk as well ?"
    ],
    "spaces/AAAABcXBTWI/threads/W4H8iQ6clew": [
        "we use the vector DB"
    ],
    "spaces/AAAABcXBTWI/threads/p4a4y071T6Y": [
        "and cosine similarity for matching"
    ],
    "spaces/AAAABcXBTWI/threads/yxk-TpNbZfg": [
        "got it.. document searching is using other approaches... @Surendra Subhash Salke any thoughts?"
    ],
    "spaces/AAAABcXBTWI/threads/Q1qH5NRcqzY": [
        "I'm unsure about the specific details of the following statement: 'This document count is used as a threshold on the total indexed content.' Could you provide a more detailed explanation? Also, to clarify, based on my understanding, whether a page contains just one text or 2000 texts, both cases are considered as a single page (document). Is there a maximum limit on the number of texts a page can contain?"
    ],
    "spaces/AAAABcXBTWI/threads/orHUkiLr2Go": [
        "What is the background of this question. This helps in providing better response.",
        "This started with a simple question - a customer is willing to know the definition of a page. especially, the max number of texts of a single page."
    ],
    "spaces/AAAABcXBTWI/threads/i1gnPGyPU3E": [
        "How can we setup 2 Factor authentication on SearchAssist? Example using OKTA or any SAML provider?\nI can see we have options like Google Account or Microsoft and Linkedin to login from home page.",
        "@Girish Ahankari We have support for IP Address restriction and SAML setup available with XO but I cant see the same on SearchAssist side can you please help me in understanding if we support these or not with SearchAssist? If not are these in Roadmap and ETA?"
    ],
    "spaces/AAAABcXBTWI/threads/uALe-KtQCHI": [
        "Search Assist behavior question. Has anybody seen a case when crawling pages with input URLs via a CSV that had loaded several thousand pages near end the end of its crawl and then when the crawl stopped there were only a fraction of pages available. I went from 3420 last night to only find 22 pages have been crawled this morning. I have no idea how that occurred since there are no logs available to see what happened.",
        "I was seeing very strange SA behaviours yesterday evening with crawling, but it seems to be working now."
    ],
    "spaces/AAAABcXBTWI/threads/jFcAh2F3Ec8": [
        "During today‚Äôs SearchAssist demonstration, the prospect expressed suspicion due to the rapid bot responses, especially with generative search. They requested components and sequence diagrams. What information can we disclose? We do have an NDA with them. cc: @Shawn White @Shaun Fiedler"
    ],
    "spaces/AAAABcXBTWI/threads/7K9EE05BU0U": [
        "Who is the prospect?"
    ],
    "spaces/AAAABcXBTWI/threads/4ec8aOOd9vw": [
        "Also explain what have you demonstrated"
    ],
    "spaces/AAAABcXBTWI/threads/uc_TvZ5q6Xk": [
        "What configurations did you do in the SearchAssist application"
    ],
    "spaces/AAAABcXBTWI/threads/vQiYU-Pq_Uc": [
        "The initial diagram which we had shared should work",
        "Which initial diagram? The one you found online? @Girish Ahankari",
        "It was a standard app with 7 PDFs. I'll DM details on the app and the utterances I used when I'm in the office tomorrow. SearchAssist was fast and responsive.",
        "I shared it in this thread and refereed slide too",
        "Are these supported today? Where do I choose my choice of vector database and GenAI?",
        "How can we determine what is available and what isn't from the shared PPT? Was the meeting with Forrester recorded? @Girish Ahankari \nCC:  @David Gwartney"
    ],
    "spaces/AAAABcXBTWI/threads/kOOxs118E5U": [
        "Slide #14 from https://docs.google.com/presentation/d/1y9cmWTFdzmiYEGPMoOpEhXAOxCx8g_GyqXt3O0RBxmU/edit"
    ],
    "spaces/AAAABcXBTWI/threads/B6OyenUB9qQ": [
        "How do I report an issue with documentation for SearchAssist?",
        "@Prabhat Singh leads the documentation team. Feel free to reach out to him",
        "@Umang Shah I raised a ticket and it was addressed that way."
    ],
    "spaces/AAAABcXBTWI/threads/z-ejhhf4p2Y": [
        "Hi all, I am getting this question from a partner, I looked in documentation could not find anything, I looked in resources did not find anything, I also searched in this chat and found couple of people asking but not clear answers, please point me to the answer and/or provide and answer here? Thanks in advance for your help: \n\nWhat is the architecture / flow of handling multiple language documents and queries for Kore.AI . Question related to uploaded document can be asked in English/Spanish. Can Kore.ai process the Spanish document and answer the asked questions in English ?",
        "Hi Julia\n\nThis is the current flow for using multiple languages for the answers functionality in SearchAssist. \n\nIf the user is uploading documents in multiple languages or any other language apart from English. We change the embeddings to LaBSE and index the documents. Now at runtime when the user is asking a question (in any language) we convert it to a vector and perform a vector match. We then pass the qualified chunks along with the query to the LLM. So depending on the LLM you are using and the no of languages it can handle we can achieve what you have mentioned. We just need to tune the prompt to the use case.",
        "Thank you!",
        "@Aditi Bhadouria what embeddings models are used to convert end user query to vectors? @Rohit Tambe",
        "MPNet for English only use cases and LaBSE for multi lingual",
        "Assuming, these embedding models are multi-dimensional, how many dimensions do we support?",
        "Number of dimensions is not a limitation. It depends on the model. Both the above models are 768 dimensions.",
        "Thank You Aditi!!"
    ],
    "spaces/AAAABcXBTWI/threads/lM-Wjc86ID8": [
        "Can someone please confirm that the Search Assist documentation is incorrect? The JWT token should include the \"ClientID\" as the \"appId\" and not the \"AppID\" as described? Can we make the terminology any more convoluted?",
        "This is now corrected by documentation team."
    ],
    "spaces/AAAABcXBTWI/threads/Cp8DWmPfVS8": [
        "Agree! The value is your client ID, not App ID. However, the key is correct, \"appId\"."
    ],
    "spaces/AAAABcXBTWI/threads/cdfiuUFcukw": [
        "\"appId\": \"Insert your client ID here\""
    ],
    "spaces/AAAABcXBTWI/threads/Ely_6R9JqWk": [
        "Thanks Andy! Funny that the VA JWT include the \"sub\" : \"1234567890\" along with the \"appId\" : \"...\". Not consistent across functions"
    ],
    "spaces/AAAABcXBTWI/threads/nw5JMiKU1VM": [
        "I don't remember using \"sub\"."
    ],
    "spaces/AAAABcXBTWI/threads/L-s03gsmtFg": [
        "@John Nicholson I saw the same error today and have reached out to documentation team to report the issue."
    ],
    "spaces/AAAABcXBTWI/threads/_ffh6HSS3yk": [
        "@John Nicholson i follow this https://docs.google.com/document/d/1AY04sMQ_PBHsCYPRLa0WoaiHHJng7RVq42eHG4H6pUE/edit#heading=h.yk4aifctzhit",
        "FYI... @Martin Anibal Bonardi you might want to update this note so that users realize the imported bot is set for \"Standard\" NLP. After much confusion over it's inability to recognize intent, I realized the setting was not correct and changed to \"Few-Shot\""
    ],
    "spaces/AAAABcXBTWI/threads/JmdAMGV2260": [
        "@Martin Anibal Bonardi customers are using this documentation and they reported this issue."
    ],
    "spaces/AAAABcXBTWI/threads/BBINZWiYmfM": [
        "Pls report this to @Santhosh Kumar Myadam"
    ],
    "spaces/AAAABcXBTWI/threads/tK4oo5Mfwgo": [
        "@John Nicholson When I have a moment, I will look at the documentation; below is what I use for my VA."
    ],
    "spaces/AAAABcXBTWI/threads/OLGAU67y8_o": [
        "In any event, what we really need is a straightforward method to generate tokens. Here is an example. An easy button to create, track, and delete."
    ],
    "spaces/AAAABcXBTWI/threads/_UykW8KfGLc": [
        "@Girish Ahankari üëÜ",
        "Thanks @Andy Pham will work with PM team on this."
    ],
    "spaces/AAAABcXBTWI/threads/VSPUV9M6hSM": [
        "Can we use Search assist to connect to a SQL data warehouse?",
        "This is part of our roadmap, but not currently available"
    ],
    "spaces/AAAABcXBTWI/threads/8qM6KRJyXj8": [
        "As per the Kore.ai documentation,¬†LLM and Generative AI - Kore.ai Documentation, currently there is restriction on number of documents to be uploaded ( Max 10) and size (only 5 MB). How do we handle the PoC scenario for more documents . Do we need to create a custom solution?"
    ],
    "spaces/AAAABcXBTWI/threads/av943Dgx5bk": [
        "https://developer.kore.ai/docs/bots/bot-builder-tool/knowledge-task/answer-from-documents/#Test_Answer_Generation. As per the Kore.ai documents, there are some limitations for this feature and it is still in beta phase.¬†They are not recommending this feature for the production purpose.\nWhen is the plan to release this feature to production",
        "Newer version in UXO will be available as GA. @Santhosh Kumar Myadam @Hariharan Velusamy",
        "@Julia Navarro this question should be asked in XO and not in XO Answers"
    ],
    "spaces/AAAABcXBTWI/threads/S7GmxpGdxvk": [
        "@Julia Navarro Use search assist the document size is larger (10 MB) and the number of documents in not restricted to 10.",
        "thank you so documentation is wrong or not up to date?",
        "@Julia Navarro as I have mentioned in the mail, XO platform and SearchAssist are two different products. Each has its own documentation. Please refer to SearchAssist documentation. It is updated accordingly. Otherwise you can post this questions to the XO platform team",
        "This is SearchAssist documentaion https://docs.kore.ai/searchassist/",
        "This is the link you have mentioned which is from XO platform https://developer.kore.ai/docs/bots/bot-builder-tool/knowledge-task/answer-from-documents/#Test_Answer_Generation",
        "Yes, I have seen the limit move several times. It is really a soft limit since depending on the deal it can be changed.",
        "BTW, You can use tools like poppler to divide large PDFS on page boundaries to get around the limits.\n\nYou can install on a Mac with https://formulae.brew.sh/formula/poppler",
        "This installs command line utilities to separate and join PDFs. Here is the list of utilities that are installed:\n\n/opt/homebrew/Cellar/poppler/23.08.0/bin/pdfattach\n/opt/homebrew/Cellar/poppler/23.08.0/bin/pdfdetach\n/opt/homebrew/Cellar/poppler/23.08.0/bin/pdffonts\n/opt/homebrew/Cellar/poppler/23.08.0/bin/pdfimages\n/opt/homebrew/Cellar/poppler/23.08.0/bin/pdfinfo\n/opt/homebrew/Cellar/poppler/23.08.0/bin/pdfseparate\n/opt/homebrew/Cellar/poppler/23.08.0/bin/pdfsig\n/opt/homebrew/Cellar/poppler/23.08.0/bin/pdftocairo\n/opt/homebrew/Cellar/poppler/23.08.0/bin/pdftohtml\n/opt/homebrew/Cellar/poppler/23.08.0/bin/pdftoppm\n/opt/homebrew/Cellar/poppler/23.08.0/bin/pdftops\n/opt/homebrew/Cellar/poppler/23.08.0/bin/pdftotext\n/opt/homebrew/Cellar/poppler/23.08.0/bin/pdfunite"
    ],
    "spaces/AAAABcXBTWI/threads/vvcp1ejQtjg": [
        "Question: What does it take to contextualize conversation within SearchAssist, and from the XO bot that queries searchassist?  For example, I pull information from a document about 3 products. I then want to ask a followup like, Can you give me the price for the first one?",
        "Hi Gurpreet \n\nCurrently, we have a custom config that rewrites the user's current query in the context of previous queries or in the context of previous conversation(queries+responses).  \n\nWe are working on adding the conversation history as a variable value in the Gen AI prompt itself to further facilitate this and avoid making 2 calls. \n\nWhen we move to UXO, the query will be transformed appropriately as the first step and then only passed to any other modules(Automation/Answers). This will solve the current issue of separate history being maintained in XO and SearchAssist.",
        "OK thanks @Aditi Bhadouria ! I will try this out."
    ],
    "spaces/AAAABcXBTWI/threads/k-_Yy5pIUxM": [
        "There is a limit on file size  supported by SearchAssist till 15MB but does that same apply for Sharepoint and other connectors? I have aksed this question previously over  a call and that time I got the response that all have 15MB limitations. but I have a doubt because when I enabled Sharepoint connector today I can see files which are 30 MB or so .\nThats why Just wanted to confirm again. Thanks\n\nexample the first one is around 27.8 MB and is about XO platform"
    ],
    "spaces/AAAABcXBTWI/threads/vXgikJmN4mU": [
        "@Sandeep Singh Rana can you tell me which customer is looking for this and which other products is the customer using.\n\nAlso let us know the usecase which customer wants to implement. Which connectors are they planning to use",
        "Hi @Girish Ahankari , \nToyota Motors a prospect and is considering SearchAssist they will start POC next year January or 1st week of February. We cleared many rounds of competition with local vendors we have done multiple demo for them and had many meetings and they have choosen us along with Amazon kendra and Yext for POC. Our product and other two will be evaluated, before that they have been confirming various things like security and limitations. They also have various data sources where they store data example Sharepoint, Amazon s3 , Salesforce, and a custom Search product built from scratch for them internally. As the current Search product is legacy they want to move to a new product with new set of capabilities. etc. The file size limitation may be a blocker as other product have no such limitations.\n\nThis is a call center Use case where Toyota customers call them for issues related to Cars. Questions can range from cars sold in 80's or 90's to latest models. Salesforce integration will also be required to get customer information etc. Other details can be shared over email with you."
    ],
    "spaces/AAAABcXBTWI/threads/sSPvixmDTLA": [
        "@Sandeep Singh Rana Same setup works for SearchAssist also. Just try logging with the configured emailId in search assist.",
        "Hi Rohit, Can you please explain in more detail what does configured email means? Thanks",
        "So, once you configure SAML in xo admin portal and add user for SAML login. You can use same user for searchAssist also to do that SAML Login.",
        "I see, Thank you very much. We should highlight these points on our docs portal for SearchAssist also.",
        "Oh! I gotta try. Does that apply to other solutions, such as SmartAssist?",
        "@Rohan Chaurasia",
        "@Andy Pham  For SmartAssist yes!! One of our customer has enabled it. \nFor Search I was not sure until now.",
        "I believe you; I will try them when time permits. üòâ",
        "not to thread hijack, but we've been unable to get this to work with SmartAssist due to differences in the idp endpoints. I've had a ticket open on this since August - https://koreteam.atlassian.net/browse/PLAT-21597"
    ],
    "spaces/AAAABcXBTWI/threads/ckhrVOU1apY": [
        "Can we export the SearchAssist App just like we can export the XO Platform bot?"
    ],
    "spaces/AAAABcXBTWI/threads/HqwYXNIqxTo": [
        "@Sandeep Singh Rana we can't export the full app configuration directly, but SA has support of import/export of index configurations and import/export of sources which covers the major part of the searchassist",
        "Hi Akhil, thank you for the confirmation."
    ],
    "spaces/AAAABcXBTWI/threads/NDEpee3Ltiw": [
        "I know this space is called XO Answers + SearchAssist. One of our clients, Pfizer, wants to use the Answer from Documents feature on XO. Is this something that will come out of Beta with Unified XO? Or will this feature just become a part of SearchAssist? What is the strategy here? What can I tell the client on what they can expect going forward? It's a question I have in general. Since Answers is a search feature, do we still plan to keep this separate from SearchAssist, or combine them?"
    ],
    "spaces/AAAABcXBTWI/threads/id0YZ4CdTZw": [
        "(The same goes for FAQ's. Do we plan to have faqs available for use within SearchAssist as well as on the XO side?)"
    ],
    "spaces/AAAABcXBTWI/threads/aRgyricxRVQ": [
        "@Gurpreet Singh here is a doc which is in draft stage showing the differences."
    ],
    "spaces/AAAABcXBTWI/threads/QxBPMnQ9bes": [
        "https://docs.google.com/spreadsheets/d/1BxemkYmeT0tiQ1vN1Ps2Hs4C5kL6milKtd94VRzVElI/edit#gid=0"
    ],
    "spaces/AAAABcXBTWI/threads/kIA8fSbmxTc": [
        "Ok thanks. It appears that UXO itself will still have an Answers feature outside of SearchAssist. Is that correct?"
    ],
    "spaces/AAAABcXBTWI/threads/hS3WPBQv9wo": [
        "(just like today)"
    ],
    "spaces/AAAABcXBTWI/threads/9MS-4xkrHII": [
        "yes"
    ],
    "spaces/AAAABcXBTWI/threads/umS4zlhRYmc": [
        "Can we change the feedback contents?If not is some advanced Feedback feature in roadmap?\n Currently we only see a thumb up or a thumbs down. Current customer and some prospect wants to have a advanced feedback feature where they can suppose have stars 1 to 5 , have some input fields for commenting etc",
        "The feedback in SearchAssist is primarily against an individual result so that the feedback can be used for improving the results. We support only thumbsup/down for this. We can definitely look at supporting other forms of feedback. Not planned at this moment.\n\nIf the requirement is to get general feedback about the overall experience, you can explore the XO's feedback model. It supports csat, nps and thumbs/up down, with the provision to capture additional inputs."
    ],
    "spaces/AAAABcXBTWI/threads/cAc0PLIy7w0": [
        "How can we track access logs of SearchAssist? Are these logs managed on XO Admin side as I haven't seen any feature which shows time stamp, IP address, who is uploading docs, Who is downloading the docs from SearchAssist, Who enabled the Connector etc etc on SearchAssist side.  \n\nCc @Surendra Subhash Salke this question is from Toyota along with the SAML, SSO integration question which we have asked you yesterday over an email with Satish Kumar. \n\nFor SAML Rohan Chaurasia have answered the question below that if you enable the SAML on XO admin side it will work on SearchAssist side aswell. \nhttps://chat.google.com/room/AAAABcXBTWI/sSPvixmDTLA/sSPvixmDTLA?cls=10"
    ],
    "spaces/AAAABcXBTWI/threads/PkYekuIBfb0": [
        "@Sandeep Singh Rana will check and comeback on this. We are tracking all of this but unsure if the story to show the same in UI is completed or in roadmap.",
        "Hi @Girish Ahankari , any update on this?",
        "@Girish Ahankari , its has been a month since I asked this but there have been no update. \nPlease tell me from where/how we can check the SearchAssist access logs on XO Platform Admin console? \nWhen the partner checked their environment they were unable to find any SearchAssist logs. \nCc  @Hisayoshi Tamaki \nhttps://chat.google.com/room/AAAABcXBTWI/cAc0PLIy7w0/cAc0PLIy7w0?cls=10"
    ],
    "spaces/AAAABcXBTWI/threads/A-IOKRrh77Q": [
        "Do we have a document on using Analytics API similar to what we have for Full SearchAPIÔºü \nCan all Analytics data be exported using this API and linked with Tableau or Power BI?",
        "https://developer.kore.ai/docs/bots/api-guide/api-list/",
        "You can verify. I believe these two tools support JSON files as a data source. Open the corresponding UI, locate the option to connect to data, and select the JSON file."
    ],
    "spaces/AAAABcXBTWI/threads/mcwgeaY3cr4": [
        "@Santhosh Kumar Myadam , Thanks for your previous response. My partner was checking this current feedback feature and saw that when you thumbs down a pop up shows up and you see multiple options as well as a input field. But when you select any option or input any comment that data is not shown on Analytics side. Is this a bug ? \nAlso please tell me if it is possible to edit the options (Incorrect, outdated, others etc)  or it is default and cannot be edited?",
        "Sandeep this is currently default. But customising this is part of the roadmap. Also we will be making answers analytics available soon in the UI",
        "Hi @Aditi Bhadouria , thanks for the info. Can you please give me brief info on what will be available with Answers Analytics?",
        "The query, the answer, along with the count and feedback(thumbs up and thumbs down). This is an initial version. We are working on advanced analytics that will serve as feedback for fine-tuning the application.",
        "We should remove the input field on the negative feedback option. If you use your browser's developer tools to capture the network traffic, that feedback is not sent to our servers.\n\nI had a POC customer who was using it and I had to scramble to come up with an excuse as to why the text comments they had provided with \"thumbs down\" feedback couldn't be found anywhere."
    ],
    "spaces/AAAABcXBTWI/threads/Y8_Yo344uBI": [
        "@Sandeep Singh Rana , this documentation specifically pertains to the XO Analytics API and does not encompass the SearchAssist analytics API. We will check with the PM team to acquire the relevant documentation and promptly share it with you."
    ],
    "spaces/AAAABcXBTWI/threads/yKFTDqegJa4": [
        "Folks, I have the following project in progress:\n\nThe client has 8 bots, 8 different WhatsApp numbers, in a single Zendesk instance to make the transfer to the agent.\n\nThe starting point and whether we can do the same is in the flow (using universal bot, identifying the origin of the number and deriving it for the specific flow?\nOr we can only have 1 Kore bot, for 1 Zendesk instance.\n\n\nThanks!\n\nProject in production!|"
    ],
    "spaces/AAAABcXBTWI/threads/a6D3p1auL-I": [
        "@Martin Anibal Bonardi i think this should be posted in the ‚ÄúXO platform‚Äù group. This is SearchAssist group.\n\nLet me know if ur query is related to SearchAssist and I missed any point. Happy to help"
    ],
    "spaces/AAAABcXBTWI/threads/xr0FZtljpmQ": [
        "Thanks Girish! I see XO Answers, so...but , thanks!",
        "Nice. Martin, XOAnswers refers to Answers from Documents feature!"
    ],
    "spaces/AAAABcXBTWI/threads/c3k_UjB_PSQ": [
        "The Alaska Search Assist bot has type ahead. If you type in \"co\"  some options come up:\n\nDoes the demo have access to the new SDK to enable this search ahead feature? Thanks",
        "This can be done. Demo team, can you please help Kevin?"
    ],
    "spaces/AAAABcXBTWI/threads/YrE_65jauSY": [
        "Please don't use the Alaska Search Assist bot too much - it is live production - it is being measured for reporting"
    ],
    "spaces/AAAABcXBTWI/threads/ShctCOXIwx4": [
        "Can someone help me understand why the response coming back in Search Assist is showing within the \"file details\", but is not getting summarized?  I have an open AI key and the generative model enable, the custom configurations are in there and I have trained it.  Is there something else that needs to be done?"
    ],
    "spaces/AAAABcXBTWI/threads/xZTGmt6CEsg": [
        "move the gen ai config setting higher than the extractive model"
    ],
    "spaces/AAAABcXBTWI/threads/ULxVt2ZjpkU": [
        "(ie. drag it above)"
    ],
    "spaces/AAAABcXBTWI/threads/5-u_OV9KylY": [
        "Yup - did that.  I don't have extractive enabled at all."
    ],
    "spaces/AAAABcXBTWI/threads/Wc5TG7hiopQ": [
        "I see. üôà"
    ],
    "spaces/AAAABcXBTWI/threads/zZpzPkBnUsU": [
        "@Todd Lewis Wasnt this happening last week in Detroit with CU 1?  It wasn't giving an answer just links."
    ],
    "spaces/AAAABcXBTWI/threads/LfNKr2rhX8s": [
        "What was crazy about last week is that I had tested the CBCS bot before I started presenting, and I got a generative response. But when I brought it up in front of everyone it just gave me extracts. I didn't want to chase the problem in front of everyone, so I bailed out by showing the generative prompt that said \"DO NOT INVENT CHUNKS\" in caps.",
        "Hi Todd, \nIf you could help me with the date and time of when this happened and what was the environment, it‚Äôll help me find what went wrong"
    ],
    "spaces/AAAABcXBTWI/threads/3ziUD3WN6lw": [
        "I know nothing about nothing, but...when this happens to me, I open the debugger and check the chunks, prompt and result see what's happening."
    ],
    "spaces/AAAABcXBTWI/threads/R9vcviAMyFE": [
        "it happened to me as well and I create another new account then it works",
        "Does this happen often? Could you reach out to us next time it happens so that we can debug and find the issue?"
    ],
    "spaces/AAAABcXBTWI/threads/Y5zezkboSuY": [
        "I've found that if there are no qualified chunks, it returns a result as shown. I would check to be sure the AI license is valid (and Generative Mode is listed first), that chunks exist and then retrain"
    ],
    "spaces/AAAABcXBTWI/threads/V8ZnmxgAhw0": [
        "Typically, when this occurs, there are no qualified chunks to examine. Last week, I had a situation where an utterance worked one day and ceased to work the next, despite all settings and keys remaining unchanged. The OpenAI key appears to be valid as other utterances seem to be functioning.",
        "Andy, can you please confirm if the 'chunks sent to AI' in the debug payload were same in both the scenarios?"
    ],
    "spaces/AAAABcXBTWI/threads/OAcT-RcEulM": [
        "I can see there are 340 pages of chunking - but it doesn't always return something",
        "Krista, can you please DM me the debug prompt json payload for this query.",
        "Krista can you try reducing the similarity threshold? \n\nEven when chunks exist they should qualify based on a threshold and this is configurable. So if the chunks fall below this threshold they will not show up. \n\nAlso sometimes LLM responds as I don‚Äôt know the answer. When the information we send to llm is not enough. If you check the response section of answer debug you‚Äôll be able to see that. Please check that as well"
    ],
    "spaces/AAAABcXBTWI/threads/ykXIrYe5liE": [
        "@Krista King did you get chance click on debug and see if chunks got qualified for the given input?",
        "@Girish Ahankari I had done that and the times when no answer came back, there wasn't anything in the debugger.  I will try it again and send a screenshot."
    ],
    "spaces/AAAABcXBTWI/threads/JLED_hJ6bc8": [
        "SearchAssist Demo support team, please work with everyone commenting here that they are not seeing responses randomly. Check if the issue is with the default prompt being used for openAI",
        "Sure Girish"
    ],
    "spaces/AAAABcXBTWI/threads/BzWZmFnRDYE": [
        "1. Chunks should be qualified for the given query.\n2. Check if same chunks are getting qualified each time you run the query\n3. If we are finding consistently same chunks, check if openAI is unable to respond due to the conditions mentioned in the prompt."
    ],
    "spaces/AAAABcXBTWI/threads/4-oSwBh0UcU": [
        "I am using the first sentence to demonstrate that there is nothing wrong with the OpenAI credential. The second sentence has no qualified chunk; nothing was sent to OpenAI.",
        "Do you have a query rewrite enabled in this application?",
        "Yes! Do you want me to remove it?",
        "Yes",
        "Out of curiosity, I updated the configuration from conversation to query, and it didn‚Äôt recognize \"library card\". I'm going to remove the rewrite configuration entirely.",
        "I removed the rewrite entry but it didn't solve the issue. I also retrained the app, but the problem persists.",
        "This is the only key configured.",
        "@Surendra Subhash Salke who will be looking into this from our demo support team?",
        "@Surendra Subhash Salke i want to understand why you suggested to disable this. Let‚Äôs syncup today and see if we can write an article on when to use it and when not to.",
        "Andy can you reduce the similarity threshold and try again? Looks like there are no chunks qualifying, so that could be the issue",
        "Where can I find the similarity threshold?",
        "We are working on making all these custom configs available through the UI so it's easier for everyone. Meanwhile could you please try this?",
        "I tried setting it to 0.3, but unfortunately, it didn‚Äôt help. I will try a few other values tomorrow, but if you have any recommended values based on your experience, please let me know. I‚Äôd be happy to try them as well. Thank you!‚Äù",
        "If the documents don't have anything mentioned about using library card as a form of ID, LLM shouldn't answer even if there are chunks qualified. I tried finding it in the chunks, and I couldn't. In that case, this would be expected behavior, right? We don't want the LLM to assume and answer.\n\nLet me know what you think",
        "There appear to be two issues at play here. The first is consistency - there is also no indication that a ‚Äúcredit card‚Äù cannot be used as a form of identification but SearchAssist has no issue answering the question.\n\nThe second issue is that if an institution accepts forms of identification A, B, or C, it can be inferred that forms of identification D, E, or F are not accepted. The response needs to be more informative by letting the user know what forms of identification are accepted. Providing a random PDF file as a response isn‚Äôt helpful for the user.",
        "Just an example ... \"We appreciate you presenting your library card; however, Fulton Bank strictly requires either an A, B, or C form of identification for identification purposes.\"",
        "@Aditi Bhadouria, Please look above for my response to your question. B.T.W., did you access my application and delete the dev_Chunk_Deviation_Percent configuration? I haven‚Äôt made any changes since last night, and this is what I got when I asked if I could use my library card. It‚Äôs hallucinating.",
        "I understand your concern, Andy. As you are aware, we rely on the LLM capabilities to generate an answer from the qualified content as the last layer of the pipeline. So it's not an issue of SearchAssist giving the wrong answer, as it is a well-known fact that LLM's have issues with consistency and hallucination. \n\nIf the problem is that SearchAssist is qualifying different chunks every time for the same query, you can send us the query along with the debug payload, and we will look into what's wrong with chunk qualification. \n\nThe only thing we can do for the consistency issue as of now is to edit the prompt according to the use case. Which is why we have given the user complete control over the prompt, with the option to switch between different prompt versions. \nFor example, you can add more relevant few-shot examples to the prompt(more examples like the one you have provided before). You can also add instructions to the prompt to mention the reasoning with facts and then mention the answer (Also known as chain of thought prompting) \nThere are several different methods of prompting (COT, TOT,COK, etc) that can be employed to improve the LLM‚Äôs performance which one to use will depend on the use case. \n\nSome other solutions we are actively exploring for this issue are: \n1. Guardrails- To not show answers to the users that contain false information \n2. Caching- Caching LLM responses based on certain parameters and showing them to the user instead of making a new LLM call for each query. This will also have cost benefits. \n\nI‚Äôll let you know when these features are available."
    ],
    "spaces/AAAABcXBTWI/threads/GlpCRmvccxw": [
        "What are your thoughts on this? The initial \"yes\" seems to contradict the subsequent no in the response.",
        "This problem is because of the GenAI taking liberty in framing the response to make it conversational. I believe we can prevent this by adding relevant instructions in the prompt. @Riyaz Ahmed",
        "That would be great. It reminds me of the first utterance I shared with you. I don't think the phrase \"based on the provided content\" is necessary. Sometimes it's part of the response; sometimes it isn't.",
        "Andy we‚Äôll try to find a stricter prompt that works in a general sense and doesn‚Äôt hallucinate. \n\nMeanwhile you can edit the prompt yourself so that it works better for this specific use case. You can also write different prompts and switch between them to see which one performs better. You just need to follow the guidelines while writing the prompt ( click on the info icon against the prompt heading and you‚Äôll be able to see the guidelines)",
        "Andy can you find in the documents where the actual answer is and send the screenshot here? We can then check the answer debug to see if qualification is also an issue and probably write a business rule to improve this query.",
        "It‚Äôs in the provided screenshot I shared above. Let me find it in the document for you as well.",
        "Page 4: Retail Manual Account Maintenace (kore.ai)",
        "@Andy Pham any luck that you have improved the prompt to resolve the issue? Could u share the prompt to me as o have the same issue.",
        "no luck",
        "@Andy Pham @Sunny Lun can you please share your app with me for quick  analysis",
        "Let me share the file to u",
        "Later",
        "@Riyaz Ahmed pls refer to this file",
        "the question is \"My wife is pregnant with 27 weeks. do I need to bring a doctor certificate? \""
    ],
    "spaces/AAAABcXBTWI/threads/2J8lHlJ9kLg": [
        "I also have exact same issue. It responds yes but the result contradicts. I will have the demo to show it tomorrow. If there is any way to fix it, it will be great",
        "Looks like it's an issue with LLM's generative response. Can you try editing the prompt to make it follow the instructions more strictly and not hallucinate?",
        "I have added the statement \"do not make the answer to start with 'Yes' or 'No'.. \" but the llm still reply \"Yes,....\"  as above and cause hallucinations",
        "What is the LLM here. It depends on that",
        "Hey @Sunny Lun! I noticed that the new application comes with a new default prompt. I replaced my default prompt with it, solving the contradiction issue.¬†I am going to test the utterance some more between meetings. Give it a try!"
    ],
    "spaces/AAAABcXBTWI/threads/Z4umlznWcB8": [
        "hi...Have we integrated/built any connectors with Omnidocs & server filesystem Storage... ask from prospect",
        "No we don't have this yet"
    ],
    "spaces/AAAABcXBTWI/threads/hISJ8YRC5Ak": [
        "Salesforce Connector Issues\n\nTeam, I'm trying to connect my SearchAssist app (searchassist.kore.ai) to my dev Salesforce instance. I've followed all the steps in the documentation here: https://docs.kore.ai/searchassist/manage-content-sources/connectors/salesforce-connector/ \n\nI'm getting the following error: '{\"status\":\"Fail\",\"message\":\"Can't find the requested route\"}' \n\nDoes anyone have time to investigate this issue? I also tried on searchassist-qa, but it seems the specific callback URLs don't work for this instance.",
        "What is the url of the salesforce instance?",
        "https://koreai7-dev-ed.develop.lightning.force.com/",
        "I recall running into issues with any salesforce instance that was not production. Not sure if the issue was ever resolved.",
        "Makes sense since there's no way to specify the target URL (I'd assumed that the client ID has it hashed and the platform interprets/regexs the URL from that).",
        "@Surendra Subhash Salke can someone look into this?",
        "@Aakanksh Dudam can you please help Laurence\n\n@Navya Sree Aluri",
        "@Aakanksh Dudam @Navya Sree Aluri any updates?",
        "I and @Navya Sree Aluri we not at gone through it. We just reached now. We will go through it and update you as soon as possible.",
        "Hi @Laurence Schoultz  As Discussed yesterday  in chat I am waiting for the app to share with me",
        "Hi Laurence, to debug this issue we wanted to know that the salesforce account which you are using is of type sandbox or cloud.Also, in you salesforce account can you please check whether the Redirect callback URL is added or not."
    ],
    "spaces/AAAABcXBTWI/threads/U40hIsdiA5g": [
        "Hi, I'm trying to Crawl a sitemap from here; https://www.wienenergie.at/ but am getting Encountered HTTP error while processing the request. Searchassist is however finding the sitemaps....",
        "@Akhil Sainath Maddala @Vishwas Tak can someone check this?",
        "sure @Girish Ahankari",
        "@Rob Le Boutillier I have gone through the site and observed that the content is loaded dynamically via a script. These kinds of pages can be crawled by enabling the JS rendered setting. I tried the same URL in one of our lower environments and can see pages getting crawled. Please try this setting once and let us know if still issue persists",
        "@Girish Ahankari @Surendra Subhash Salke Why can't we detect this and suggest the user with alternate approach or automatically switch to using JS rendered setting? We have discussed this multiple times before - we should simplify or remove the need for such questions",
        "Hi @Prasanna Arikala,\n\nDefault JS rendering is resource-intensive hence we choose to keep this setting optional. But I understood the experience gap you are pointing out here.  We will attempt to crawl pages with JS rendered if the usual crawl fails or provide an actionable message to the developer. \n\n @Rohit Tambe  @Aditi Bhadouria \nI have added this task in the tracker.",
        "I received the same issue even with JS Rendered & Respect robots.txt enabled..  @Rohit Tambe @Aditi Bhadouria"
    ],
    "spaces/AAAABcXBTWI/threads/LwdJpUjEvFQ": [
        "When will we be supporting Anthropic in Search Assist. I am working with Twitch they are not able to work with Open AI since they are an Amazon company.",
        "FYI: I have some history with previous engagement with Twitch team...",
        "This is planned for Jan 2024."
    ],
    "spaces/AAAABcXBTWI/threads/vH9SbRLtFYw": [
        "@Girish Ahankari @Surendra Subhash Salke"
    ],
    "spaces/AAAABcXBTWI/threads/z9TRRhUIZoQ": [
        "Its a dev account in the cloud."
    ],
    "spaces/AAAABcXBTWI/threads/NwLs12K9P5c": [
        "In that salesforce account information please check Proof Key for Code Exchange(PKCE)  is enabled or not.If it is enabled then please disable it and once try authorizing connector again."
    ],
    "spaces/AAAABcXBTWI/threads/VqRmY1O3aNg": [
        "Just did that and still doesn't work: {\"status\":\"Fail\",\"message\":\"Can't find the requested route\"}"
    ],
    "spaces/AAAABcXBTWI/threads/z2zyqqUYzr0": [
        "@Surendra Subhash Salke @Girish Ahankari In the pilot env we are observing an issue with the TR application where if / is present in the user's query, we are not getting any response. Can somebody help debugging this? The customer content team SMEs are doing validations right now.",
        "checking @Shantanu Ghorai",
        "Please try now"
    ],
    "spaces/AAAABcXBTWI/threads/JwLTCG3FFwA": [
        "How about the ability to host LLMs in AWS bedrock?"
    ],
    "spaces/AAAABcXBTWI/threads/y6OTPhCGElk": [
        "it is a typo in SA \"Bussiness rules\""
    ],
    "spaces/AAAABcXBTWI/threads/juh65vqgEI4": [
        "Is it possible to understand why it skipped the 3rd chunk? Is it possible to manipulate what chunk_id and file it should use for certain questions?",
        "Yes, we can use business rules to improve chunk qualification. But in this specific case, if the answer is in the third chunk business rules won‚Äôt solve it. Reason being that we send the top 5 chunks to LLM and LLM determines which information is necessary to answer the question. \n\nCan you give me some time I‚Äôll look into this and let you know. This will probably improve if we increase the chunk size, but I need to check first. \nReasoning for increasing chunk size: LLM doesn‚Äôt think that chunk is relevant because it probably got cut off or didn‚Äôt have enough context. By increasing the chunk size we can have more context and prevent information loss.",
        "Yes, take your time. I will circle back next week. Thanks!",
        "Is there any particular reason why there is a limit of 5 chunks?",
        "Context length",
        "We had initially kept the limit at 5, while the user could configure from 1 to 5. This was because LLM's had limited context window available, and we also had to account for the prompt instructions, query, and response. \n\nBut as we have observed the LLM's context windows keep increasing. We are planning on having a feature that will dynamically decide at run time how many chunks to send based on the LLM you are using and the context window available after budgeting for instructions, query and response. We have planned this as part of UXO",
        "@Aditi Bhadouria lets also make sure we provide the control to the user",
        "Sure Prasanna",
        "@Prasanna Arikala controls on how many chunks should be chosen is already being added in UXO. We will see how quickly we can make it configurable  to > 5, even in SearchAssist.",
        "@Girish Ahankari in the interim we have a custom configuration to update NoOfchunks(runtime)and chunk size(design time)."
    ],
    "spaces/AAAABcXBTWI/threads/OCqieMzdqAQ": [
        "Thank you Sunny. We will fix this",
        "You should award him a trophy. üèÜ Nice catch!"
    ],
    "spaces/AAAABcXBTWI/threads/fZVTwggZWFY": [
        "Hi @Santhosh Kumar Myadam and @Surendra Subhash Salke , Please could you advise if we support OneNote url in SearchAssist?",
        "Hi Komal,\n\nOne note format is supported only as part of the SharePoint connector.",
        "@Surendra Subhash Salke Azure Storage Connector also, right?",
        "Yes",
        "Thanks! I will touch base with you separately to understand more.",
        "https://docs.kore.ai/searchassist/manage-content-sources/connectors/sharepoint-connector/",
        "See if this helps"
    ],
    "spaces/AAAABcXBTWI/threads/vqkUG1cpSrs": [
        "Considering that the similarity score also applies to the generative model, placing it in a separate advanced settings tab would be more intuitive.",
        "We have planned this for the next release"
    ],
    "spaces/AAAABcXBTWI/threads/SQwBYq6Ok6o": [
        "I have a question that is asked by two prospects within the same week. I would like to know if it is something possible?  The question is \"how can we know does LLM generate the correct answer from the Document AI\"?",
        "You can check this through the answer debug. You will have information about the qualified chunks, LLM prompt and response",
        "Thank you. Without human inspection, how does it work?",
        "We don't have any automation that can tell you that OOB. But we are actively exploring different approaches to provide this. Ideally, we would like to show this through the Analytics.",
        "@Aditi Bhadouria our validation framework we are building should help here. Check with team if it‚Äôs release to production"
    ],
    "spaces/AAAABcXBTWI/threads/jDgPCG84cOw": [
        "Thank you for today‚Äôs training; it was highly informative. The content was excellent, and I appreciated the walkthrough. @Aditi Bhadouria @Surendra Subhash Salke @Girish Ahankari @Vishwas Tak \nHey Vishwas, I just implemented a couple of business rules for my Monday demo.üòâ. Thank you!",
        "Happy to help @Andy Pham !"
    ],
    "spaces/AAAABcXBTWI/threads/9R-1aSZN-uk": [
        "@Andy Pham thanks a lot for the feedback"
    ],
    "spaces/AAAABcXBTWI/threads/KjGo8WSS08w": [
        "@Girish Ahankari pls share the recoding here and with me directly also."
    ],
    "spaces/AAAABcXBTWI/threads/IuMXsxkBEhQ": [
        "Here is the recording of yesterday‚Äôs session\n\nhttps://drive.google.com/file/d/1W1CmQ3clZGb26YboxcXJK580QzpKeCMW/view?usp=drivesdk",
        "@Aron Kurzinski"
    ],
    "spaces/AAAABcXBTWI/threads/cD46ilfnEUA": [
        "Session on RAG: https://drive.google.com/file/d/1rVWlp-ft5lrj4t727Y-Wmt_W3U3I3NoE/view",
        "@Aron Kurzinski"
    ],
    "spaces/AAAABcXBTWI/threads/1NiSHGwjEf4": [
        "I have a potential client that would like to upload documents in English, Spanish and German. Should I separate documents into separate folders by language and use a business rule so that German questions are only answered from the German documents?"
    ],
    "spaces/AAAABcXBTWI/threads/3tvcCtvSZlI": [
        "The content of the documents is the same, translation was done by them and they want to use their documents rather than a Google-like translator.",
        "Hi John,\n\nYou could separate a document into different directories and apply an answer index business rule (starts with vi_) to filter the chunks with sourceName (directory name) and query language.",
        "Or if customer is ok, create 3 different Apps",
        "Creating 3 apps is a maintenance problem, but clear separation of rules.",
        "Here is a video recording by our interns demonstrating the business rules for language-specific filters\n\nhttps://www.loom.com/share/bff05e93222a4c2d8f7f60705ee03dae?sid=0f9cd8bf-ebde-48a0-9a6a-b32e8e4e9174"
    ],
    "spaces/AAAABcXBTWI/threads/yktnvSVKEFk": [
        "@Nibhrit Vij this is valid but need to be raised in XO platform and not in SearchAssist"
    ],
    "spaces/AAAABcXBTWI/threads/cKkQwXEXtVs": [
        "@all We are conducting the \"Office Hours - Search Assist\" and included \"Enablement@kore.com\", \"solutions@kore.com\".\n\nI see only 16 participants out of which 5 are from SearchAssist team itself.. Please use this opportunity to ask your questions and share your knowledge.\n\nAlso, let us know if we need to include any other DLs.",
        "Enablement is my team and is only 4 people - I think \"Solutions@Kore.com\" is probably @Gopi Polavarapu 's team.\n\nIs the target audience all of the GTM teams?  If so, you should add \"Sales.All@kore.com\" that includes the direct and partner sales teams, CustomerSuccess should have all the CS team members too\n\nNote - the early hours are challenging for anyone west of Orlando - it's 5:30am for those in the western time zone.  Perhaps moving them out an hour would help attendance."
    ],
    "spaces/AAAABcXBTWI/threads/9JBsxqzQGEs": [
        "@Subrahmanyam Donepudi please find the video links for SearchAssist Answers\nSearchAssist Overview: https://drive.google.com/file/d/1vR8Yg-Pkpp_G3wX93Z58YRhr8Qzbwi8h/view\n\nRAG Overview : https://drive.google.com/file/d/1rVWlp-ft5lrj4t727Y-Wmt_W3U3I3NoE/view\n\nHow to Debug and Fine-tune: https://drive.google.com/file/d/1W1CmQ3clZGb26YboxcXJK580QzpKeCMW/view"
    ],
    "spaces/AAAABcXBTWI/threads/JtNqxx1fgg4": [
        "Is there a reason why the value for ‚ÄúUsed for Generative Answers‚Äù is zero?\nIt had been working correctly throughout the entire week until today.",
        "Hi Andy,\nThis is most likely the issue with GPT response structure. If response format is slightly changed then response synthesis will take a hit.\n\nYou can confirm this by comparing the prompt responses of query when it works and partially works.",
        "So! It's not something we can fix on our end?",
        "@Surendra Subhash Salke I did not understand this, can you call me or explain when we meet today?",
        "this is not a good experience too when the references is shown as empty []",
        "Sure @Girish Ahankari.\n\nOne option is to use json mode with completetion api",
        "Could it be that none of the identified chunks reached the required threshold? Isn't the default 0.6?",
        "@Surendra Subhash Salke, I was able to fix the issue by modifying the prompt. However, I am curious about the JSON mode that was mentioned. I searched everywhere, including the Custom Config Feature list, but I couldn‚Äôt find where to enable it. Can you please guide me on how to enable the JSON mode with completion API, and when should I enable it?",
        "@Andy Pham Surendra was referring to the use of JSON mode option of the Completions api. If we use it then OpenAI will always give a valid json and we will be show all the relevant results. This is not yet exposed in the product. \n\nWe might still have issues where the response is json but it may not be adhering to the format that we expect. \n\n@Surendra Subhash Salke \n@Aditi Bhadouria I think we should do a fallback experience  for scenarios.",
        "@Andy Pham What did you modify in the prompt that fixed it? I've the same issue."
    ],
    "spaces/AAAABcXBTWI/threads/WHdjJ0m7zys": [
        "Hi Team, we have a few RFI questions on access control/role management. Please see below\n\n1)¬†The system should fully respect access controls in the respective repositories, and security trim to only present results from content to which the users have permission to access. (both EX and CX use cases)\n\n2)¬†Describe how ‚Äúreal-time‚Äù your security trimming is. For example, if the access controls on a piece of content changes, how quickly will that change be reflected in response the bot presents.\n\nCan this be configured on SearchAssist, or is this dependent on XO-P, where the VA is built? I couldn't find information on the SearchAssist documentation. Please advise. Thank you. (cc:  @Tim Burke)",
        "Hi Mohan \n\nWe currently don't have RACL for SearchAssist. It's in the roadmap. \n\nI can't comment on the XO bot part, but if you were using the Advanced Search API, you could define the rules as metafilters, and SearchAssist will honor them. But this requires that the information is also a part of the chunk metadata at the time of ingestion (Might have an impact on the method of ingestion). Additionally, we would have to capture this information at run time, so we also need to understand how that information can be sent and converted to appropriate metafilters. To sum it up, while it could be achieved, there will be custom implementation involved with several dependencies.",
        "Thank you, Aditi. Any rough timeline that you could share for this roadmap item?",
        "Tentatively we are aiming for Q1 2024"
    ],
    "spaces/AAAABcXBTWI/threads/T2GRd07eOjI": [
        "I am seeing that XO supports custom LLMs (see below). When will SearchAssist have something similar? I am in need of such capability for the prospect Twitch which is an Amazon company and they want to use AWS Bedrock service.",
        "@David Gwartney \n\nWe do not plan to take up Custom LLM in SearchAssist. \n\nWe are planning to migrate all of the SearchAssist features into the new unified XO. Once this is done (Jan/Feb), we will be able to use the Custom LLM in XO for 'search/answers' functionality too. \n\n @Aditi Bhadouria  @Rohit Tambe"
    ],
    "spaces/AAAABcXBTWI/threads/eh5W-gKsP9E": [
        "Can someone give me a guideline on setting up Search Assist and only using the Extractive Model.  What should the settings and configurations be and should I get the answer back in a summary and have the document listed.",
        "@Krista King \n\nPlease refer here:\nhttps://docs.kore.ai/searchassist/personalize-results/answer-snippets/\n\nYou can enable only the 'Extractive' model\n\n @Aditi Bhadouria  @Rohit Tambe"
    ],
    "spaces/AAAABcXBTWI/threads/7zluV8n3xRw": [
        "Also - is there a sharepoint site we can have access to, so we can demonstrate the integration from Search Assist to Sharepoint?",
        "@Surendra Subhash Salke is there a Sharepoint site available for us to use to show this to a customers?",
        "+1"
    ],
    "spaces/AAAABcXBTWI/threads/A7BntWDj-W8": [
        "Solutions@kore.com is the global SE team and some affiliated staff",
        "@Girish Ahankari - I would love to join but I don't have a meeting invitation on my calendar",
        "@Richard Passavant the goal is to answer any questions which sales, SEs, demo team have about SearchAssist. We are happy to include anyone interested from Kore.ai",
        "We will try to move the meeting by another hour, but will ensure we record the sessions. If team, can post questions, we will be happy to answer even offline or even in calls",
        "Girish, please make sure the invite is extended to everyone so that anyone can come and ask questions",
        "@Prasanna Arikala sure. We just did not want to spam calendar of everyone. We will send the invite to everyone"
    ],
    "spaces/AAAABcXBTWI/threads/SXMhjgSX0KI": [
        "Huh - would‚Äôve expected that to be the Solutions team SEs to be ‚Äúsalesengineers‚Äù or something like that"
    ],
    "spaces/AAAABcXBTWI/threads/HjfhgygPqGg": [
        "@Martin Jahn Is it okay if we include the DL of the CS team? If that is okay, pls let me know the DL to use\n\n @Aditi Bhadouria",
        "Guys , why don't you just extend it to everyone",
        "@Prasanna Arikala sure. We just did not want to spam calendar of everyone. We will send the invite to everyone",
        "Please extend it to everyone."
    ],
    "spaces/AAAABcXBTWI/threads/QRelJIGY0bw": [
        "Hello @all ,\n\nWe have observed an increased interest in SearchAssist, and we are very grateful for that. We also understand that a lot of people have been facing difficulties with using SearchAssist.\n\nDue to this, we have decided to arrange Office hours for SearchAssist thrice a week(Monday, Wednesday & Friday) from 6:30-7:30 PM IST. We will have representation from product, engineering, and documentation in these calls. Everyone is free to join and raise any questions or difficulties they want our help with.\n\nOur goal would be to make additions to the product based on your feedback and also document the questions so that it is easily available for anyone who might need assistance with using SearchAssist.\n\nThis is an effort from our side to enable the SE and sales team so that we can make SearchAssist a successful product.\n\nWe request you to make full use of these sessions to discuss any questions you may have about the SearchAssist/Answers functionality for RFPs, demos, PoCs, and general queries from prospects. As this is a recurring session, we request you to join based on your needs.\n\nWe request you to not set up specific calls for individual customer/prospect-specific clarifications. This is essential for us to continue to focus on the product development and build the right features. We hope you understand.\n\nIf you are interested, please use the following link to add this event to your calendar. We are being cautious not to spam your calendar.¬†\nhttps://calendar.google.com/calendar/event?action=TEMPLATE&tmeid=MG9qc2ltb2VlaXNkaGtmMm9lZmV2OTZlMjBfMjAyMzEyMjBUMTMwMDAwWiByb2hpdC50YW1iZUBrb3JlLmNvbQ&tmsrc=rohit.tambe%40kore.com&scp=ALL\n\nIf you encounter any issues in adding this event, please reach out to¬†@Rohit Tambe¬†or¬†@Aditi Bhadouria"
    ],
    "spaces/AAAABcXBTWI/threads/MAe7KHvmjZ8": [
        "@Richard Passavant @Peter Wulfraat @Prajakt Deshpande @Narasing Rao Akula please invite anyone missing. We do not have access to send email to everyone@kore.com",
        "Created a task for @Richard Passavant (via Tasks)"
    ],
    "spaces/AAAABcXBTWI/threads/6mfUwQcoYW8": [
        "cc @Aayush Mediratta"
    ],
    "spaces/AAAABcXBTWI/threads/xnI1BRl-N9c": [
        "@Srinivasa Pakala"
    ],
    "spaces/AAAABcXBTWI/threads/4BJTnPGK660": [
        "Thank you Shared invite to all seal team members."
    ],
    "spaces/AAAABcXBTWI/threads/1_oc4ZfsDss": [
        "Created a task (via Tasks)"
    ],
    "spaces/AAAABcXBTWI/threads/0ndpJTgGFBY": [
        "Searchassist API Documentation:\nhttps://searchassist.kore.ai/searchassistapi/public/api-docs/"
    ],
    "spaces/AAAABcXBTWI/threads/d2v2kYE_75Y": [
        "@Shantanu Ghorai please find in here the list of beta features you can use via custom configs -\nBeta Features Docs : https://docs.google.com/document/d/1kqSH_g0GZ8A6LvLZyCr2EB4Y7FlAj5Rdxo4TekQVunM/edit?usp=sharing"
    ],
    "spaces/AAAABcXBTWI/threads/LMdJ5kNVqkU": [
        "@Surendra Subhash Salke Can you please share the recordings of office hours at a central place so people who missed the session can review the recordings?",
        "@Umang Shah Yes, we are creating a cwntral repository for all the how to guide docs, cheat sheets, Training recordings and office hour recordings. \n\nWill share this in a couple of days."
    ],
    "spaces/AAAABcXBTWI/threads/57sPwXI7DFY": [
        "Isn't that the Resource Portal?  With that content marked as Internal only?"
    ],
    "spaces/AAAABcXBTWI/threads/M2gXZb5-B6I": [
        "Yes, it can be the resource portal. From the product team's perspective, we will capture everything in a single place/doc/drive. \n\nEnablement team can pickup from here and add the relevant stuff to the resource portal."
    ],
    "spaces/AAAABcXBTWI/threads/llZkQvqN7WI": [
        "I checked 2FA feature from XO Platform Admin console and it works for XO side but doesn't work for SearchAssist. Do we have any plans to support this 2FA with SearchAssist also?",
        "@Sandeep Singh Rana We do not have any immediate plan to add 2FA in SearchAssist.",
        "Besides email, are we looking to add additional 2FA device types? @Santhosh Kumar Myadam",
        "@Andy Pham No plans for other 2fa device support (sms or others) for now.",
        "@Sandeep Singh Rana all features of SearchAssist will be coming in UXO Answers at a an Additional price around March-April'24. Hence we may not need this feature in SearchAssist",
        "@Girish Ahankari , thanks for the info. I understood!"
    ],
    "spaces/AAAABcXBTWI/threads/RgN-O0hDoAc": [
        "Created a task (via Tasks)"
    ],
    "spaces/AAAABcXBTWI/threads/SsbbQ4DgaTs": [
        "Hi @all,\nPlease find the consolidated sheet that contains links to the overview videos, \"how-to\" videos and documents, and office hours meeting recordings. The link is also added in the Tasks tab and in the Space Details for convenient access.\nSearchAssist Repository: https://docs.google.com/document/d/1V6eB77yoW2A9YgEr0oOnvxsSYrg-mVMGXZI3wflPpSA/edit"
    ],
    "spaces/AAAABcXBTWI/threads/T5MUwExVcpw": [
        "Hi guys, do we have any public SearchAssist instances that can be shared with Customer? I have a Prospect (administrator of shopping malls) in Brazil that want to know SearchAssist customers and a live instance.",
        "Hi Francisco, here‚Äôs the link to SearchAssist production(live) instance- https://searchassist.kore.ai/accounts/"
    ],
    "spaces/AAAABcXBTWI/threads/iOpSWi3nb2w": [
        "Thanks @Rohit Tambe, but the the Prospect (Multiplan) want to know an instance that is owned by a Customer. Do we have any?"
    ],
    "spaces/AAAABcXBTWI/threads/Wuncvy8qu98": [
        "Hello - Can someone help me with this.  I have Search Assist integrated to my XO platform - but when the answer comes back and references the document multiple times, it shows the link multiple times.  How can I get this to only show once?",
        "@Krista King can you share the script you have written for this?",
        "@Shantanu Ghorai var answer = \"\";\nvar links = \"\";\nif (context.searchAssist.response && \ncontext.searchAssist.response.body && \ncontext.searchAssist.response.body.template.graph_answer && \ncontext.searchAssist.response.body.template.graph_answer.payload && \nObject.keys(context.searchAssist.response.body.template.graph_answer.payload).length > 0) {\nvar snippet_content = context.searchAssist.response.body.template.graph_answer.payload.center_panel.data[0].snippet_content\n¬† ¬† function convertToLink(title, url) {\n¬† ¬† ¬† ¬† var link = \"[\" + title + \"](\" + url + \")\"\n¬† ¬† ¬† ¬† return link;\n¬† ¬† }\n¬† ¬† for (let i = 0; i < snippet_content.length; i++) {\n¬† ¬† ¬† ¬† answer += snippet_content[i].answer_fragment + \"\\n\"\n¬† ¬† ¬† ¬† if (snippet_content[i].sources) {\n¬† ¬† ¬† ¬† ¬† ¬† for (let j = 0; j < snippet_content[i].sources.length; j++) {\n¬† ¬† ¬† ¬† ¬† ¬† ¬† ¬† links += convertToLink(snippet_content[i].sources[j].title, snippet_content[i].sources[j].url) + \"\\n \"\n¬† ¬† ¬† ¬† ¬† ¬† }\n\n¬† ¬† ¬† ¬† }\n¬† ¬† }\n} else {\n¬† ¬† answer = \"Sorry! I could not find the results\"\n}\ncontext.answer = answer\ncontext.links = links",
        "Can you try the below snippet",
        "var answer = \"\";\nvar allLinks = [];\nvar links = \"\";\nif (context.searchAssist.response && \ncontext.searchAssist.response.body && \ncontext.searchAssist.response.body.template.graph_answer && \ncontext.searchAssist.response.body.template.graph_answer.payload && \nObject.keys(context.searchAssist.response.body.template.graph_answer.payload).length > 0) {\nvar snippet_content = context.searchAssist.response.body.template.graph_answer.payload.center_panel.data[0].snippet_content\n    function convertToLink(title, url) {\n        var link = \"[\" + title + \"](\" + url + \")\"\n        return link;\n    }\n    for (let i = 0; i < snippet_content.length; i++) {\n        answer += snippet_content[i].answer_fragment + \"\\n\"\n        if (snippet_content[i].sources) {\n            for (let j = 0; j < snippet_content[i].sources.length; j++) {\n                snippetLink = convertToLink(snippet_content[i].sources[j].title, snippet_content[i].sources[j].url) + \"\\n \";\n                if(!allLinks.includes(snippetLink)){\n                    allLinks.push(snippetLink);\n                }\n            }\n\n        }\n    }\n    for (const element of allLinks) {\n        links+=\"\\n\"+allLinks[element];\n      }\n} else {\n    answer = \"Sorry! I could not find the results\"\n}\ncontext.answer = answer\ncontext.links = links",
        "made a small correction use it now",
        "Now it shows as \"undefined\" for the link:",
        "can you share the bot with me?",
        "shantanu.ghorai@kore.com",
        "sure",
        "it is fixed now",
        "I just wanted the ability to see one link - possible a \"click here to see more details\" type of thing and now i get too much detail on the link itself",
        "@Shantanu Ghorai please see the image now and what i noted above it",
        "This is not from the fallback task - I only fixed the issue in the fallback task",
        "I've the same issue. It would be great to receive a response we receive in SearchAssist.."
    ],
    "spaces/AAAABcXBTWI/threads/jaPiQQoblF4": [
        "@Francisco Chang \n\nI think what you are asking is to know if there is a \"live\" instance of a SearchAssist customer so that we can share it with another prospect so that they can test/experience it? \n\nHere are some of the customers live on SearchAssist \n\n- IDFC - It is integrated with the bot and it is live (https://www.idfcfirstbank.com/) - Help - Chat with IRA\n\nLG.com - It is available as an internal beta. PLs check with Harinder Bommkanti if/how to share it other customers\n\nThere are a few others but they are all internal/employee facing and it may not be possible to share\n\n @Rohit Tambe  @Aditi Bhadouria  @Surendra Subhash Salke Please review",
        "Thank you very much Santosh!!"
    ],
    "spaces/AAAABcXBTWI/threads/tMG9A34Epss": [
        "Hi all,\n\nSearchAssist connects to VA so that some dialog tasks can be called from SearchAssist. I just tried to open the dialog task, SearchAssist shows some FAQ articles which SearchAssist crawled as a snippet over the chat window. However, dialog tasks are not showed in the snippet, and it's showed in the chat window, not the snippet, after entering keywords completely.\nAre there any ways to show dialog tasks in the snippet?",
        "Have you added bot you want to run from SearchAssist ? Under  SearchAssist Bot Action ?",
        "@Ichiro Fukuyama \nDialog Tasks are not included as part of the Live Search results in SearchAssist.",
        "@Sandeep Singh Rana As we discussed offline, I'd like to open a dialog from SearchAssist.",
        "@Santhosh Kumar Myadam Okay, got it. I'll consider to raise an enhancement ticket with my team."
    ],
    "spaces/AAAABcXBTWI/threads/3a20BH2pazU": [
        "Hi all,\n\nPlease let me ask one more question. When we open a digital form of a dialog task in SearchAssist, the digital form is opened in an another tab, not in the chat window of SearchAssit. Can we open a digital form in a same chat window like VA?",
        "@Ichiro Fukuyama This is currently not support in SearchAssist SDK. Please raise an enhancement ticket. We will check the feasibility.",
        "@Santhosh Kumar Myadam Thank you for your comment. Okay, I'll consider to raise the enhancement ticket with our sales member."
    ],
    "spaces/AAAABcXBTWI/threads/vo3aR3BVPxk": [
        "Can anyone answer below Security concerns shared by Toyota Motors \n\n1. If someone intentionally or not shares the Chatbot web app URL anyone will be able to access it and will be able to query chatbot. How can this risk be mitigated? \nKore.ai doesn‚Äôt have IP address control on the webapp URL.\n\n2. The files uploaded to SearchAsssit when opened. the URL is accessible by anyone. How can we control that? Is there a way by which even if the URL is shared no one else is able to open it. Example the below URL can be accessed by anyone https://jp-searchassist.kore.ai/searchassistapi/getMediaStream/findly/f-88337bad-dda0-590d-bcac-eeca5cd6dcf1.pdf?n=8517837681&s=IjU4Yk5EdmJkSFJQczhHL3M3TjFCRjRzOTVPU0pEMzNMVHpOYWRoa0k1WDQ9Ig$$#page=3",
        "1. The HTML code can be embedded into the prospect's preferred web domain. They can always have some form of authentication for the website itself. That way, they can limit access to the bot.\n\n2. If the user has uploaded documents, then yes, anyone can access those documents using the reference URL. But, if they are using a connector, when they click on the link, they will be redirected to the respective connector, and only once they login there will they be able to see the documents. Alternatively, if they have used an authenticated website for the web crawl, the user will have to login again to view the content.",
        "Hi @Aditi Bhadouria , thank you for your prompt response. \n\nFor Q1 I understood. But still if someone gets the direct URL of the webapp or thinking of a case where a employee who was part of the development team copies the URL and intentionally takes back or shares the URL with someone outside of the Organization they will be able to query bot for the docs or FAQs which were directly uploaded to SearchAssist. Sometimes FAQs also have critical information if the bot is developed for internal use.\n\nQ2 I can understand that by having documents on CMS like Sharepoint can limit the access to docs. \n\nBut can‚Äôt we have a capabilities built where once the reference URL of a document uploaded directly to SearchAssist is accessed the URL cannot be reused. In my previous organization we were working on similar scenarios and were utilizing AWS but we were able to resolve this by having capabilities where once the URL is accessed the same URL will not work on other browser or in a different session. Everytime the user would open the file the URL gets regenerated.",
        "We will explore this @Sandeep Singh Rana . Thank you for the feedback.",
        "@Aditi Bhadouria @Surendra Subhash Salke @Santhosh Kumar Myadam In the platform, We do support JWT based auth for them to not allow anyone to include the chat widget outside authorized websites; similarly we do support secure signed shared urls that have time limits \n\ncan you have someone create a doc on how to setup these for search assist ? that should solve for what @Sandeep Singh Rana  is asking. @Girish Ahankari",
        "Sure @Prasanna Arikala",
        "Hi @Prasanna Arikala \n\nWe have implemented mechanism where everyone file is in the response payload will be converted into one time signed url, we will externalize this feature.\n\nI will work with platform architects to know more and have jwt based auth for searchassist SDK.\n\n@Girish Ahankari @Santhosh Kumar Myadam",
        "@Surendra Subhash Salke prasa once we Move SearchAssist into UXO, there will be no need of separate SDK. XO SDK will suffice. We need to ensure that all templates of SearchAssist are supported in the do SDK.",
        "@Prasanna Arikala @Santhosh Kumar Myadam",
        "Team, wishing you a very Happy New year. Thank you for supporting us. \n @Surendra Subhash Salke ,  @Girish Ahankari ,can you please give ETA on this mechanism? \"We have implemented mechanism where everyone file is in the response payload will be converted into one time signed url, we will externalize this feature.\"",
        "@Surendra Subhash Salke",
        "Hi Sandeep It will be available by 2nd week of Feb\n @Bharat Rekha  @Rohit Tambe \n\nhttps://koreteam.atlassian.net/browse/FLY-10371",
        "@Surendra Subhash Salke , thank you very much for prompt response. Appreciate you help."
    ],
    "spaces/AAAABcXBTWI/threads/ccz5vw6VgNE": [
        "The documentation for the connectors doesn't seem to be updated. In the introduction to connectors: https://docs.kore.ai/searchassist/manage-content-sources/connectors/introduction-to-connectors/ the first page says there are 3 connectors and then lists off 4. It also doesn't include the other connectors listed in the TOC: Saleforce, Azure Storage, Google Drive, Dropbox, and Oracle Knowledge Connector. This makes it very confusing",
        "@Matt Panaccione We will update this today. \n @Prabhat Singh  @Rohit Tambe",
        "Thanks for pointing that out @Matt Panaccione. I updated this page. In the past two months, many new connectors were added, we added respective documentation but missed updating the Intro page."
    ],
    "spaces/AAAABcXBTWI/threads/gYMizhhqNj0": [
        "Does SearchAssist support HTML documents or do they need to be converted into PDF? Example doc is attached",
        "We don't support HTML in file upload. While you could convert it to PDF and upload it, that's not recommended, as the chunks will contain the HTML tags along with the content and might lead to reduced accuracy.",
        "We recommend using web crawl. Please let us know if you are facing any issues with that."
    ],
    "spaces/AAAABcXBTWI/threads/TJtXVzNEQFI": [
        "Can someone explain how the answer returned is not what is displayed to the user? Shouldn't it say \"no answer found\"?",
        "Here, both the Extractive and Generative models must be enabled. As the system didn't find an answer through the generative model, you got an answer from the extractive model. If you go to the JSON view, you will be able to see the debug payload for both extractive and generative models.",
        "You could also use the simulate feature in answer snippets to understand the run time flow."
    ],
    "spaces/AAAABcXBTWI/threads/asTrd8AWai0": [
        "I have setup a demo instance at https://searchassist-app.kore.ai/home/. I can get the Document AI responses and create an app last week. I got the error \"Error in creating app\" when i create a new app or the Preview function  does not return any Document AI answers today for my existing app that worked last week.",
        "Hi @Sunny Lun,\nIt was due to service restart. It is fixed now, please check."
    ],
    "spaces/AAAABcXBTWI/threads/qxXNTFutd4w": [
        "Regarding the support of scanned images, tables, and graphs, are they supported and available to demonstrate with SharePoint integration? cc: @Shawn White",
        "Can you assist with this question? This is a must-have for CBRE. Here is a URL that contains various file formats with scanned images, tables, and graphs. CBRE Group, Inc. Reports Financial Results for Third-Quarter 2023 :: CBRE Group, Inc. (CBRE)",
        "Sorry Andy, missed your message. We don't have a timeline for this yet",
        "We will be updating the roadmap with the latest changes in the next few days",
        "@Frank Suljic fyi",
        "@Andy Pham do you know if Document Layout Studio has been released?  Would it support Japanese language?"
    ],
    "spaces/AAAABcXBTWI/threads/RWJsOaZYiqc": [
        "How can I inject / set the UserContext in the Preview mode of SearchAssist? I want to simulate and trigger the Business Rules in the Preview Mode."
    ],
    "spaces/AAAABcXBTWI/threads/YU3SDfvUcdE": [
        "I have setup Context rules to filter the the results that contains some keywords in the filename. It works for the extractive model searching results filtered by file_title. But I cannot filter the results when the answers are coming form the Answer AI. How can I set the filter for the Answer AI \"Reference\" attributes?",
        "@Sunny Lun we can discuss this in the next Office hours call.",
        "no worries. All are well-covered in today Office hours call by Rohit"
    ],
    "spaces/AAAABcXBTWI/threads/XhdhHpOC8qw": [
        "What is the simplest way to show the Like or Dislike after every responses (answers) in SearchAssist without using XO platform integration?"
    ],
    "spaces/AAAABcXBTWI/threads/BbUA8O7oXEk": [
        "I'm working on an opportunity at the moment and the customer is looking to use SearchAssist to query their disparate systems e.g. Google Analytics, Snowflake etc in order for staff to get live answers from their structured and unstructured data. (e.g. how many products did we sell last week in the London store?) Are we planning to integrate with any of these vendors in the future out the box? Thanks!",
        "This isn‚Äôt part of the current roadmap. We will look into it and consider adding it",
        "Thank you @Aditi Bhadouria  - the functionality they referenced was outlined here; www.datagpt.com",
        "@Rob Le Boutillier check out the Eva team... i have it connected to hubspot as a source and think that VA is going to be more similar to what youre looking for"
    ],
    "spaces/AAAABcXBTWI/threads/R1WaUexHdV8": [
        "Trying to index a site on SearchAssist (https://www.wienenergie.at/) and getting this error below. Not seen this before - if any one can advise, I have a client follow up on this Friday AM. Thank you!",
        "We‚Äôll get someone from the team to look into it",
        "@Aditi Bhadouria @Surendra Subhash Salke @Bharat Rekha the error message too is useless.. please check asap.",
        "Hi Rob,\n\nAre you trying to crawl using a CSV file?",
        "We will get this error due to improper column name in CSV file which user is trying to upload.\nFor example, if someone tries to upload a sitemap file, but the column is named \"url or any other\" instead of \"sitemap\" this error will occur and vice-versa.",
        "Forwarded the steps to replicate @Surendra Subhash Salke",
        "Crawling has been successful in lower environments. However, it seems there might be an issue in the PROD and pilot environments according @Mounika vemula Will fix this issue and update accordingly. Thanks for help on this one"
    ],
    "spaces/AAAABcXBTWI/threads/-5l93WzlxTw": [
        "HI can anyone from the SeachAssist product team assist here please.",
        "@Surendra Subhash Salke @Girish Ahankari",
        "Hi @Andy Pham \n\nSupport for extracting the tables and images from the uploaded pdf file is available. This feature is in beta, and to enable this you could use \"dev_Chunk_Extraction_Method = layout\" as a custom configuration. However, this feature is not yet available for scanned PDFs and files via connector.",
        "@Surendra Subhash Salke @Girish Ahankari  The customer has expressed that supporting scanned images on SharePoint is a critical and top priority. They are also interested in extracting data from images, tables, and graphs to answer user queries. However, they do not require displaying graphical images and their elements. They are asking for an ETA. Is there one we can share? They believe they have over 100,000 documents and plan to decide by the end of the month.@Shawn White",
        "@Andy Pham where should those images be stored? Does customer have any pre requisites on storage? Like S3 or any CDN or is it ok to store in any storage?",
        "This can be done but will need more implementation time",
        "Also needs custom work.",
        "Sharepoint is their primary storage and a must-have. They want to know how much time it would take. Can you provide an  estimate so we can set proper expectations with the customer? @Girish Ahankari",
        "Hi @Girish Ahankari. We have a meeting with the prospect tomorrow. Can you estimate when we can support the above requirements? Your immediate feedback is vital for us to move the conversation forward.\ncc:  @Shawn White",
        "Girish can you assist please.",
        "@Shawn White @Andy Pham how big is this deal?",
        "also, do we know if they are just image files or do they mean images inside the documents?",
        "Can @Surendra Subhash Salke also join the call with them to understand the requirement better? @Sathya Priya Turaga",
        "@Surendra Subhash Salke and @Shawn White Understand the requirement first and then we can think of a solution in the product or an extension as a tactical solution and permanent solution as part of the product",
        "@Andy Pham and @Shawn White are they OK to use GenAI frameworks like OpenAI for answering? SearchAssist can extract, search, but I propose using OpenAi for answering content",
        "They have committed to sharing the exact document formats with us for review soon. Based on our last meeting, my understanding is that these images will be a part of a larger document and not on their own. I anticipate that some of these images will be digital while others will be scanned. I will forward the meeting to @Surendra Subhash Salke. @Shawn White Can you share the deal size with Girish. Thanks !",
        "They haven't clearly stated their preference regarding the use of OpenAI. However, they wanted to see if we can switch the feature off.",
        "We also need to know where to store the images.. if they are ok with S3",
        "Is there a need to extract and store the images?",
        "Hi @Andy Pham , pulkit has shared an application with you where a beta feature for reading the scanned pdf and images as answers is deployed. Its in the searchassist-app env.",
        "I noticed I couldn‚Äôt click on the source. How would this work over a channel that can‚Äôt display images? They only care about the texts and their relevant context and meaning. @Shawn White Feel free to add your feedback if there is something I may have missed.",
        "@Surendra Subhash Salke",
        "They wanted to move forward with a P.O.C. What is the recommended deployment model for customers with intranet sites?",
        "@Andy Pham what is the scope of the PoC?",
        "@Melissa Prince Once ready, can you share the deal size with @Girish Ahankari? \nGirish, do we have an ETA for the above feature?",
        "@Gopi Polavarapu @Melissa Prince @Frank Suljic @Surendra Subhash Salke"
    ],
    "spaces/AAAABcXBTWI/threads/TnHiGk4j90c": [
        "Hey Guys, can someone help around SA SDK I created, it keeps on spinning for some odd reason? I tried creating a couple and it‚Äôs the same results - one is Servus Credit Union and another one is Henry Fund for Demos. PLMK if m missing anything,"
    ],
    "spaces/AAAABcXBTWI/threads/2x73kaiV_5I": [
        "Looks like you are trying to use barefoot to host the Search Assist SDK. Not sure if the barefoot supports the Search Assist SDK\n\n@Subrahmanyam Donepudi Do you know?",
        "You need to add / whitelist ‚Äòdemo.kore.ai‚Äô domain in SearchAssist configuration under channels",
        "@Navdeep Grover",
        "@Kevin Mullay Thanks! it worked!"
    ],
    "spaces/AAAABcXBTWI/threads/ePRCPeUOV0w": [
        "Hi all, wish you a happy and healthy 2024.  I need your help.  I am building a SearchAssist while source is coming from text files (example legal doc and terms and conditions).  When I ask a question, SerachAssist gives me a very long answer from text files.  The answer is correct; however, the response it is very long, and I would like to summarize / shorten the answer.  I am not using OpenAI and wonder if any of SearchAssist features can help.",
        "Here I think you are using the Extractive model. For extractive model the extraction process is such that we don't lose context, and clip text in between. Reason being if we chunk randomly the resulting text won't make any sense to the end user.¬†\n\nWhile using generative model, because we rely on the LLM to generate a comprehensive response we have more freedom in chunking the text.",
        "So, we can't reduce the chunk size for extractive model as of now. We plan on including some features in UXO that will help here. We can discuss this in more detail in today's Office Hours call",
        "@Aditi Bhadouria Thank you for your response.  Yes, I am using extractive model.  The answer from extractive model can be very long text, I was just seeking a solution without using Generative AI for this.",
        "I will join the Office-Hours",
        "@Aditi Bhadouria Can we trim the response in the SDK?",
        "We can trim the answer (Max 150 words), but if the answer is contained in the last few lines it won't be visible to the user. Hence might lead to a lesser accuracy and user experience will be impacted, even though the answer would be technically correct. Also summarisation is not available for Extractive currently.",
        "Yes, you are right."
    ],
    "spaces/AAAABcXBTWI/threads/-Iqm8KOGREA": [
        "What are the limitation of the trial SearchAssist account in terms of per file size limit, number of files supported and number of pages?",
        "There are limits in terms of the number of files and the size of files on the cloud environment.",
        "These are configurable for any private cloud or onprem customers"
    ],
    "spaces/AAAABcXBTWI/threads/0PxMElkH7uE": [
        "Same question for the paid SearchAssist customers"
    ],
    "spaces/AAAABcXBTWI/threads/I6z_de4Bnkk": [
        "Both refer to the GenAI model",
        "1. For Free Account, Limits are set per source.\n     Webcrawl- Max. of 2000 records\n     File Upload- Max. of 2000 records\n     FAQ- No cap\n     SD- No cap\n     Connectors- Max. of 2000 records\n\n- Definition of a record- https://docs.kore.ai/searchassist/getting-started/glossary-of-terms   \n- No cap on the number of files/pages ingested. The limit is defined in terms of records\n\n2. Enterprise Accounts don't have these limits. There are soft limits set internally and can be updated as per user requirements.¬†\nSoft Limits-¬†\nWebcrawl¬†- 100k records\nFile Upload¬†- 50k records\nfaqs - 50k records\nstructured-data - 50k records\nconnectors - 300k records\n¬† ¬†¬†\n3. per file size limit- The file size limit is 15MB, this is for both free and enterprise accounts",
        "Will file size limitation also apply for connector based integration?",
        "Yes Umang, the 15 mb file size limitation is across all sources  including connectors",
        "This would be a practical challenge as I see customers are sharing larger file sizes for demo/PoC",
        "Yes, we'll work on addressing the issue\ncc:  @Surendra Subhash Salke",
        "@Rohit Tambe @Surendra Subhash Salke has the per file size limit been changed?",
        "@Jordan Bostick per file size limit is unchanged, it is max 15 MB",
        "@David Taglieri üëÜ",
        "@Joe Mello üëÜ @Billy Reilly"
    ],
    "spaces/AAAABcXBTWI/threads/vKfbSIqyAK8": [
        "Another question.. how can i disable the following section. I have already disabled the Extractive Model",
        "You can go to Result Templates under Indices and delete these fields.",
        "Web, FAQ and File"
    ],
    "spaces/AAAABcXBTWI/threads/qWK0WAZjP8U": [
        "Hello Japan team, hope all of you are safe and healthy.",
        "Thank you Girish. We‚Äôre all ok‚Ä¶"
    ],
    "spaces/AAAABcXBTWI/threads/Til-MAvsF-o": [
        "@Sunny Lun @Hisayoshi Tamaki @Sreeni Unnamatla"
    ],
    "spaces/AAAABcXBTWI/threads/ABhROKF39A8": [
        "I'm building a Whatsapp bot on XO and also a voice bot, one for each experience.\nIn order to be able to speak and how the bot pronounces, I have to publish it and test it through SmartAssist.\nIt works, but it takes a long time\n\nIs there a faster resource for this type of development?\n\nSomething like a button in the dialog construction, to have a preview of how the text will be synthesized\n\nThanls",
        "Hi Martin, \n\nI think the platform team will be able to help better here.",
        "Thanks!"
    ],
    "spaces/AAAABcXBTWI/threads/AGoyKRtMXAo": [
        "In the past, we've had two good standard Search demos.  One that showcased a top bar search (cosmetics) and one that showed a virtual assistant style banking demo (one of our best looking SA demos).  Both are from early 2022 before GAI and newer versions of SearchAssist. \nIs there a plan in place to upgrade those to use GAI in the demo script with sample questions to ask, etc?  For example, the Cosmetics (retail) could be more like our LG experience (not exactly, but closer such as \"Which mens perfumes have more of a musk smell to them? or \"Whats your return policy?\") -  And same for the banking, it shows very well but doesn't highlight the newer features. (this is my favorite SA demo but it doesn't go deep enough).",
        "We will work on getting an updated demo and share it here"
    ],
    "spaces/AAAABcXBTWI/threads/ymRT-SEOwcI": [
        "Can we add an indicator to show when the SearchAssist App needs training? I don't want to train unnecessarily, as it can be time-consuming.",
        "Ok. Will take this as a feature request"
    ],
    "spaces/AAAABcXBTWI/threads/n2IRxuBUvPY": [
        "Team, can someone answer these general questions? \n1. In the UXO will the customer be able to select between Search bar and Assistant interface just like current SearchAssist?\n2. In the UXO if a customer just want to use SearchAssist and don't want to use task bots or any other feature will that be possible or it will be necessary to configure a task bot and then use SearchAssist in fallback task?",
        "1. Yes but it will not be available immediately",
        "2. Yes that will be possible",
        "@Aditi Bhadouria , can you give any tentative timeline by when it will be available? Thanks",
        "@Sandeep Singh Rana #1 will be available end of March in cloud. Until then, customer can use SearchAssist",
        "Awesome !! @Girish Ahankari Thank you very much"
    ],
    "spaces/AAAABcXBTWI/threads/HopKDx-BiKA": [
        "Hi all,\n\nI just found unable to open my SearchAssist with published URL even though I could open it as \"Preview\".(\"Loading\" hasn't finished) Could you check if there are some issues with SearchAssist?\n\nhttps://jp-searchassist.kore.ai/webclient/5c856a5a34c84bc380840f265b2c7941abb615d801fd4ea18040201cc16fd014st12",
        "Hi Ichiro,\nCan you please check the Whitelist domains in Manage>Channels>Web Client Details, as we getting Domain(s) are invalid error in the above url response.",
        "Hi Rohan, thank you for your quick help! I'll check it.",
        "If possible, share the list of whitelist domains."
    ],
    "spaces/AAAABcXBTWI/threads/zFNEvry7B5k": [
        "I have a SA demo for an italian audience using Sharepoint connector. For the demo, use cases are all in english. However, the client wants to also know the following:\n\n- Can we search italian documents with italian questions?\n- Can we search italian documents with english questions?\n- Can we search english documents with italian questions?\n- Can we pull data from images (eg. from a Pie chart)\n- Currently, what file types are supported? PDF, Word, PPT, Excel, others? (I ask because I know the SA team is actively improving the product!)\n\nI will be enabling generative AI using Azure OpenAI.",
        "My experience with your language combinations work in Asian language. We will do a translation via LLM prior the vector DB searching.. For the data recognition from chart images, it depends on the OCR. Even it can recognize the data from the chart, it loses the semantic understanding of those chart data. We can understand the tabular structure so far.",
        "Tutto bene!"
    ],
    "spaces/AAAABcXBTWI/threads/OXHrESvjCEg": [
        "Also need to know if not available now, what is in pipeline, to communicate with client. This is for existing client Eli Lilly."
    ],
    "spaces/AAAABcXBTWI/threads/uw31W_PtocM": [
        "@Gurpreet Singh most of these questions were answered already for different language.\n\n@Matt Panaccione are we preparing a QnA document from all the answers given by the product team?\n\n@Aditi Bhadouria and @Rohit Tambe can we have a SearchAssist application which can attempt at answering these questions and if no answer found, route to us?",
        "Yes, @Girish Ahankari we've started building an application to answer these kinds of questions, it's in the testing phase",
        "This is a great idea. Thanks!",
        "@Girish Ahankari are you talking about all the questions in this chat?"
    ],
    "spaces/AAAABcXBTWI/threads/ik-_sXhnXRI": [
        "Informative response! Love it..."
    ],
    "spaces/AAAABcXBTWI/threads/O_vYAu2Tycs": [
        "Had a call today with HP Computers on our platform and Search.  Do we have roadmap for searching audio & video file types?  I think at the moment we are limited to text documents and soon hopefully, text from images.  Correct?",
        "Hi Tim,\n\nBoth text from images and audio video files support is in the near roadmap.\n\n@Aditi Bhadouria for the ETA.",
        "@Tim Burke just to give context, we have technically solved the searching of audio and video files. We are working on productization for scale and enterprise controls.\n\n@Aditi Bhadouria if you can also share the demo we did and also the application it will help.\n\nAlso see if this can be demonstrated to all the SEs in Office hours",
        "Sure Girish"
    ],
    "spaces/AAAABcXBTWI/threads/KK7AdJ6kUFk": [
        "Hi team, can we install SearchAssist on premise?",
        "yes per my understanding",
        "@Andres Valdez Yes, SearchAssist can be deployed for on=premise",
        "Thanks for your quick response! üëç"
    ],
    "spaces/AAAABcXBTWI/threads/nmITEXp6H8M": [
        "Anyone can point me to the SearchAssist WebSDK documentation on how to set the context variables from the existing web applications to the embedded websdk searhassist bot?"
    ],
    "spaces/AAAABcXBTWI/threads/CJeFf8nGZ3g": [
        "Hi Team, can somebody confirm if the following documentation from Microsoft regarding the Azure OpenAI API is what we are using in SearchAssist to make the API call https://learn.microsoft.com/en-us/azure/ai-services/openai/reference.  I have a meeting with Otsuka Infosec team today and they need this information.",
        "Yes, this is the correct documentation"
    ],
    "spaces/AAAABcXBTWI/threads/nBMsRgP10as": [
        "@Melissa Prince you can reach out to @Jo√£o Cabral ti assist with your Portant-HubSpot acesss. If you need any other assistance please let me know directly."
    ],
    "spaces/AAAABcXBTWI/threads/7-4iwdnPpPI": [
        "Is there Cherwell Connector on the road map. Also, Is there any documentation or SDK on creating your own connectors?",
        "No. Who is the customer and do we know the number of probable customers using Cherwell?",
        "No cherwell connector. Not SDK either?  Is that correct?",
        "Can the ingestion API be used to load data and use just like any source for answer snippets?",
        "@Girish Ahankari charter requires and so does David and my customer Columbia Sportswear.  These are priority 1 accounts",
        "You may be able to run a report in hubspot to see how many customers require Cherwell integration but it‚Äôs not as realiable yet as it will be in future I‚Äôd guess. @Jo√£o Cabral thoughts?",
        "Ofcourse you can use the ingestion API",
        "Unfortunately, I don‚Äôt have access to HubSpot",
        "Will it be an upsell at Charter and Columbia if we add this connector?",
        "@Girish Ahankari We should have an SDK for generic connector",
        "There was some work done on that before. Let's get it out as SDK"
    ],
    "spaces/AAAABcXBTWI/threads/w-_bMARw-Kw": [
        "Hi @Girish Ahankari , Please let me know if this sheet is old or incorrect because this sheet below shows that there will be no connectors like Sharepoint, Gdrive etc with UXO then how can I tell Toyota to do POC with SearchAssist and later use UXO? \nWill UXO really not going to have Connectors? Cc  @Hisayoshi Tamaki \nhttps://docs.google.com/spreadsheets/d/1BxemkYmeT0tiQ1vN1Ps2Hs4C5kL6milKtd94VRzVElI/edit#gid=0",
        "@Sandeep Singh Rana this sheet is to compare the current capabilities of SearchAssist vs UXO- Answers module. Connectors will be available in UXO. But it will take us some time to bring all features of SearchAssist fully into UXO. Hence in the status column the expected date has been mentioned",
        "Hi @Aditi Bhadouria , thank you for the update. Relieved to hear that connectors will also be included in UXO. \nCan we get ETA on basic connectors like Sharepoint and Gdrive?"
    ],
    "spaces/AAAABcXBTWI/threads/vkFVwSEIycY": [
        "@Aditi Bhadouria @Rohit Tambe"
    ],
    "spaces/AAAABcXBTWI/threads/_e6ruNJgt_o": [
        "Please check"
    ],
    "spaces/AAAABcXBTWI/threads/-ULVDbkSTbw": [
        "I am looking for pre-built integration pieces for the following and curious if someone has already done this work?\n- when calling fullSearch API and displaying the results in either a digital interaction or AgentAssist widget, we need a template that can take response from fullSearch API and provide a nicely formatted answer using something similar to what SearchAssist returns in the direct integration. i.e. Answers from documents summarized by OpenAI, with reference links underneath.\n- needs to be in plain text or Markdown as that is all AgentAssist supports in the widget currently",
        "this is the type of response or similar I'm looking for",
        "this is a common need across many demos right now",
        "Curtis, I was looking for the same thing.\nI did the formatting manually, taking the image link, the article link, the Generative AI response, but I agree that we have to have a template ready for this.",
        "@Martin Anibal Bonardi  can you share what you did for this please? thanks!",
        "@Curtis Swartzentruber Is the requirement about better formatting of search results inside AgentAssist widget or does it also include some kind of summarization of search results?",
        "Could be both",
        "Would be good to have a few options depending on use case",
        "It also becomes a UX and AX question fairly quickly. For instance, if there are three highly ranked answers, you might want agent to be able to choose which to send in digital",
        "Rather than one message with everything"
    ],
    "spaces/AAAABcXBTWI/threads/fCkKwvAJN14": [
        "Hi. (How) Can we add custom smalltalk (or edit responses of default smalltalk) within searchassist? If its not yet possible, what can be the workaround?",
        "Hi Nibrit. Custom smalltalk is not supported in searchassist. \n\nUnfortunately there is no workaround within searchassist. Can you check if linked bot smalltalk responses can be delivered as intents in the findIntent API.",
        "@Surendra Subhash Salke the findIntent API does return small talk thats identified. it is returned under \"smalltalk\" key instead of \"task\" key. would it be enough to add a linked bot to an app for small talk to work, or is additional configuration needed? \n\n{\n    \"request\": {\n        \"input\": \"How are you\",\n        \"streamName\": \"Neo Bank v10\",\n        \"language\": \"en\"\n    },\n    \"response\": {\n        \"usedtime\": 1449,\n        \"debugTitle\": \"Intent Match Successful: ''\",\n        \"result\": \"successintent\",\n        \"messageStoreId\": \"xxx\",\n        \"bot\": \"Neo Bank v10\",\n        \"botid\": \"st-8caf164c-b871-52ec-8e8a-49c5f4b795d6\",\n        \"skipConversation\": true,\n        \"botLanguage\": \"en-US\",\n        \"nluLanguage\": \"en\",\n        \"intentStatus\": \"published\",\n        \"subType\": \"dialog\",\n        \"input\": [\n            \"How are you\"\n        ],\n        \"identifiedVia\": \"none\",\n        \"language\": \"en\",\n        \"userId\": \"u-6bc4a312-f47e-53cb-97e0-cde9a5edf2e0\",\n        \"time\": \"2024-01-16T12:08:50.049Z\",\n        \"_id\": \"f-a39b078d-c6d5-5c97-84c0-5ea4ccd1bca7-1705406930049\",\n        \"smallTalk\": [\n            {\n                \"activityType\": \"smalltalk\",\n                \"intent\": \"~emohowzit\",\n                \"matchedPattern\": \"~emohowzit\",\n                \"graph\": [\n                    \"greetings\",\n                    \"~emohowzit\"\n                ]\n            }\n        ],"
    ],
    "spaces/AAAABcXBTWI/threads/cnHw54Xm5pg": [
        "During the demo today, I was asked if it‚Äôs possible to summarize ingested documents with a specific length. In case you‚Äôre asked the same question, it appears feasible.",
        "custom configurations: \n\ndev_Answer_Response_Length | default:150 | This flag is to configure the answer content length",
        "and this is definitely more than 100 mins, maybe like 130? I didn't count exactly."
    ],
    "spaces/AAAABcXBTWI/threads/tRfZeEmS0n0": [
        "whoa"
    ],
    "spaces/AAAABcXBTWI/threads/alOPbbrffVc": [
        "üòâI didn‚Äôt count. The request is to summarize the document to a length of the user‚Äôs choosing."
    ],
    "spaces/AAAABcXBTWI/threads/2k3hi2b7LTo": [
        "It‚Äôs 126 words. Good catch, @Gurpreet Singh \nTeam, while the ability to summarize is crucial, users also want the freedom to dictate the length. After testing, SearchAssist does reduce the length as instructed. However, it doesn‚Äôt always match the number of words specified by the user. \n\nIs this possible? Also, could it not end with a comma and provide a result similar to what you get from EVA?"
    ],
    "spaces/AAAABcXBTWI/threads/_d7zn6FSSJ0": [
        "From EVA"
    ],
    "spaces/AAAABcXBTWI/threads/XJZf_tzsAmM": [
        "Hi Team!\nI'm curious if there is a one-pager with information on Search Assist pricing? I've looked for info on the portal but wasn't able to find anything showing the list price. Thank you!"
    ],
    "spaces/AAAABcXBTWI/threads/rxMay0xkJTA": [
        "@Sandeep Singh Rana this will not be in XO as this is part of SearchAssist. However, you will get to see this information in the unified XO once integration of SearchAssist is complete in the XO.\n\nRegarding your original question, currently it‚Äôs not available in the UI. We will add a story to track this but cannot commit to deliver before end of Feb."
    ],
    "spaces/AAAABcXBTWI/threads/9mxL_3eQ1WM": [
        "How critical is the feature to sign the deal?"
    ],
    "spaces/AAAABcXBTWI/threads/rrcoY6A8tZc": [
        "How big is the deal?"
    ],
    "spaces/AAAABcXBTWI/threads/z-ql-09VEtM": [
        "Can we have a deal done with a clause that this feature will be ready by say end of March?",
        "@Girish Ahankari , thank you for your prompt response. There are two cases which I want to highlight.\n\n1. Existing customer - NSSOL is an existing customer and a partner. They are part of NIPPON STEEL GROUP.\nThey have IT audits for which they will need to share the Access logs by April to IT/Security department.\n\n2. Prospects - ‚ë†Toyota Motors- we have been unable to start the POC because our SearchAssist solution is weakest when it comes to security but overall it looks most promising when compared with other competitor‚Äôs [comments from Toyota]. We need commitments on basic security features like access logs, WebApp URL disable button similar to what we have in XO when the APP is published. If we can commit these features availability by End of March we can start POC by next week. POCs in roadmap .\n‚ë° Tokyo Marine[one of the largest Insurance company Planned in coming weeks] \n‚ë¢Mizuho bank [One of the top 3 banks planned for April target sustainability department]"
    ],
    "spaces/AAAABcXBTWI/threads/QaRzPO3fXAw": [
        "Yes, we can commit the same for end of March",
        "@Girish Ahankari , thank you very much for committing to the requests. This will help us start the POC by next week and further introduce SearchAssist to new prospects."
    ],
    "spaces/AAAABcXBTWI/threads/wW2Fe_-ZWqo": [
        "I will check with @Santhosh Kumar Myadam about the Web URL disable button"
    ],
    "spaces/AAAABcXBTWI/threads/PoFeLlR37sc": [
        "@Aditi Bhadouria please add these to our roadmap and ensure we track for end of March in JP environment",
        "Sure Girish"
    ],
    "spaces/AAAABcXBTWI/threads/8hCoOYtuhKU": [
        "üôè"
    ],
    "spaces/AAAABcXBTWI/threads/HQsTKJtkXAE": [
        "Cc @Vamsi Vagvala"
    ],
    "spaces/AAAABcXBTWI/threads/txrxa-UqnM4": [
        "Is this way of search possible with SearchAssist?\n\nOne of the mega bank in Japan is looking for a search solution where \n\"The user should be able to first set multiple search words at once [like a batch]\" and then example click on search button and the answers, docs show up. \n\nInstead of a natural search where the user searches a word a sentence and then when the answers show and filter is applied, but looks like they want to apply filters before making search.",
        "@Sandeep Singh Rana \nSearchAssist query APIs allow filtering of the search results based on the meta filters included in the request. \n\n- Customers can customize our SDK or build their own SDK\n- Build the UI to offer the required filters\n- Pass the selected fitlers in the search request\n- Receive the results and choose how to present the results to the users\n\n @Surendra Subhash Salke  @Aditi Bhadouria  @Rohit Tambe",
        "@Santhosh Kumar Myadam , thank you. Will share it with the partners."
    ],
    "spaces/AAAABcXBTWI/threads/k3V5_vOe64A": [
        "When will the solution Alaska Airlines benefit from, GenAI answers + cached answers, be GA? I have a prospect who is working on the business case and LLM costs are a big factor"
    ],
    "spaces/AAAABcXBTWI/threads/kpKsCTdfn34": [
        "When data is uploaded directly to SearchAssist or via a connector we use it for indexing and vectors are created.\nQuestions\n1. Does the data after indexing continuous to resides in the SearchAssist DB ? If yes in what format is it stored text format or the format it was actually uploaded example pdf, ppt, txt etc?\n2. If the App created is deleted does the data associated with that app also gets deleted from DB?"
    ],
    "spaces/AAAABcXBTWI/threads/jJzV6_aWKZI": [
        "Two questions:"
    ],
    "spaces/AAAABcXBTWI/threads/n28t3x4I0aI": [
        "1.  Where is the latest how-to for LLM integration in SearchAssist?",
        "not sure if there is official docu -- but basically you could go to Answer Snippets, and switch on Generative Snippets -- it should prompt you automatically for configuring an LLM",
        "https://docs.kore.ai/searchassist/personalize-results/answer-snippets/\n\nhttps://docs.kore.ai/searchassist/administration/integrations/"
    ],
    "spaces/AAAABcXBTWI/threads/XMoJQLZHxzE": [
        "2.  Is there a how-to for integrating searchAssist with a SmartAssist-defined voice channel?",
        "there is a doc for connecting searchassist app to a bot in xo platform. you could add that bot to smartassist voice channel to essentially enable searchassist on voice channel.",
        "@Michael Piotrowski SearchAssist doesn't have voice channel support OOB. You can integrate with a bot and then integrate with Smartassist. This is a document detailing how to connect a bot to SearchAssist. (Bot user facing, SearchAssist as fallback)\nhttps://docs.google.com/document/d/1AY04sMQ_PBHsCYPRLa0WoaiHHJng7RVq42eHG4H6pUE/edit#heading=h.yk4aifctzhit\n\nThis is the documentation for linking a SearchAssist app with a bot. (SearchAssist user facing)\nhttps://docs.kore.ai/searchassist/manage-content-sources/linking-your-virtual-assistant/",
        "@Aditi Bhadouria Can we add this as part of the documentation on the portal?",
        "Sure Amit. Documentation team is working on it. It will be added soon"
    ],
    "spaces/AAAABcXBTWI/threads/I-RNIdXOTN8": [
        "https://docs.kore.ai/searchassist/administration/integrations/"
    ],
    "spaces/AAAABcXBTWI/threads/84RSIZElPjA": [
        "what are the supported languages for searchassist + xo answers and what is the process for adding a new language",
        "Hi Rob, this page has the list of languages supported by searchassist and steps to enable a new language. https://docs.kore.ai/searchassist/manage-indices/index-languages/"
    ],
    "spaces/AAAABcXBTWI/threads/frMFg2M7dZA": [
        "great thanks  Shruti- whats the turnaround time for product enabling additional languages that are not on that list"
    ],
    "spaces/AAAABcXBTWI/threads/mNLUfcHMgGo": [
        "SearchAssist now can handle multilingual snippet generation using LLMs . Try exploring that!"
    ],
    "spaces/AAAABcXBTWI/threads/2UJO8ncLwkM": [
        "@Rob Le Boutillier I'm testing italian. It's not on the approved languages but it's working nicely. Once you enable any other language on the list in the settings, the embeddings model will change (from MPNet to LaBSE) and you can play with many other languages."
    ],
    "spaces/AAAABcXBTWI/threads/ip1N1fDKywg": [
        "How would we solve for a SearchAssist app for support personnel that have their information stored in OneNote?",
        "Hello Eva"
    ],
    "spaces/AAAABcXBTWI/threads/u6uLXdL1KHA": [
        "A question about UAT: Do we have a standard expectation or requirement for successful responses from SA? How is a successful response defined? To what level of perfection can an instance be trained in practical application? Obviously, these are parameters to be included in the contracts, but what expectations should we set?"
    ],
    "spaces/AAAABcXBTWI/threads/wPkvR9WZhDE": [
        "In one of our training sessions on SearchAssist this table was introduced (see below). Structured data is supported for generative answers by indicated *Predefined Fields* in parentheses.\n\n1. What are those predefined fields?\n2. Can you use the ingestion APIs to populate those fields?\n\nI am trying to find out if I can use web scraping libraries like Beautiful Soup, Scrapy to handle extraction from web pages which I am familiar with rather than the scripting available in the workbench.\n\nAlso if this ability holds to be true, could also be used to create custom extraction tools.",
        "@Surendra Subhash Salke is the above possible?",
        "Hi David,\n\nFor structure data to be qualified as snippets please create a Json object with following three fields\n\ntitle, content, url"
    ],
    "spaces/AAAABcXBTWI/threads/Vs_rnfAwwHQ": [
        "Was there a change made to search assist in prod this weekend? My generative answers are not quite the same as Friday. Also - the image link for Web Pages results is broken:",
        "@Aditi Bhadouria @Rohit Tambe",
        "@Surendra Subhash Salke is looking into it",
        "Yes @Gurpreet Singh we have the version 1.5.1 on prod now. We will go over the changes in this version in today‚Äôs Office Hours.",
        "@Gurpreet Singh can you also please share the app you're facing the issue and a few queries if possible to reproduce the issue?",
        "ok sure",
        "Just shared with you, @Aditi Bhadouria.",
        "Will look into it and let you know in a couple of hours",
        "@Aditi Bhadouria @Akhil Sainath Maddala @Surendra Subhash Salke looks like some issue --> I'm not getting any qualified chunks when I do a search",
        "although the chunk search for \"etesevimab\" does return 2 chunks",
        "added you to the app, and shared my test utterance file",
        "@Gurpreet Singh Can you please join here for a quick call.",
        "yea I'm on!",
        "Surendra, I'm on the line",
        "@Gurpreet Singh we've found the issue and it's due to some incorrect config while doing the deployment on U.S prod environments. It's fixed now and please train the app to reflect the changes.",
        "ok thanks",
        "do I need to increase the threshold ?",
        "Ideally no, but please check once right after training",
        "btw - the demo this morning went very well",
        "only 1 utterance didn't return the genAI response",
        "but that was ok, since I was able to explain why"
    ],
    "spaces/AAAABcXBTWI/threads/6SKzStkjvVI": [
        "Hello team, could someone provide guidance on generating chunks from a PDF file in SearchAssist? I attempted to upload a stock research report and then proceeded with the training. However, I encountered an issue where not all contents of the document were successfully extracted into chunks. The generative model being utilized is the Azure OpenAI GPT-3.5 Turbo.\n\nAdditionally, I have added a custom configuration with the key 'dev_Chunk_Token_Size' and the value '1000.' Despite this, I've observed that the chunk size remains limited to 400. Can someone help me understand why this limitation persists?",
        "@Inseon Park we can discuss this in today's Office Hours meeting",
        "Ok, I will join meeting",
        "@Bharat Rekha @Vaishali Addala @Akhil Sainath Maddala",
        "Hi @Inseon Park,\n\nOne of the production service was  down during that time. We have fixed the issue. Can you please train the application again.",
        "@Surendra Subhash Salke I'm appriciate for support. I've confirmed all contents of the document were successfully extracted into chunks. And can we be defined the size of chunks extracted? Would you please check beta feature of chucks_token_size?"
    ],
    "spaces/AAAABcXBTWI/threads/5cB3aOyJYtA": [
        "@Girish Ahankari sure sir can you reply.. we have a meeting with Samsung Insurance Tom.."
    ],
    "spaces/AAAABcXBTWI/threads/o22MG-7ep7M": [
        "@Sreeni Unnamatla what is the question?"
    ],
    "spaces/AAAABcXBTWI/threads/XxKKsCJ69vU": [
        "Hi all, would somebody kindly increase the file upload limit for THK to 35 MB?  Thanks!"
    ],
    "spaces/AAAABcXBTWI/threads/7gA3mwmq4ig": [
        "Hi Team,\n\nCan one of you please enable THK's¬†search¬†assist¬†instance for¬†35¬†MB files?\n\nThe stream id of the¬†search¬†assist¬†app is:¬†¬†st-16e24493-5571-5d22-8278-2a712ff9efb0\n\nThanks,\n\n--Mike",
        "Okay, that is the magic.",
        "@Sathya Priya Turaga is this done?",
        "yes this is done"
    ],
    "spaces/AAAABcXBTWI/threads/FJ_dm0OuQWE": [
        "Does anyone have a recorded demo (English) of search assist embedded in a Salesforce desktop? Customer wants to enable SFDC users to search for answers when creating an email response. Thank you.",
        "Please check with AgentAssist team. You should get it"
    ],
    "spaces/AAAABcXBTWI/threads/-Cn1Zo7nmwE": [
        "Could someone please let me know the expected update date when the custom configuration for extracting chunks from PDF documents will be implemented?",
        "Could not understand your question. Could you please elaborate?"
    ],
    "spaces/AAAABcXBTWI/threads/2VXGVRw6xXo": [
        "Question: one of my clients has their knowledge base sitting directly on onenote. Is there a way to injest/crawl content from there? Any other sugggestions? Also, the onenote section/content used by an agent (via agent assist) is different depending on who is calling in. Is there a way for search assist to provide responses only considering certain data? Is this where business rules come in? Can we use business rules before the search takes place to only search from specific sources?",
        "Is it pure text? OneNote is kinda like notion."
    ],
    "spaces/AAAABcXBTWI/threads/-0MYgy6fB0s": [
        "Yea text in these auto grouped containers on the page. They also have images which they said are important contextually."
    ],
    "spaces/AAAABcXBTWI/threads/IBjCdIYwXS0": [
        "We will explore OneNote. Have not done yet"
    ],
    "spaces/AAAABcXBTWI/threads/QtYVYNZ5paM": [
        "But is customer ok for a PS effort to sync onenote content into SearchAssist via a custom connector?",
        "Will confirm, as I understand this is not ootb.",
        "@Mike Ashe please take note"
    ],
    "spaces/AAAABcXBTWI/threads/2i2yRGPagxQ": [
        "Also, see if you can explain the scenarios with few examples"
    ],
    "spaces/AAAABcXBTWI/threads/q3YOYXpLmnE": [
        "When is the expected launch date for SearchAssist's beta features? I am particularly interested in the capability to specify the chunk token size within it.",
        "@Inseon Park team will update you on Monday as it‚Äôs a long weekend in India. IMHO it will be released on 10th Feb. However it is available in lower environment if you want to try",
        "Thank you for providing the schedule. When you mention \"lower environment,\" are you referring to the pilot server or QA server?",
        "@Inseon Park If you are referring to the use of the below custom config it is already available. This custom config can be used to define the chunk token size, only applicable for Generative model. \n\nKey\ndev_Chunk_Token_Size\nValues\n<number of tokens>\nFunctionality\nUsing chunk token size, the size of chunks extracted can be defined.\nChunk size can be defined only when the extraction is done using Text extraction model\nBy default the chunk size for text extraction is 400 tokens.\nSuggestion/Pro Tip\nFor gpt-3.5-turbo-4K model, set number of tokens= 400¬†\nFor gpt-3.5-turbo-16K model, set number of tokens= 1000",
        "I knew that, so tried to config of number of token is 1000 and max token size of chunk is limited 400, Is this correct working? additionally, I set generative model is get-35-turbo of Azure openai."
    ],
    "spaces/AAAABcXBTWI/threads/X6IP8lc0YQQ": [
        "I have a prospect that is trailing SearchAssist. They are loading HTML documents into SearchAssist with a JSON wrapper as structured data. All works well however when the answers (found chunks are displayed) the formatting is off as the chunks being sections of the document lose HTML tags. Does anyone have a good solution to this. Is this just a problem with structured data or does it occur when using other sources? Thanks.",
        "One way to accomplish this is to update the prompt to instruct LLM to retain html formatting"
    ],
    "spaces/AAAABcXBTWI/threads/_CTcMo5wMrY": [
        "what is the easiest way to price (sku) customer wants SearchAssist, XO UA platform?",
        "Search Assist is baked into the XO Platform, so the easiest way is to sell them the platform - we don't have separate skus for SearchAssist vs XO"
    ],
    "spaces/AAAABcXBTWI/threads/ttYPYkZHi-s": [
        "@Richard Passavant that is not right. Pls check with @Peter Wulfraat"
    ],
    "spaces/AAAABcXBTWI/threads/-WP2hypEZfo": [
        "We have connected and I have helped Richard understand how we are pricing answers vs Advanced RAG vs full SearchAssist"
    ],
    "spaces/AAAABcXBTWI/threads/wphjbbMcKME": [
        "A prospect asked: \n\nIf a document / PDF/ Word is country-specific, should we tag the properties a certain way?¬† ¬†Do we set the properties at the file level (within word for example), or within Sharepoint (file or folder level?)\n\nI responded with:\n\nThe easiest¬†way is to consistently include the key field, such as the country, in the title. Then, when we ingest the document, we are able to tag it with the correct country and use it in retrieval.\n\nHowever, they asked an additional question:\n\nOutside of the document title, do you recommend adding any tags to the file as well? ¬† For example, adding tags such as Country and other key words to help enhance search? Or do you feel it won‚Äôt be necessary as the AI is smart enough based on the crawling it does?\n\nDo you have any best practices I can share to ensure their documents/files will be retrieved accurately and consistently? Thanks",
        "for SharePoint, one option is to physically separate the files based on the country into different directories or sites.\n\nThis information can be retried during the extraction and added as metadata. We write the business rules to retrieve from a specific folder using the user-context."
    ],
    "spaces/AAAABcXBTWI/threads/LnE2NFzv8FU": [
        "I have a customer who loaded a PDF file into search assist, but search assist failed while trying to extract content. How can we troubleshoot this? Can we adjust the workflow somehow?"
    ],
    "spaces/AAAABcXBTWI/threads/rBZqHuECt48": [
        "BTW the file was about 25 MB, they received the correct privs to increase the size limit to 35 MB. That part seemed to work okay."
    ],
    "spaces/AAAABcXBTWI/threads/Ce96jJHQVDc": [
        "Thank you @Surendra Subhash Salke do you recommend including any key fields in the document themselves other than adding country in the title? Thanks"
    ],
    "spaces/AAAABcXBTWI/threads/RyQ88G0IaF0": [
        "When using the GDrive connector on SearchAssist, is there a way to limit the file to just a specific GDrive folder?",
        "Followup to this: how do I delete a connector? Looks like the GDrive connector crawled random content from Kore's GDrive, which I want to remove, either the files, or at a global level. I disabled the connector, but the files that it crawled still get chunked.",
        "@Gurpreet Singh The source level Filter is in the develop.\n\nYou can use the exclude document stage for unnecessary content",
        "ok thanks. I'll remove the stage and re-try."
    ],
    "spaces/AAAABcXBTWI/threads/xqy39-UQ0sE": [
        "Hi, do we have a video that demonstrates how the SearchAssist experience/ bot would look like for mobile? A customer that is currently deploying on web is interested knowing how the mobile experience would look like."
    ],
    "spaces/AAAABcXBTWI/threads/G4baQc8h8rg": [
        "Hi team, I'd like to know if Keyword extraction stage does not extract appropriate keywords from FAQ ? Is there any script to insert keyword per faq manually?"
    ],
    "spaces/AAAABcXBTWI/threads/HmzeLig-074": [
        "@Surendra Subhash Salke just moving this up to the top. I appreciate your input.",
        "Hi Kevin,\n\nhere we are referring to files stored in Sharepoint as documents. Adding a field in the document will be difficult to extract. Hence, we suggest creating sites so that site information can be added as a meta data to apply filtering at runtime."
    ],
    "spaces/AAAABcXBTWI/threads/odEbCElLGzQ": [
        "What is the process for optimizing searches via connectors, ServiceNOW, when there exist multiple articles on a topic, i.e. 100 articles on phishing and spam?\n\nAlso, an FYI when connecting to ServiceNOW our partner determined that the account has to have certain KB roles/rights to VIEW the documents or nothing will show up."
    ],
    "spaces/AAAABcXBTWI/threads/GUcr2-ugnzU": [
        "reposting this question:"
    ],
    "spaces/AAAABcXBTWI/threads/_HRodb99q_E": [
        "I have a customer who loaded a PDF file into search assist, but search assist failed while trying to extract content. How can we troubleshoot this? Can we adjust the workflow somehow?",
        "@Michael Piotrowski Which model are they using? Extractive or Generative? Also could you share a sample document to identify the issue.",
        "I will ask for the file, we have both configured, but I don't know if we actually reached that stage.",
        "@Michael Piotrowski Are certain the document has text and not an image. I have run into that before."
    ],
    "spaces/AAAABcXBTWI/threads/aZBIgauL0fo": [
        "BTW the file was about 25 MB, they received the correct privs to increase the size limit to 35 MB. That part seemed to work okay."
    ],
    "spaces/AAAABcXBTWI/threads/LhqiwplDD4Q": [
        "@Michael Piotrowski Were you not able to join the Office Hours today? You could have taken advantage of the availability of the team üòÄ"
    ],
    "spaces/AAAABcXBTWI/threads/OIbdFrKFzN8": [
        "I will ensure that team answers you by tomorrow during the day time in IST, in case no one replies today"
    ],
    "spaces/AAAABcXBTWI/threads/dWXH4a9_PEs": [
        "It is 5 am my time - lol"
    ],
    "spaces/AAAABcXBTWI/threads/t28ZHc5IFgs": [
        "thank you Girish!"
    ],
    "spaces/AAAABcXBTWI/threads/KUnpQruFmxU": [
        "oops.. Sorry for that.. i dont expect to join calls so early"
    ],
    "spaces/AAAABcXBTWI/threads/d_4ErGv5GQ0": [
        "Will ask team to respond to you ASAP"
    ],
    "spaces/AAAABcXBTWI/threads/4AqDBP9HU5A": [
        "thank you!"
    ],
    "spaces/AAAABcXBTWI/threads/9N7ZSqjb-og": [
        "Role-based Access Control - Question\n\nDoes Kore.ai support applying RBAC to Azure OpenAI searches or the information returned?¬†\nWhat about Kore.ai in general.¬† Does it support RBAC regarding information contained in a Knowledge Base?\n\nI see from our XO Platform Documentation that we can create a custom role for Knowledge Graph role based auth for this outside of course the access given to a given bot, etc.\n\nI am not finding any Roles / Permissions as it relates to LLM Integration Search results? Do we offer the ability to restrict that anywhere?\n\nI posed this question in the Solution Engineering channel... And Tim Burke had the following response.\n\n\nI know we can indeed do role based access, also Active Directory integration for permissions, SSO, etc. \nfor example, if you don‚Äôt have access to a doc in SNOW, you will. Or get it in the results. \nSearchAssist itself and data chunking / vectoring etc. is likely similar, and that at the runtime it will use the permissions that the user has for results that it brings back. All of this should be confirmed by the search assist team.",
        "In one of the posts late last year relating to SearchAssist, Aditi mentioned that role-based access capability is on the roadmap for Q1 of 2024, if I remember correctly.",
        "Thanks @Andy Pham.\n\n @Aditi Bhadouria @Girish Ahankari Can you confirm this please or elaborate?",
        "Hi @Jon McCain sorry for the late reply.¬†\n\nI will not be able to comment on the Platform KG part or Kore.ai in general but I have detailed the answer for SearchAssist below.¬†\n\nRole based access control is part of the roadmap but not currently available OOTB for SearchAssist.¬†\nIt can be done through a custom implementation using business rules with PS effort.¬†\nRBAC will always be connector/ingestion specific and not LLM model specific.¬†\nWhen RBAC is available OOTB we will filter the relevant chunks only from those documents that the end user has access to, hence it will not be LLM dependent."
    ],
    "spaces/AAAABcXBTWI/threads/3SZ8oH0IuoE": [
        "@Girish Ahankari If the office hours were an hour later I would be able to attend"
    ],
    "spaces/AAAABcXBTWI/threads/ReVXkSIVhmI": [
        "Hi team. Answering a questionnaire for a Search Assist opportunity. Do you know these answers? (yes, I know they are vague...)Thanks \n\n1. Addition/Removal/Version Control of data sources from context data\n\n2. Analytics Dashboard like Cost, Requests, Context Tokens, Generated Tokens and Cost",
        "Can anyone assist on this question? The prospect is requesting a response today. Thank you @Surendra Subhash Salke",
        "1. We have different ways, of ingesting and filtering content, that support variety of use cases. We also have a workbench where users can apply complex conditions and perform operations like excluding data.¬†For connectors and web crawl we ingest the latest version of documents based on updates to documents and sync frequency. \n\n2.¬†We show¬†Completion Tokens, Prompt Tokens, and Total Tokens for individual requests through answer debug but we don't currently have a dashboard that shows these details for all requests",
        "@David Gwartney  just FYI - this response may be helpful for our SA pursuits at Columbia and the Allegion RFQAllegion Knowledge Management Vendor RFQ (1).pdf"
    ],
    "spaces/AAAABcXBTWI/threads/nx_o_jBQLos": [
        "Hi Team, I have questions about SearchAssist API during a project delivery. Do you know these answers? Thank you.\n\n1. Scoring Algorithm: Could you please elaborate on the algorithm used to calculate the 'Score' in the SearchAssist API Full Search results? Understanding the underlying logic and methodology would greatly aid in explaining the product's functionality to the client.\n\n2. Score Range: What is the defined range for the 'Score'? I tried to use the API and some scores are more than 1000. Knowing the maximum and minimum values, or how the score is scaled, is crucial for us to accurately interpret the results provided by the API.",
        "Hi Nobutaka,\n1. For scoring, we are using a custom algorithm which is a combination of the weighted sum of text scoring (bm25 variation), vector similarity, field-specific language analyzers, etc\n\n2. scores are not bounded because they are calculated relative to other documents in the index, based on factors like term frequency and inverse document frequency. This allows for more accurate ranking and relevancy of search results.",
        "Thank you Surendra, both are clear to me."
    ],
    "spaces/AAAABcXBTWI/threads/UnHns9cZw-s": [
        "When I call the SearchAssist API from XO with generative AI enabled in SearchAssist, how do I know how many Answer Fragments I need to iterate through? Is there a field that says the number?",
        "Hi Matt, to limit the search results, we have a key in the payload with maxNumOfResults\n\n{\n \"query\": \"Is system up?\",\n\"maxNumOfResults\": 1\n}",
        "That affects how the answer is broken up or number of possible file matches. My issue is the single answer is broken up across several fragments. I can account for it with some JavaScript but wasn‚Äôt sure if there was an easier way",
        "@Surendra Subhash Salke this is what I mean:",
        "\"data\": [\n              {\n                \"snippet_title\": \"\",\n                \"snippet_content\": [\n                  {\n                    \"answer_fragment\": \"To clean your Thirsti Beverage System, follow these steps:\\n\\n1. Create a cleaning solution by combining 12oz. of water and 12oz. of white vinegar in the water reservoir. \",\n                    \"sources\": [\n                      {\n                        \"title\": \"WC1000 Series Ninja Thirsti‚Ñ¢ Beverage System Owner's Guide\",\n                        \"url\": \"https://support.ninjakitchen.com/hc/en-us/article_attachments/9379849967260#page=5\",\n                        \"chunk_id\": \"chk-3779bcd9-3e0c-41ce-8f8c-62107fc4d48c\",\n                        \"doc_id\": \"fc-bc7e238e-125a-50e0-a2c4-954325224aab\",\n                        \"source_id\": \"fs-fe02326f-eeec-5432-9bf6-a82f43bd6504\",\n                        \"source_type\": \"file\",\n                        \"image_url\": \"\"\n                      }\n                    ]\n                  },\n                  {\n                    \"answer_fragment\": \"\\n2. Place the water reservoir with the cleaning solution on the docking station. \",\n                    \"sources\": [\n                      {\n                        \"title\": \"WC1000 Series Ninja Thirsti‚Ñ¢ Beverage System Owner's Guide\",\n                        \"url\": \"https://support.ninjakitchen.com/hc/en-us/article_attachments/9379849967260#page=5\",\n                        \"chunk_id\": \"chk-3779bcd9-3e0c-41ce-8f8c-62107fc4d48c\",\n                        \"doc_id\": \"fc-bc7e238e-125a-50e0-a2c4-954325224aab\",\n                        \"source_id\": \"fs-fe02326f-eeec-5432-9bf6-a82f43bd6504\",\n                        \"source_type\": \"file\",\n                        \"image_url\": \"\"\n                      }\n                    ]\n                  },",
        "The generative response is split across multiple answer_fragments. To print it out I would need to iterate across all of the answer_fragments",
        "I've seen this too and had to write code to iterate in order to present the whole answer. Curious if we can update the prompt to provide this in 1 snippet",
        "Would love to have that in the SE - Tools GitHub space. Either as an example bot or in the javascript examples repo.\n\nKore.ai Sales Engineer Tools",
        "var message = \"\";\nvar result = context.snippet.data[0].snippet_content;\n¬†for (i=0;i<result.length;i++){\n¬†message = message + context.snippet.data[0].snippet_content[i].answer_fragment\n¬†};\n¬†message = message + \"\\n\\n*Reference:*\\n \" + context.snippet.data[0].snippet_content[0].sources[0].title\nprint(message)",
        "That's with one reference",
        "John - for the message variable, I updated it to also include the link:\n\nmessage = message + \"\\n\\n*Reference:*\\n [\" + context.snippet.data[0].snippet_content[0].sources[0].title + \"](\" + context.snippet.data[0].snippet_content[0].sources[0].url + \")\";",
        "var message;\nvar result=context.session.BotUserSession.DocumentResult\nif(result){\n¬† ¬† if(context.snippet){\n¬† ¬† ¬† ¬† message=\"Here are some more articles which might help you.\\n\"\n¬† ¬† }else{\n¬† ¬† ¬† ¬† message=\"Unfortunately I am unable to generate an answer for this query. \\n\"\n¬† ¬† }\n¬† ¬† for(var i=0;i<result.length;i++){\n¬† ¬† ¬† ¬† var url=result[i][\"default_action\"][\"url\"]\n¬† ¬† ¬† ¬† var msg= (i+1)+\") \" + result[i].title+\"\\n *More info:* [Click Here](\"+ url +\")\\n\\n\"\n¬† ¬† ¬† ¬† message +=msg\n¬† ¬† }\n} else {\n¬† ¬† message='I am sorry there are no results found matching your request'\n}\nprint(message)",
        "Thanks all, just couldn't get my brain wrapped around it last night at 1:30 AM after getting a 138 PDF implementation working",
        "That is for the reference documents",
        "Gurpreet - for voice interactions, I leave all references off and just read the snippets",
        "Sorry, I am late to the party here. The approach suggest by gurpreet and John is a right way to do it."
    ],
    "spaces/AAAABcXBTWI/threads/zJQHPI1Kv50": [
        "I'm reposting for visibility as I must respond to the client today. I appreciate any help you can provide.\n\nAnswering a questionnaire for a Search Assist opportunity. Would you happen to know these answers? \n\n1. Addition/Removal/Version Control of data sources from context data\n\n2. Analytics Dashboard like Cost, Requests, Context Tokens, Generated Tokens and Cost",
        "@Kevin Mullay \n\nThe question #1 is a little vague/open ended. \n\n#1\nSearchAssist provides complete control to the enterprises on how the content from data sources is ingested into the application. Some of the key capabilities are (a) Content Filters - Enterprises can choose the type of content that they would like to ingest. For example, we can sync content from specific sites of Sharepoint or specific type of documents from shared drive etc. (b) Enterprises can also choose how and how often the content should be synchronized from the source systems and (c) SearchAssist also provides a powerful content enrichment and content management Workbench. Using this, enterprises can pre-process every document and choose to exclude it from ingesting, modify certain parts or part, enrich with additional context et.c\n\n#2 - SearchAssist stores complete information on how LLMs are used for answering. This includes the date and time of when the call was made, time  took to get the response, response nature (success/failure), tokens consumed (context, request and response) etc. \n\nMost of #1 is currently available in the product. Certain parts will be added in the next couple of months\n\n#2 is partially available during design time. We are extending this to cover end user interactions. This will also be available by end of March.",
        "@Aditi Bhadouria @Surendra Subhash Salke @Rohit Tambe",
        "@Santhosh Kumar Myadam, thank you. I agree they are vague and will ad a disclaimer in our response."
    ],
    "spaces/AAAABcXBTWI/threads/DTQy0EIBGko": [
        "I'm probably missing something obvious, but is there logging of who made what changes and when?  Specifically, if someone modifies the LLM prompt, how can I see what changes were made and who made them?  I can't find any documentation on change logs.",
        "@Graeme Dean audit log feature is in the development. \n\n@Aditi Bhadouria @Rohit Tambe",
        "Hello @Graeme Dean Currently not, but we will have it by the end of March'24"
    ],
    "spaces/AAAABcXBTWI/threads/goWvuXasvaY": [
        "Shout out to the SearchAssist team for all the work you have done for us. I am so glad you are being acknowledged for your all your efforts!",
        "Thanks a lot @David Gwartney We know, there are miles to reach, but these kind words motivate us."
    ],
    "spaces/AAAABcXBTWI/threads/Q911mR8KAoE": [
        "Great Job SearchAssist Team and Thanks for your help Always!"
    ],
    "spaces/AAAABcXBTWI/threads/6GXczOiuddg": [
        "@Sales team, @SE team and the @CS team, thanks a lot for all the encouragement. Your questions, clarifications helped us understand that this evolving product is growing demand. On behalf of the entire team, I thank you for your cooperation, patience and the inputs. üôèüôè"
    ],
    "spaces/AAAABcXBTWI/threads/EMB7s0yKqVM": [
        "Working on an RFP and it has the following question - \"What is the Multilingual Performance: Accuracy and response time metrics for different languages supported by the LLM?\" - do we have any metrics around this or do we see any variance between languages?  Any feedback/thoughts on best response would be appreciated.",
        "Reposting - this is the last question left in this RFP and I‚Äôd like to get it closed out - shirt turnaround - any feedback or help would be appreciated.  Thanks."
    ],
    "spaces/AAAABcXBTWI/threads/HrfX3NndUY4": [
        "Hello @Graeme Dean we do not have any benchmark results for multilingual"
    ],
    "spaces/AAAABcXBTWI/threads/Wdgozs_hDz0": [
        "Response can be ‚ÄúSearchAssist provides hybrid search capabilities which includes the lexical search and sentence embedding based search on multilingual data. This search capabilities are very fast and respond under a second. The extractive responses are return under a second, while in the Generative responses, The generation of answers is done using the OpenAI and the latency depends on the OpenAI api responses.‚Äù"
    ],
    "spaces/AAAABcXBTWI/threads/r_9XydXKPv4": [
        "Or"
    ],
    "spaces/AAAABcXBTWI/threads/wAS4rn53Nt8": [
        "‚ÄúSearchAssist provides hybrid search capabilities which include the lexical search and sentence embedding based search on multilingual data. \n\nThe 'extractive answer' will provide responses under a second. \n\nThe 'generative answer' uses LLMs and the answer generation depends on the availability and latency of the underlying models.‚Äù"
    ],
    "spaces/AAAABcXBTWI/threads/Unb8i_lKKvA": [
        "Hey Guys, is there any way a bot can respond on different channels based on the Caller‚Äôs  (voice call) question. Imagine someone calling from a landline (a store employee), asks an FAQ and the bot responds over call (responds from the \ningested FAQ docs in SearchAssist), however, when on the same call, he asks for troubleshooting steps to fix say a POS (point of sale) machine in the store, the bot responds over an email with troubleshooting steps (from the ingested troubleshooting guides in SearchAssist)? The idea is to respond right there for short answers and send emails for long troubleshooting steps, to fix a specific issue. Note: caller will be calling from a landline, not a mobile phone. They don‚Äôt have access to internet."
    ],
    "spaces/AAAABcXBTWI/threads/HGsgQsh5fu0": [
        "@Aditi Bhadouria @Rohit Tambe üëÜüèªüëÜüèª",
        "LMK if this is supported or can be done."
    ],
    "spaces/AAAABcXBTWI/threads/9jUoHZasZRI": [
        "Use combination of XO and SearchAssist for this",
        "Thanks @Girish Ahankari for confirming! Thats exactly the plan but I wanted to make sure it is doable."
    ],
    "spaces/AAAABcXBTWI/threads/oFqU8VJd_bo": [
        "team I am trying to enable search assist for a bot, however when I build the curl to test it in postman I get code 400 Malformed JSON"
    ],
    "spaces/AAAABcXBTWI/threads/NCKxlIni-Y8": [
        "this is the curl I import"
    ],
    "spaces/AAAABcXBTWI/threads/cSyQ3jPTIMQ": [
        "curl --location -g --request POST https://searchassist.kore.ai/searchassistapi/public/searchAssist/stream/st-7f75ba9d-27de-5f86-87aa-14a195e5bdcb/sidx-2d5e44ce-769b-53bd-aaa0-c8ff3fb062c2/fullSearch' \\\n--header 'auth: eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJhcHBJZCI6Int7Y3MtYTA1Mzc2NWUtOWE3Ny01OWRhLWI2MWYtZjg2MTY0M2ZmNDAyfX0ifQ.tS8ICdnRoBNeK0VD2OLjtEsdwdrVfdwGdSIF0Gbbt2s' \\\n--header 'Content-Type: application/json' \\\n--data-raw '{\n\"query\":\"O√π et comment sont livr√©es les cartes Ticket Restaurant¬Æ ?\",\n\"maxNumOfResults\":4¬†\n}'",
        "curl --request POST 'https://searchassist.kore.ai/searchassistapi/public/searchAssist/stream/st-7f75ba9d-27de-5f86-87aa-14a195e5bdcb/sidx-2d5e44ce-769b-53bd-aaa0-c8ff3fb062c2/fullSearch' \\\n--header 'auth: eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJhcHBJZCI6Int7Y3MtYTA1Mzc2NWUtOWE3Ny01OWRhLWI2MWYtZjg2MTY0M2ZmNDAyfX0ifQ.tS8ICdnRoBNeK0VD2OLjtEsdwdrVfdwGdSIF0Gbbt2s' \\\n--header 'Content-Type: application/json' \\\n--data-raw '{\n\"query\":\"O√π et comment sont livr√©es les cartes Ticket Restaurant¬Æ ?\",\n\"maxNumOfResults\":4 \n}'"
    ],
    "spaces/AAAABcXBTWI/threads/Sr5OF7hrIxM": [
        "can someone help me identify and fix this problem?",
        "@Akhil Sainath Maddala @Vishwas Tak can you please help with this?\n @Surendra Subhash Salke"
    ],
    "spaces/AAAABcXBTWI/threads/OIEGY26qwpU": [
        "Please enable the API scopes if you have not done already.",
        "Please check this for creating the jwt token",
        "@Prabhat Singh",
        "API scopes done",
        "do you want me to share the bot with you?",
        "can you please use following API doc \nhttps://searchassist.kore.ai/searchassistapi/public/api-docs/#/Public%20Apis/post_searchassistapi_external_stream__streamId__fullsearch\n\nPlease use /external API instead of current /public",
        "why in the document is not mentioned this",
        "will try now",
        "can you please update my curl just to make sure",
        "I have the right one",
        "This curl is for the sample application \n\ncurl -X 'POST' \\\n¬† 'https://searchassist-pilot.kore.ai/searchassistapi/external/stream/st-ca93944d-bb59-5abb-ac32-52e2bc2c248f/fullsearch' \\\n¬† -H 'accept: application/json' \\\n¬† -H 'auth: eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJhcHBJZCI6ImNzLWZjNGEwMjM3LWU1NDEtNTBkZC04NWExLWI1ZGRiMmE3MmJkZCJ9.e8LnQYRej2vv_VkyU27st8HM_8Tz-iwS6ovNbkNppKA' \\\n¬† -H 'Content-Type: application/json' \\\n¬† -d '{\n¬† \"query\": \"Autogenerate\",\n¬† \"maxNumOfResults\": 3,\n¬† \"customData\": {\n¬† ¬† \"userContext\": {\n¬† ¬† ¬† \"userId\": \"u-5b315536-082b-51d8-b552-4819d34b5a4e\"\n¬† ¬† }\n¬† }\n}'",
        "also would be good if you can try it before you send it to make sure is working",
        "I tried just now and I get the same error message",
        "Sorry!, update the curl. I was puzzled how I missed the quotation mark in curl, and equally puzzled about why seasoned SE couldn't catch and fix it.",
        "@Prabhat Singh Please help us create detailed, developer-friendly documentation of linking the SA application to the Xo bot.\n\n @Santhosh Kumar Myadam  @Aditi Bhadouria  @Rohit Tambe \n\nhttps://docs.google.com/document/d/1AY04sMQ_PBHsCYPRLa0WoaiHHJng7RVq42eHG4H6pUE/edit",
        "@Surendra Subhash Salke We have published the documentation for this.  @Shruti Kukkar could you check what more details can be included?\n\nhttps://docs.kore.ai/searchassist/how-tos/integrate-xo-bot-with-searchassist/",
        "We need to replace /public api with /external API",
        "guys I cannot make this work",
        "is anybody who can get on a call with me to help me",
        "I have a demo tommorrow",
        "It is already /external in the published doc https://docs.kore.ai/searchassist/how-tos/integrate-xo-bot-with-searchassist/",
        "I created this curl:",
        "curl --location -g --request POST 'https://searchassist.kore.ai/searchassistapi/public/searchAssist/stream/st-7f75ba9d-27de-5f86-87aa-14a195e5bdcb/fullSearch' \\\n--header 'auth: eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJhcHBJZCI6Int7Y3MtYTA1Mzc2NWUtOWE3Ny01OWRhLWI2MWYtZjg2MTY0M2ZmNDAyfX0ifQ.tS8ICdnRoBNeK0VD2OLjtEsdwdrVfdwGdSIF0Gbbt2s' \\\n--header 'Content-Type: application/json' \\\n--data-raw '{\n\"query\":\"Quelle est la dur√©e de validit√© d'une carte Kad√©os ?\",\n\"maxNumOfResults\":2\n}'",
        "still doesn't work same error",
        "I am using postman to check the API call",
        "I am trying with another application and it works fine",
        "Also partner feedback is when I use searchassist to ask and get answers is taking too long",
        "is there anything we can do to perform faster?"
    ],
    "spaces/AAAABcXBTWI/threads/waaXcpODC20": [
        "Hi team, I have a client who wants to display an image when answering a question from the FAQs, is there any way to do this with SearchAssist and XO Platform?"
    ],
    "spaces/AAAABcXBTWI/threads/IGDSVxClx7g": [
        "Ya it‚Äôs possible. Check with demo team or SE team, they can help you"
    ],
    "spaces/AAAABcXBTWI/threads/r3scyy2GIsY": [
        "That‚Äôs great! Thank you!"
    ],
    "spaces/AAAABcXBTWI/threads/eQxoAyRxoOI": [
        "Images are displayed using markdown. The message builder allows you to click a button to provide the text and url link to the image."
    ],
    "spaces/AAAABcXBTWI/threads/iWOMt8W9GE4": [
        "Search for images in this page for the specific format for including an image in various output. \n\nhttps://www.markdownguide.org/basic-syntax/"
    ],
    "spaces/AAAABcXBTWI/threads/uwg39c5wiYc": [
        "I am making an API call to searchassist using the XO API integration with SearchAssist and whatever I ask it times out, here is the error:   \"statusCode\": 421,\n  \"status\": 421,\n  \"customCode\": \"ResolverError\",\n  \"errors\": [\n    {\n      \"msg\": {\n        \"cause\": {\n          \"code\": \"ESOCKETTIMEDOUT\",\n          \"connect\": false\n        },\n        \"isOperational\": true,\n        \"code\": \"ESOCKETTIMEDOUT\",\n        \"connect\": false\n      },\n      \"code\": \"ResolverError\"\n    }\n  ],\n  \"_headers\": {},\n  \"message\": {\n    \"cause\": {\n      \"code\": \"ESOCKETTIMEDOUT\",\n      \"connect\": false\n    },\n    \"isOperational\": true,\n    \"code\": \"ESOCKETTIMEDOUT\",\n    \"connect\": false\n  },\n  \"name\": \"ResolverError\"\n}"
    ],
    "spaces/AAAABcXBTWI/threads/7NfZ9Sm4Or4": [
        "any ideas on how to solve this"
    ],
    "spaces/AAAABcXBTWI/threads/0-qrIHILgqc": [
        "?"
    ],
    "spaces/AAAABcXBTWI/threads/VPpMfu1HTGM": [
        "I tried to increase the timeout on the service which is doing the API call, but maximum I can do is 20 seconds"
    ],
    "spaces/AAAABcXBTWI/threads/QaKm35KPM80": [
        "any ideas"
    ],
    "spaces/AAAABcXBTWI/threads/c6q_FDHwvy8": [
        "Can u share you script or service node config screenahoot?"
    ],
    "spaces/AAAABcXBTWI/threads/q9i-euF2fq0": [
        "This has been resolved now"
    ],
    "spaces/AAAABcXBTWI/threads/a5F4FWCxPAM": [
        "thanks"
    ],
    "spaces/AAAABcXBTWI/threads/G7LuOCeE_vQ": [
        "this is my webclient for searchassist"
    ],
    "spaces/AAAABcXBTWI/threads/JyNC8Yse0GI": [
        "https://searchassist.kore.ai/webclient/310d74aa28574e55b2d59468a6d464aff75e2349d5a54993ab5ae508c7eb60b1st7f",
        "We are checking"
    ],
    "spaces/AAAABcXBTWI/threads/szxohTJliUw": [
        "but it seems to load forever"
    ],
    "spaces/AAAABcXBTWI/threads/O4prOW0Q6F4": [
        "I tried on two of my lpatops"
    ],
    "spaces/AAAABcXBTWI/threads/qEJJVVE9Eak": [
        "and different browsers"
    ],
    "spaces/AAAABcXBTWI/threads/yLYKWAkQw5g": [
        "can you guys try too"
    ],
    "spaces/AAAABcXBTWI/threads/_aeNAuKu3cs": [
        "@Andrei Zaharia it appears that the channel is currently disabled in the searchassist application. Could you kindly navigate to Manage > Channel and enable the channel ."
    ],
    "spaces/AAAABcXBTWI/threads/ZWO7HoXmF6c": [
        "indeed"
    ],
    "spaces/AAAABcXBTWI/threads/gFh6LbJ4534": [
        "this fixed"
    ],
    "spaces/AAAABcXBTWI/threads/fRQN9Fr-YX8": [
        "I am not sure how this got turned off"
    ],
    "spaces/AAAABcXBTWI/threads/BqE3PA3rpSo": [
        "@Rohan Chaurasia i also have the same issue but i got the following error when try to login to enable the channel:",
        "Can you share the error from Network tab?"
    ],
    "spaces/AAAABcXBTWI/threads/-H2dilUA4eA": [
        "Can SearchAssist ingest documents in Greek?",
        "Yes you can for demos. As languages for answers are supported by embeddings and LaBSE supports 100+ languages. When the deal is finalised you can raise a FR for this and we will QA test and add it to the product.  \n\nAdditionally here is a comprehensive explanation of SearchAssist features for your reference.",
        "thank you @Aditi Bhadouria , I tried option 3, and Azure Open AI GPT 4 -  the results are not great. is there any other recommendation on how to deal with this",
        "for questions such as what is Student Life Account I get better outcomes from Knowledge AI",
        "of course these questions are asked in Greek",
        "Have you enabled the language in index settings?¬†\nhttps://docs.kore.ai/searchassist/personalize-results/answer-snippets/#Multilingual_Support_for_Generative_Snippets"
    ],
    "spaces/AAAABcXBTWI/threads/H9SCzF5GfRo": [
        "My apologies if this has been asked before.\n\nDoes SearchAssist support the presentation of Images in answer snippets? If not is this capability on the road map?",
        "This is part of the roadmap but not currently supported"
    ],
    "spaces/AAAABcXBTWI/threads/IRKaL2uWHlU": [
        "How does answer from documents work? Is it a similar architecture to the RAG arch used by searchassist? But instead of a search, does the platform send all the uploaded documents along with a prompt and the user's query to the LLM?",
        "@Gurpreet Singh \nANswer from Docs in the XO also works on similar lines - Yes, like light RAG. It does chunk the content, retrieves similar chunks and uses LLMs to generate answer\n\nHowever, it has limited capabilities - number of documents, type of content, extraction abilities, control on retrieval mechanism and control on the answer generation. \n\nIt is a 'beta' feature. Recommendation is to use SearchAssist for all RAG use cases.",
        "gotcha. So there IS a retrieval (ie. search) element against the vector databased to retrieve the right chunks to send to the LLM. So the entire files are not being sent, huh? Cool thanks.",
        "and yes, I agree SearchAssist is the way to go, which is much more flexible.",
        "Are there any use cases where using Answers is recommended for clients?",
        "Assuming Answers refers to Answers from Docs, not really. We marked that feature as beta. Soon after gpt 3 was launched, we tried to develop rag framework in Platform and SearchAssist. We very soon realized Seais a more natural fit. Hence no further improvements were done in the Platform. \n\nIt is a tested by a few customers but I don't think anybody enabled it for production in platform.",
        "Ok thanks for explaining. So any reason why we are emphasizing XO Answers in our documentation? Even this space. Or does XO answers refer to something else other than Answer from Documents?",
        "XO Answers is the new branding for SearchAssist. \n\nWhich documentation are you referring to?",
        "I guess I assumed xo answers was answers from documents. Maybe because this space name is SA + XO Answers, even though they‚Äôre the same thing. But now I get it. Thanks for the clarification.",
        "üòÉ"
    ],
    "spaces/AAAABcXBTWI/threads/PGswlsTHb8Y": [
        "Like a RAG light approach?"
    ],
    "spaces/AAAABcXBTWI/threads/OLNfFjRtqFI": [
        "I'm helping a prospect define success criteria with SearchAssist.  Does anyone have a document that you can share with me, defining SearchAssist success criteria?",
        "@Sathya Priya Turaga can you take this up please"
    ],
    "spaces/AAAABcXBTWI/threads/IMelbs5FnEE": [
        "@Team - was there a change deployed on the SearchAssist platform in the last day or two? My search app, a simple one with 9 uploaded pdf's, configured with Azure OpenAI, was providing perfect responses, but no longer works."
    ],
    "spaces/AAAABcXBTWI/threads/DgBztpBT1xY": [
        "happy to share the app and test use cases if someone can take a quick look.",
        "Yesterday, I changed it to my public API key, and it worked."
    ],
    "spaces/AAAABcXBTWI/threads/-y8doP1LkJk": [
        "5 out of the 20 chunks were sent but not used for the Gen answer:"
    ],
    "spaces/AAAABcXBTWI/threads/C2MxKMcxYJs": [
        "Sure Girish, @,melissa will send you by tomorrow EOD IST.",
        "Hi sathya , I have a meeting with the customer shortly. Can you please share success criteria for search assist?",
        "@Melissa Prince Did you receive this?",
        "just shared with you @Jordan Bostick",
        "@Melissa Prince me too please"
    ],
    "spaces/AAAABcXBTWI/threads/j2BsixRJTXA": [
        "@Sathya Priya Turaga Kindly post the success criteria here, as these will surely be useful for many of us."
    ],
    "spaces/AAAABcXBTWI/threads/bCidAy8DKpQ": [
        "If I have a linked bot with a SearchAssist App, when I open searchAssist widget for searching, shouldn't the Welcome task and the fallback tasks be triggered?",
        "@Andrei Zaharia \n\nIf the bot is front-ending then it will work as you described. User can choose to define when to call SearchAssist via the Service Node.\n\nIf SearchAssist is front-ending then we use the bot only for triggering the tasks identified from user input. \n\n @Aditi Bhadouria  @Rohit Tambe"
    ],
    "spaces/AAAABcXBTWI/threads/phyUQC3M64w": [
        "How do we stack against Lucy.ai on search?"
    ],
    "spaces/AAAABcXBTWI/threads/slTvFONngGU": [
        "CBRE is an active deal with Searchassist opportunity and looking for any competitive intel against CBRE",
        "Hello @Gopi Polavarapu We have not reviewed lucy.ai fully. I had a glance and feel that Lucy is focused only on Employee data and answering from the ingested data via connectors. This is move like Eva which is also employee focused.\n\nSearchAssist is a platform which can be used for both Employee cases and consumer cases. For example, Lucy cannot be used for answering the content on your website. \nWe will do more research on this, but there is not much of a content available on the website. Does anyone have detailed writeup or slides of Lucy?"
    ],
    "spaces/AAAABcXBTWI/threads/OquqFFXylmo": [
        "https://www.lucy.ai/"
    ],
    "spaces/AAAABcXBTWI/threads/LvOMxBGlc1g": [
        "Does SearchAssist pull in metadata like Role Based Access Control info from sources like Sharepoint or Cherwell?  \nOne of our customers (Columbia Sportswear) is looking to pull their Role-based Access Controls  from their source CMS (Cherwell) into SearchAssist so their Employees searching in SearchAssist dont' get access to documents that they shouldn't.  cc:  @David Gwartney",
        "Yes, this can be done through business rules, workbench and metaData field in the chunks.¬†These are the design time features that help in achieving RACL. More importantly at run time, the correct user id needs to be sent to SearchAssist while making the search call. This will have to be done through the webSDK. If the user id is different in the CMS and the webSDK custom implementation will be required to map the user ids. E.g. userid in webSDK= XYZ@123 and userid in CMS= XYZ@gmail.com.¬†Additionally user groups in the CMS will also need some additional implementation effort as different connectors have their own definition of groups."
    ],
    "spaces/AAAABcXBTWI/threads/PHAx7WEXw8Q": [
        "@Girish Ahankari @Gopi Polavarapu Lucy.ai has been reviewed by @Hari Krishna Poludasu before",
        "someone has reached out to us for acquisition interest for lucy.ai. I have forwarded that email thread to you guys. Here is the summary they shared \n------\n\nWe wanted to bring to your attention an acquisition opportunity of a Generative AI-powered enterprise search and knowledge management platform.\n¬†\nLucy, based in Minnesota, is an advanced enterprise answer engine providing the right answer to the right person at the right time ‚Äì regardless of where information resides. The answers provided include a synopsis produced through Generative AI and specific citations down to the page level with the source material. It integrates with the existing assets of the organization to eliminate the tedious task of uploading and tagging content. The platform through its automated integrations, learns and remembers the data stored across the users‚Äô internal files and systems and connects to many popular third-party subscriptions. The company has the connectors to bring together enterprise data into a single searchable index and allows for training and tuning of data via reinforcement learning and unsupervised learning. This B2B enterprise SaaS is in its 4th generation and has included GPT as a feature since Feb 2022. Additionally, to support mass automation of data processing, the company has developed Bluesky, a proprietary indexing & tagging engine that processes and continuously synchronizes with vast pools of rapidly changing enterprise information spread across various directories and systems of owned and licensed data.\n¬†\nKey highlights:\n\t‚Ä¢\tExtensive integrations, 50+ connectors to a variety of systems including SharePoint, Teams, Azure, SAP, Workday, ServiceNow, SFDC, PowerBI, Tableau\n\t‚Ä¢\tAbility to search through structured and unstructured data, including MS Word, PPT, PDF, Infographics, Excel, Wiki‚Äôs, Text, Audio, Video and more\n\t‚Ä¢\tIncreased efficiency and effectiveness by reducing 25% knowledge worker time looking for content\n\t‚Ä¢\t5 issued patents used to provide cutting-edge digital transformation\n\t‚Ä¢\tISO/IEC 27001 certified and is compliant with GDPR and CCPA in accordance with emerging international data security regulations\n\t‚Ä¢\tDiversified Fortune 1000 customer base (ex. PepsiCo, Kraft, Haleon and 84.51 | Krogers), catering to companies in various industries, with use cases across departments\n\t‚Ä¢\tARR of $2.8M, expected to reach $6.6M by 2024; burn is now ~$20k / month\n\t‚Ä¢\tFounded by seasoned entrepreneurs and led by experienced team, covering all facets of finance, sales, product development, customer support and marketing\n\t‚Ä¢\tEarned significant recognitions including AdAge winner of \"Tech to Watch\" and Gartner‚Äôs \"Cool Vendor\""
    ],
    "spaces/AAAABcXBTWI/threads/YvryCxFfOSk": [
        "Hi Team,\n\nI have a question from a client about the definitions of the footer of the Sample CSV in \"Import FAQs\" screen.\nDo you know what should they input or can they leave it as it is?\n\n'''\nconditions  conditionId value   contextType operator    contextCategory\n'''",
        "Please leave it as is. This is for conditional questions"
    ],
    "spaces/AAAABcXBTWI/threads/tE_0cyVzT74": [
        "fullSearch API is currently VERY slow and throwing 504 gateway timeouts or 426 socket timeouts for me consistently. is there something going on with the API layer?",
        "@Girish Ahankari this is preventing work on actual demos, there appears to be something going on with the platform. normally these queries resolve in a second or less. consistently getting timeouts calling even in Talk to Bot."
    ],
    "spaces/AAAABcXBTWI/threads/bao5OudVCzY": [
        "@Girish Ahankari @Melissa Prince @Frederic Lam Please find the document that describes success criteria for Search Assist Implementations https://docs.google.com/document/d/1ab5DVsR5pPb-4oU4MXf3r8IAZby1uh-Cy3m8CqP82UM/edit?usp=sharing"
    ],
    "spaces/AAAABcXBTWI/threads/nRHiGQoUIC0": [
        "Checking",
        "Hi @Curtis Swartzentruber API performance appears normal in prod. Can you please share the curl for further investigation."
    ],
    "spaces/AAAABcXBTWI/threads/yArADXSjo-I": [
        "OpenAI has partial outage. Is this a possibility for delays in responses?\n\nhttps://status.openai.com/"
    ],
    "spaces/AAAABcXBTWI/threads/_wGFwrTkDX8": [
        "@Rohan Chaurasia @Surendra Subhash Salke Have we found the root cause?"
    ],
    "spaces/AAAABcXBTWI/threads/LZEjk_T7GR8": [
        "@Curtis Swartzentruber are you using OpenAI?"
    ],
    "spaces/AAAABcXBTWI/threads/-NShQn3E5B0": [
        "Azure cognitive services are fine\nhttps://azure.status.microsoft/en-gb/status"
    ],
    "spaces/AAAABcXBTWI/threads/0ZfeyIsUxY4": [
        "If its OpenAI issue, may be you can shift to Azure OpenAI"
    ],
    "spaces/AAAABcXBTWI/threads/oJ1t14IhnnY": [
        ":) @Santhosh Kumar Myadam we typed almost at the same time"
    ],
    "spaces/AAAABcXBTWI/threads/2W76vkrh7vQ": [
        "Let‚Äôs confirm if its indeed an issue with OpenAI"
    ],
    "spaces/AAAABcXBTWI/threads/5ZktQqjhky4": [
        "@Curtis Swartzentruber is your application \"streamName\": \"EdenRed Demo\"?",
        "no - that's one that @Andrei Zaharia was working on"
    ],
    "spaces/AAAABcXBTWI/threads/IVrKV9Zpcpk": [
        "I am assisting Andrei. The app name is ERed, but not sure if the stream name is something different. The app is set up with both OpenAI and Azure OpenAI. Rohan is invited to the app now and reviewing"
    ],
    "spaces/AAAABcXBTWI/threads/7oYr7N7yULg": [
        "I have a customer that stores all their documents in Salesforce. The documents include .pdf, .doc and .xls formats. Successful testing was done with uploaded documents and the customer wants to confirm that the exact same functionality is available when using the connector. Are there any known limitations to SA functionality caused by the use of the SFDC connector rather than file upload? I say it's the same regardless, but wanted to check...",
        "You're right John. All ingested data will be treated same irrespective of the source type. A known limitation with connectors is that, each connector their own definition of various groups for documents (Sites, containers, drive etc). Which leads to issues with the ingestion in certain cases. You can refer to our documentation for details on what is supported specifically for Salesforce.",
        "Please share the documentation link. @Aditi Bhadouria",
        "https://docs.kore.ai/searchassist/manage-content-sources/connectors/salesforce-connector/",
        "@John Nicholson You can use the SFDC APIs to extract the document files and then use the new upload file APIs in search assist. See the SearchAssist API documentation for details",
        "Thanks David. The question is can I use the documents where they are now or will I be forced to upload?  Based on you response, it sounds like I can use the SFDC documents one way or the other regardless..."
    ],
    "spaces/AAAABcXBTWI/threads/RYGX16up0eU": [
        "I tried both Azure and OpenAI and the result is the same, timeouts on both"
    ],
    "spaces/AAAABcXBTWI/threads/aJVZxsZMOxE": [
        "i found there is an timeout issue today as below:"
    ],
    "spaces/AAAABcXBTWI/threads/ki5PNxU1w1k": [
        "chunks are splitted properly ..."
    ],
    "spaces/AAAABcXBTWI/threads/sCY_bRzPgPI": [
        "Sharing the document prepared by SeachAssist team that covers SearchAssist AI implementation across various clients like IDFC Bank, Huntington Bank, Alaska Airlines, Thomson Reuters, eBay, and Deutsche Bank. This compilation of client experiences maps SearchAssist capabilities to tangible use cases, while revealing key pain points that prospects can relate to. Understanding these intersections will help you to have more meaningful conversations grounded in customer needs or make implementations successful.\n\nHere are the highlights of the document: \nCommon use cases are:\nAnswering customer service FAQs from bank websites to reduce call volumes\nAssisting contact center agents with tailored responses to customer queries\nExtracting insights from documents like insurance policies and emails to auto-categorize and respond\nCustomizations done to improve implementations involve:\nCrawling client websites using sitemaps to ingest all pages\nConfiguring connectors to ingest data from sources like SharePoint, Azure, ServiceNow\nWriting painless scripts to extract FAQs, tables, metadata from complex documents\nSome key issues faced during deployments are:\nInaccuracies in answer snippets leading to low relevancy\nFailures in crawling or data extraction due to site restrictions\nSearch failures due to special characters or expired connectors\nFixes to the above problems required:\nRe-crawling sites to refresh expired URLs\nTuning of search relevance settings including increasing result counts, using synonyms, updating prompts, and applying business rules to boost key content\nImproving extraction by writing custom scripts, reconfiguring connectors, ingesting complex data as structured data, and checking chunk extraction.\n\nhttps://docs.google.com/document/d/13A2XPB2Y4tjeE9xE1veY4FbD0VhRym9E-_b3S2o7Mho/edit?usp=sharing",
        "@Aron Kurzinski @Louie Garrovillo @Zeena Greene - valuable stuff for our training & SKO build",
        "@Manav Khandelwal @Reilly Hughes"
    ],
    "spaces/AAAABcXBTWI/threads/vxEnjaCcIVI": [
        "@Prasanna Arikala hi,  can we neutralise this document and create case study snippets from this till marketing provides full fledged published case studies? Goes without saying that we shall share the output for review.",
        "Yes",
        "Ok thx."
    ],
    "spaces/AAAABcXBTWI/threads/gGmOjjKhg9o": [
        "@Marcel Korst @Michael Kropidlowski @Lynda Smith"
    ],
    "spaces/AAAABcXBTWI/threads/x7tUlRpfboc": [
        "Team,\nI have the following ask from a customer: Where can I find this info?\n\nSearch Assist Product Capabilities\nKoreAI's product literature/implementation best practices (re: data sources, security, data crawling, generative AI etc.) with regards to enabling SearchAssist\nreference of other clients (irrespective of industry/domain) for whom you have enabled this functionality"
    ],
    "spaces/AAAABcXBTWI/threads/wt-CR0HgC6A": [
        "Our partner Persistent, included this slide in their deck to my prospect. Do you agree with these bullets?",
        "I was literally just searching for where I read this - about the maximum number of pages per document! \n\n @Surendra Subhash Salke  @Rohit Tambe  @Aditi Bhadouria also very interested here. Especially on page size.",
        "Moving this up for visibility. Your insight would be appreciated",
        "Hi @Kevin Mullay @Laurence Schoultz \n\nThis was true 6 months ago, but it's not true anymore. This was meant for internal stakeholders and is not meant to be shared with clients. \n\nCurrently we provide multiple solutions if the OOTB extraction model has any issues. \n\n1. Third-party IDP: Clients can use an external IDP  and then push the extracted data into SearchAssist via structured data API\n\n2. Custom Utility: Clients can use a custom utility developed by Kore to intelligently extract PDF documents. There is a comprehensive read me file available. We are working on the documentation. https://github.com/surendra-koreai/SearchAssist-Public-Utilities/tree/main",
        "@Aditi Bhadouria thank you. On the point about maximum number of pages in the document. If a client has documents in a Sharepoint where some have 40 pages for example is this going to be an issue?"
    ],
    "spaces/AAAABcXBTWI/threads/We-l1c5M5js": [
        "How would I set up a webcrawler for this site: https://www.guidanceresources.com/groWeb/login/login.xhtml ? It is  login protected, and I tried to configure the login details but unable to make it work.  I can share the app with someone that can look at the existing config. The login creds are already set, but I can provide those if needed."
    ],
    "spaces/AAAABcXBTWI/threads/jIj7968BD7o": [
        "Team - when using connectors for ServiceNow, do we only synchronize new content, or pull in all content every time it is scheduled (or manuall triggered)",
        "We get all the contents from the source (serviceNow), but only new and updated contents are reingested.",
        "ok thanks. Any documentation on this?",
        "We will add this to the documentation @Gurpreet Singh Thank for pointing it out. cc: @Shruti Kukkar \n\nFYI, the way this is accomplished is by checking the timestamp of the documents. If there is an update in the document then the entire document is re-ingested and indexed again. This is true for all connectors but not for web crawl. For web crawl we reindex all the webpages. We are working on a feature that helps in doing incremental crawl.",
        "Ok thanks that is very helpful. üôè"
    ],
    "spaces/AAAABcXBTWI/threads/KFwT4oF9q0o": [
        "I wasn't able to find documentation on this."
    ],
    "spaces/AAAABcXBTWI/threads/3-UwcfwlQEg": [
        "@Surendra Subhash Salke @Sunil Singh I do not agree with this. We cannot force our limitations on Partners and Customers. I am sure we have already addressed some of them. Can we update this and reshare with everyone? Also update the documentation. @Aditi Bhadouria please track this and discuss with me if required"
    ],
    "spaces/AAAABcXBTWI/threads/iiKc52jCiGY": [
        "@Girish Ahankari  @Kevin Mullay\n\nThis was before externalizing the extraction utility. \n\nNow with custom utility developer will have full control over the extraction. \n\nWe should not include this slide in the presentations anymore.",
        "Hi Girish I did update Kevin and Laurence regarding this to their previous message . I‚Äôll sync up with you as well"
    ],
    "spaces/AAAABcXBTWI/threads/E680RRQ7yfA": [
        "Posting the reply again for everyone‚Äôs reference. \n\n\nHi @Kevin Mullay @Laurence Schoultz \n\nThis was true 6 months ago, but it's not true anymore. This was meant for internal stakeholders and is not meant to be shared with clients. \n\nCurrently we provide multiple solutions if the OOTB extraction model has any issues. \n\n1. Third-party IDP: Clients can use an external IDP  and then push the extracted data into SearchAssist via structured data API\n\n2. Custom Utility: Clients can use a custom utility developed by Kore to intelligently extract PDF documents. There is a comprehensive read me file available. We are working on the documentation. https://github.com/surendra-koreai/SearchAssist-Public-Utilities/tree/main"
    ],
    "spaces/AAAABcXBTWI/threads/-x_xHmuIpDU": [
        "I still get the timeout issue in Searchassist today since two days back. Anyone has the same issue ?"
    ],
    "spaces/AAAABcXBTWI/threads/2jCRdR6RAHo": [
        "i create another new account and the result is the same @Aditi Bhadouria"
    ],
    "spaces/AAAABcXBTWI/threads/3oc5EantCKg": [
        "Yes, I have been having the same problems"
    ],
    "spaces/AAAABcXBTWI/threads/qMvIDQGRU0w": [
        "This issue is from the LLM provider side. I tried testing it myself with different queries. I am getting an answer right now, but I wasn't getting an answer for certain queries a few minutes ago. We'll find a way to make the experience more consistent for such scenarios"
    ],
    "spaces/AAAABcXBTWI/threads/-1SIFpsSZcc": [
        "I'm seen that when I use GTP4, the responses are VERY slow. So I'm using 3.5 instead. Much faster."
    ],
    "spaces/AAAABcXBTWI/threads/R7CNw-JcD-g": [
        "Also, I'm defaulting to OpenAI (not Azure) and it's been much faster"
    ],
    "spaces/AAAABcXBTWI/threads/bOk_rSIixWs": [
        "Hopefully someone can help me out...\n\nI am trying to crawl these two sites https://mhe.my.site.com/macmillanlearning/s/article/Student-Student-Store and https://mhe.my.site.com/macmillanlearning/s/achieve\n\nOnce its complete I train it and notice the chunks dont have any real information to them, and each one says Loading √ó Sorry to interrupt CSS Error Refresh\n\nHere is a quick video I recorded https://www.loom.com/share/5aeda8df4a634939bcbf953808355502",
        "I have seen this on many sites. Opened a ticket 6 months ago. Only suggestion I can make is to enable javascript rendering.",
        "Thank you for the reply David, I did the Java script rendering",
        "@Surendra Subhash Salke Did you guys not improve the crawl output to show more details about why the crawl failed and what are the alternatives to solve it?",
        "Hi @Prasanna Arikala \n\nThe story to improving the web crawler failure message and suggesting next steps is under qa validation and is due release mid end of Feb.\n\nBut issue David reported can be solved by adding a crawl delay. I confirm this and get back to you and David",
        "Thank you @Surendra Subhash Salke I have a tentative demo scheduled for Macmillan planned for February 27th. They want to see our ability to crawl their sites and produce answers. We are competing with many CAI providers in the space who are demoing to them this upcoming week. @Frederic Lam",
        "@David Taglieri please enable javascript rendering in the crawler configuration and set\ndev_enable_crawl_delay  to 9 In the custom configuration (under query configuration).\n@Bharadwaj for more help on this.\n\n@Aditi Bhadouria please  help productize crawl delay\n\nCC: @Girish Ahankari @Prasanna Arikala",
        "@Surendra Subhash Salke is this delay custom setting documented in Beta features document for now?",
        "@Akhil Sainath Maddala Can you please add crawl delay in the beta feature if not already present.",
        "@Surendra Subhash Salke Added!\ncc:  @Umang Shah"
    ],
    "spaces/AAAABcXBTWI/threads/8Mg_U2ZhFhc": [
        "Team, I have a client that wants to 1) process an inbound PDF (100 pages) and reorganize the pdf pages (based on their requirements) for their internal process use, and 2) later in their process let users use our search capabilities to query information from that specific PDF. Can these be done?",
        "What is the underlying problem they are trying to solve with this capability?",
        "There are any number of APIs and libraries that can rearrange pages.",
        "Help with looking up info from large docs. Productivity gains",
        "The rearranging is interesting. I think it also helps them find info easier.",
        "bump",
        "For context, this is for a claims process. The insurance company gets these 100 page documents that are compiled by the provider (doctors office), and the pages are all mixed up and not in the order that is required by the insurance company in order for their people to effectively \"process\" it. Also, trying to find info from a long 100 page document is time consuming, hence search assist capability at play here. \n\nAdvice?",
        "I've been told by the SearchAssist team that there is an Azure service that can reformat documents, such as consistently apply headers, fonts, etc. in order to provide reliable, structural context. I wasn't told the name of said service, but its existence was supposed to favor SharePoint over Drive.\n\nMaybe Azure AI Document Intelligence? https://azure.microsoft.com/en-us/products/ai-services/ai-document-intelligence"
    ],
    "spaces/AAAABcXBTWI/threads/fv4oaA2q0gM": [
        "Are there storage fees or limits for search assist documents?",
        "@Girish Ahankari"
    ],
    "spaces/AAAABcXBTWI/threads/cgUv9zxr5t8": [
        "Yes. Please reach out to Peter W. he will share the pricing info and limita",
        "@Kevin Mullay The current ingestion limit is 100 docs for each \"fee\" The new fee isn't 100% final yet so I won't quote the dollars, but it's going to be ~$100 per 100 docs",
        "So, there is a SearchAssist license cost, session fee and also a fee based on how many docs you have?   Is this \"storage\" for our index of their docs / vector database, etc from their sharepoint (for example)?  Or are you talking about uploaded PDFs?",
        "There's no license cost of which I am aware - AND remember that search assist pricing isn't final yet.\n\nI believe that the ingestion fee is for uploads but will let  @Peter Wulfraat confirm"
    ],
    "spaces/AAAABcXBTWI/threads/nlwf4qZb4oc": [
        "I know we have Workday.com integration for HRAssist.  Have we integrated with Workday's KB via SearchAssisst?  Or XO platform, etc.?  We have a prospect:  Caliber Collision interested in HRAssist and SearchAssist (primary use cases IMHO) with Workday as their LMS (KB)."
    ],
    "spaces/AAAABcXBTWI/threads/BAdif6NQAdU": [
        "Hi Tim - let‚Äôs have a meeting to go over this. We do have integrations with workday for core HR. Lms usually are talent use cases. We had built a custom demo for delta.  Happy to hop on a call to discuss.",
        "Please can I join, we have a customer requiring Workday integration",
        "@Swapna Oundhakar I‚Äôd love to be included in this discussion. As you know I‚Äôve been talking to WDAYs VP of AI and I have Fortune100 media company working on the same; a WDAY bot from Kore.  Might be more efficient to have one bigger convo then two but it‚Äôs up to you and @Tim Burke",
        "We already met @John Brandes for Caliber Collision. Happy to meet with you as well.",
        "For Caliber, we are still unclear as to Kore's ability to integrate with WDay's other modules like their LMS.   I think we may have done something, but to what degree, what limitations?  Etc."
    ],
    "spaces/AAAABcXBTWI/threads/w31vCAfAMEI": [
        "I have a question about Role Based Access Controls.  From my understanding.  We do have it available in XO but not yet in SearchAssist to limit who can see which docs.  But I also saw a workaround IF the docs were named certain ways, etc. using variables.  Not sure what the Roadmap timing is on this for Search Assist.   Can anyone shed some light on this for me?  \nMy prospect asks: Can the dataset be categorized according to distinct contexts?\nAre there access control measures available for categorizing confidential or restricted information, meaning not every user can access all contexts‚Äîfor example, limiting certain information only to authorized or designated users?",
        "@Surendra Subhash Salke  - I see in the Features doc that there are \"access controls\" of some sort. How different is this from RBAC?  How can I explain our Access controls features? Is there a good doc to explain?  I don't see it on the documentation web site: https://docs.kore.ai/searchassist/.",
        "Hi @Tim Burke the infrastructure to enable RBAC is built within searchassist. (@Shruti Kukkar) We will share you a \"How To\" documentation limit certain uses group from accessing certain resources very soon.\n\n\nCurrently we are developing RACL part-2 which allows connector (e.g gdrive, SharePoint) file permissions to be honoured at searchassist. @Aditi Bhadouria \n\n\n@Shruti Kukkar please plan \"how to\" article on RACL.",
        "Thanks.  I think the whole SE team could benefit from this discussion once you have documentation.",
        "@Surendra Subhash Salke, Can you post the how-to doc here?",
        "@Andy Pham This is work in progress. Will be able to share in the next few days. \n\n  @Aditi Bhadouria  @Rohit Tambe",
        "@Tim Burke @Santhosh Kumar Myadam was this shared? Can you pls post it here or forward email? Thanks!",
        "Answer from @Aditi Bhadouria  stated: \nRACL¬†is a feature we are currently developing. But it has a lot of nuances and will be rolled out in phases. I think it's important to highlight the details of each phase to you, and probably¬†good to tell the customer as well. I'll let you take the call there.¬†\n\nPhase 1:¬†RACL¬†support with implementation work required.¬†\nThis is already available and can be achieved via Business Rules and¬†Metadata. At design time, we will ingest the list of user identities that have access to a document along with the document as metadata. At run time, the client will be responsible for passing the correct identity and identity groups for a user as metafilter, based on which SearchAssist will filter the documents¬†and return the answer.¬†\n\nPhase 2:¬†RACL¬†support directly integrated with connectors (Tentative ETA July; we will try to deliver it sooner if feasible)\nAs part of phase 2, we will pull in the associated permissions of a document directly¬†from the connector along with each document. Additionally, we will also pull in all the information related to various user identities, groups, etc, and maintain it within SearchAssist. We will have a configuration where the client can select how often they want to sync this list. So, at runtime, we would just need the user identity, and SearchAssist will be able to filter the content and provide the answer. This could be passed as user context and doesn't need metafilters to be configured.¬†\n\nPhase 3:¬†RACL¬†support with a mapping between unique user identities\nThis is not fully thought out yet, and we don't have any solid timelines around it. But here, we want to allow the clients to configure a mapping between user identities. For example,¬†abc@gmail.com¬†in Google Drive, and abc@123 in Confluence. The actual user identity shared as part of the search call¬†abc@outlook.com. Additionally, we also want to allow clients to manually create the identities and map it to documents. Again to clarify we can not commit anything for Phase 3 or when it will be available, this is just a high-level overview.¬†\n\nI hope that is helpful. Let me know if you have any more questions."
    ],
    "spaces/AAAABcXBTWI/threads/M2pFYAL43G4": [
        "Where can i  find the spec of NL2SQ?",
        "@Sunny Lun \n\nHere is the documentation link\n\nhttps://docs.kore.ai/searchassist/personalize-results/nlp-rules/\n\n @Shruti Kukkar",
        "@Santhosh Kumar Myadam is there any way that I do not require define the pattern under the NLP rule sand use the LLM to resolve the intent?",
        "@Shruti Kukkar  , @Santhosh Kumar Myadam May I know if you have any ideas?  eg if the users ask \"pls show me the washing machine that is in the price range of 1000 to 2000 and has the energy saving, red color and made in Germany.\", the prospect expects the zero shot can understand the utterance and hence fetch the corresponding records from our indexes in which the data are coming from the backend."
    ],
    "spaces/AAAABcXBTWI/threads/kJavReQWq9c": [
        "Confluence \n\nTeam, are Confluence labels tagged to KB-articles taken into account during SearchAssist indexing? The aim is to use these tags in Business Rules for contextualisation. Here is a screenshot of the labels I'm referring to:",
        "Please check if these variables are available in the document.json in the workbench stages by simulating few confluence docs",
        "@Surendra Subhash Salke so when I go into the document.json in the connector I can see the 'labels' but I cannot see them in Workbench. \n\n{\\\"editor\\\":\\\"\\\",\\\"atlas_doc_format\\\":\\\"\\\",\\\"export_view\\\":\\\"\\\",\\\"styled_view\\\":\\\"\\\",\\\"dynamic\\\":\\\"\\\",\\\"storage\\\":\\\"\\\",\\\"editor2\\\":\\\"\\\",\\\"anonymous_export_view\\\":\\\"\\\"}},\\\"metadata\\\":{\\\"labels\\\":{\\\"results\\\":[{\\\"prefix\\\":\\\"global\\\",\\\"name\\\":\\\"bike\\\",\\\"id\\\":\\\"33131\\\",\\\"label\\\":\\\"bike\\\"},{\\\"prefix\\\":\\\"global\\\",\\\"name\\\":\\\"policy\\\",\\\"id\\\":\\\"33133\\\",\\\"label\\\":\\\"policy\\\"},{\\\"prefix\\\":\\\"global\\\",\\\"name\\\":\\\"netherlands\\\",\\\"id\\\":\\\"131212\\\",\\\"label\\\":\\\"netherlands\\\"}],\\\"start\\\":0,\\\"limit\\\":200,\\\"size\\\":3,\\\"_links\\\":{\\\"next\\\":\\\"/rest/api/content/98459/label?next=true&limit=200&start=200\\\",\\\"self\\\":\\\"https://koreai-ls.atlassian.net/wiki/rest/api/content/98459/label\\\"}},\\\"_expandable\\\":"
    ],
    "spaces/AAAABcXBTWI/threads/qgOZTWCoXV0": [
        "I heard that on the Alaska Pilot there were testing tools developed to help testing and validation when will these tools be made generally available?",
        "https://github.com/surendra-koreai/SearchAssist-Public-Utilities/tree/main/Evaluation",
        "It's in beta hence not yet moved under organisation account",
        "@David Gwartney can we use this for Columbia Sportswear?",
        "I have read through the setup but have not deployed yet. But likely yes we can use this for the Columbia project.",
        "@Surendra Subhash Salke  we should move it under org account and provide links in the app for this under \"tools\" section in the UI",
        "Sure @Prasanna Arikala.\n\nWe will complete this migration by tomorrow.",
        "@David Gwartney  good news for Columbia Sportswear that these testing tools will be available as of Tuesday 2/27",
        "Hello @Surendra Subhash Salke can you provide the Testing tool link in Github assuming its been migrated?  cc @Sathya Priya Turaga @David Gwartney",
        "https://github.com/surendra-koreai/SearchAssist-Public-Utilities/tree/main",
        "https://github.com/Koredotcom/SearchAssist-Toolkit\n\nHi @Prasanna Arikala \nPublic utilities are moved under organisation account",
        "super"
    ],
    "spaces/AAAABcXBTWI/threads/hGWodrriJgM": [
        "Hi, can someone let me know what is the limit of file sizes and the number of files which can be imported into structured data: https://docs.kore.ai/searchassist/manage-content-sources/managing-structured-data/ there is no mention of such limits in our documentation.",
        "Structured data is in JSON or CSV format so you can't upload files there. I have not seen any file limitation there but text files are usually very small anyways."
    ],
    "spaces/AAAABcXBTWI/threads/VV5Ag6xYNic": [
        "Question from Accenture, can we read information from cold / blob storage?",
        "?"
    ],
    "spaces/AAAABcXBTWI/threads/lnTqqfv-_y4": [
        "@Joseph Forster What is this with respect to relational databases? NoSQL? Cloud storage. Any additional details would help?",
        "Usually the cold storage will be used to store unstructured data, like archived files from share point or local drive. ¬†No relationships with relational dB.",
        "Relation DBs do have blob storage so that is why I asked. There is typically going to be APIs to access the data for example like S3. I am wondering if they are referring to S3 Glacier.\n\nThe bigger question is why do they want do perform these reads from the virtual assitant?",
        "Sorry, that was the prospects response",
        "Ill ask!"
    ],
    "spaces/AAAABcXBTWI/threads/f2zNed94jcg": [
        "Usually the cold storage will be used to store unstructured data, like archived files from share point or local drive. ¬†No relationships with relational dB."
    ],
    "spaces/AAAABcXBTWI/threads/i6UlQOgzTok": [
        "Can we import the chunks into the SearchAssist for Document AI purposes?",
        "https://docs.kore.ai/searchassist/public-apis/searchassist-apis-list/#Ingest_Data_API"
    ],
    "spaces/AAAABcXBTWI/threads/uljsZYEgkHc": [
        "Hello, can we implement SearchAssist in an on-premise, Air-Gapped environment for a DOD supplier?  We have a request from BAE Systems."
    ],
    "spaces/AAAABcXBTWI/threads/w-a91a7BT74": [
        "I have a client that needs to identify and track the source document of the answer returned from SA by a reference number that is assigned to every unique document in their knowledgebase. Can SA be configured to capture the reference number and return it as part of the metadata in the response?"
    ],
    "spaces/AAAABcXBTWI/threads/vbCKSce4c9M": [
        "When SearchAssist has the SFDC connector enabled and it is ingesting documents does it also ingest the data fields associated with the articles in SFDC?",
        "@Santhosh Kumar Myadam @Rohit Tambe @Surendra Subhash Salke @Aditi Bhadouria Appreciate your kind inputs on the above? üëÜ",
        "I have the exact same question for another opportunity. Hoping someone will reply...",
        "For all connectors under the content tab we show the actual json of the data we have pulled in for each document. You can refer to that and check if the data you are referring to has been ingested or not. \n\nPost that you can refer to this for how to utilise it. https://docs.kore.ai/searchassist/how-tos/how-to-use-custom-fields-to-write-business-rules-on-search-results-and-answers/"
    ],
    "spaces/AAAABcXBTWI/threads/1kyy6milNBQ": [
        "Hello, can we implement SearchAssist in an on-premise, Air-Gapped environment for a DOD supplier?  We have a request from BAE Systems."
    ],
    "spaces/AAAABcXBTWI/threads/IYcCmFe_zrc": [
        "I am engaged in an opportunity where their customers/users have two personas - Instructors and Students\n\nThese two user types will interact with the VA and ask it questions which will return an answer from a crawled webpage.\n\nA Student might ask \"I don't know how to access to my digital product\" and SearchAssist will provide an answer and display this link - https://mhe.my.site.com/macmillanlearning/s/article/Student-Store-How-do-I-get-access-to-my-digital-product-after-I-ve-purchased\n\nAn Instructor might ask \"How do I add a TA to my course\" and SearchAssist will provide an answer and display this link - https://mhe.my.site.com/macmillanlearning/s/article/Achieve-Add-a-TA-or-co-instructor-to-your-course\n\nHowever there are times that an Instructor and a Student will ask the same question like, \"My grades are missing from Canvas?\" In this case we don't know who is asking the question and there are separate type answers. For a students an answer from link https://mhe.my.site.com/macmillanlearning/s/article/LMS-integration-troubleshooting-for-students should be displayed and for an Instructor an answer from link https://mhe.my.site.com/macmillanlearning/s/article/Instructors-Troubleshoot-deep-integration-with-Canvas should be displayed\n\nThey don't want to ask the user upfront whether they are a student or instructor, they want it to happen \"naturally\" in the flow of the conversation. \nExample \n(User): \"My grades are missing from Canvas?\" \n(VA): Are you a student or instructor?\n(User): I am an instuctor\n(VA): GenAI provides an answer in XO referencing this location https://mhe.my.site.com/macmillanlearning/s/article/Instructors-Troubleshoot-deep-integration-with-Canvas out of the two above links.\n\nSo there are really 3 paths\nAsk question and answer is displayed\nSame question is asked with two possible different answers for each persona\nProvide only the Instructors answer if the requester is an instructor asking \nProvide only the Students answer if the requester is an Student asking \n\nAny thoughts on how to accomplish this? I am willing to get on a live call to discuss and explain but I thought I would drop the question in here first.....\n\nWhat's been already completed? I have already built a SA application, built a VA in XO and I can pass data between the two - I ask an utterance, it uses the dialog tasks Search Documentation listed in intent not found and displays an answer --> This part works fine.",
        "Start by asking @Matt Panaccione about this as he recently did something similar for a retail client. If I understand correctly, he was able to pass a contextual parameter from the VA to SA to help identify relevant documents to search. \nI'm struggling to understand how an agent (live or virtual) would know the difference between student and instructor without asking. One method would be to set context tags based on a flow or intent that is unique to each group. Otherwise, the bot will need to access the GPT-clairvoyant feature (roadmap 2050) ü§£",
        "In the use case I did was:\n\n-Connect SearchAssist via API within XO.\n-Create an array with the last question asked.\n-Create a context variable concatenated with the last question.\n-Send in an API call to SearchAssist\n-If the student is satisfied with the answer, I clear the variable and start all over again.",
        "@David Taglieri you can either make the bot ask if the user is a student or instructor and pass that as a metafilter to SearchAssist while making the search call. \n\nOr a better user experience could be if you could capture the user identity through the login/browser etc and pass it as user context while making the search call. Then you would have to set up business rules to define which identity should get answers from which documents. For this you would also need some metadata as part of the ingested content.¬†\n\nExample: \n{usercontext: student}\nBusiness rule: If usercontext=student then filter documents where  \"access=student\"\n\nThis would work given that you have the appropriate field in each document to identify which document has access for which users",
        "Thank you @Aditi Bhadouria for your input, However the opportunity wants to know if there is a way or rather doesn't want to ask the user upfront if they are a student or instructor or doesn't want to have the user to have to log in. \n\nThey only want to ask the user if they are a student or instructor \"if\" the same question is asked by both and has two separate answers, one for student and a different one for the instructor. \n\nIf the student asks a question and this question pertains to only a student then they are presented with the answer. If the question can be asked by an instructor or student then present them with clarifying questions to confirm what role the person is and then present the appropriate answer to them."
    ],
    "spaces/AAAABcXBTWI/threads/v0BFqKi20YM": [
        "Do we have updated architecture diagrams for SearchAssist? These two look more like \"marketecture,\" and may not pass scrutiny at a Q4 prospect."
    ],
    "spaces/AAAABcXBTWI/threads/W3fCsipyvlM": [
        "(continued)"
    ],
    "spaces/AAAABcXBTWI/threads/JvnVT3RCFsk": [
        "Also, I believe the new name is \"Search AI\""
    ],
    "spaces/AAAABcXBTWI/threads/zMpgeH7BNZ8": [
        "@Surendra Subhash Salke @Girish Ahankari Do you have updated architecture slides we can share with a prospect.  They are looking at other solutions and trying to make a quick decision.",
        "@Surendra Subhash Salke will respond soon. He is currently handling an escalation",
        "This has been handled by Surendra in a separate chat. Thank you!",
        "@Surendra Subhash Salke Can you please provide the details here? I would also need them for a prospect.",
        "Hi Fred, Here are the diagrams provided to me by Surendra",
        "Thanks.  Will work with my SE on these."
    ],
    "spaces/AAAABcXBTWI/threads/w55bQqMkjpQ": [
        "Get Content API\n\nTeam, could you quickly validate my understanding. Would this API also return records configured in the 'FAQ' section under sources? The documentation states 'Structured data', but I would posit that FAQ falls under this categorisation. \n\nhttps://docs.kore.ai/searchassist/public-apis/searchassist-apis-list/#Get_Content",
        "From what I am seeing it is just structured data using this bash script:",
        "Sample output from above",
        "Thank you, @David Gwartney. Appreciate it!",
        "Hey @Aditi Bhadouria do you know if there is anyway to get the configured FAQs content by API currently? If not, when will the Content API be updated to support other Content types like FAQ.\n\nCan we do this with: https://docs.kore.ai/searchassist/public-apis/searchassist-apis-list/#Get_Content_by_Condition\n\nsys_content_Type = faqs?",
        "I'm trying to use Get-Content-By-Condition in Postman but getting SDK credential issues. AdvancedSearch and Content APIs working fine."
    ],
    "spaces/AAAABcXBTWI/threads/VN2XUD31fI4": [
        "Is there a list of roadmap connectors? Not necessarily with dates of when they will be implemented, even a list of connectors that are currently contemplated. It would be great to also be able for us to give feedback on what has been asked.",
        "@Matt Panaccione We will publish this tomorrow and on Monday include timeline for each",
        "Thanks Girish, that is super helpful.",
        "@Girish Ahankari @Matt Panaccione I may have missed it (so many information sources üôÇ), but was there an update on this documentation?",
        "I haven't seen anything. @Girish Ahankari let us know where we can find the information. Thanks!",
        "@Matt Panaccione - I t was in the deck posted this morning in this main space by Aditi",
        "9:49 am Eastern",
        "Ah! Missed that"
    ],
    "spaces/AAAABcXBTWI/threads/sVdZxeDnn20": [
        "@Girish Ahankari is working on this now."
    ],
    "spaces/AAAABcXBTWI/threads/sqXrskRQaEI": [
        "We just signed a prospect (Adtalem), and they want to do some self-paced learning. They will be using a search bot for their agents. Ideally, they want all their agents to be familiar with Generative AI. They were poking around on Kore Academy and didn‚Äôt see any Gen AI stuff as it relates to SearchAsssit. Do we have any training I can point them to? Thanks"
    ],
    "spaces/AAAABcXBTWI/threads/pzqHbvWo_lQ": [
        "I need some help regarding SearchAssist pricing.  I'm working with a prospect that would like to roll this out to 7K employees but I need guidance on how to price out the search assist product, or even an excel template that I can use to play with the numbers to know what this would look like.  Any help is greatly appreciated."
    ],
    "spaces/AAAABcXBTWI/threads/2LbmfJd2YyM": [
        "@Melissa Prince pls talk to @Peter Wulfraat he is getting ready to roll out new pricing which include EX pricing per user for XO platform, Agent AI and Search AI also."
    ],
    "spaces/AAAABcXBTWI/threads/bQX2_G8-j38": [
        "Already replied to mphasis and copied Peter. mphasis wanted to know if there is a different pricing for on-prem deployment. The only thing i see is the search doc ingestion fee of \"$70.00 per each 100 pages ingested\" which is an initial/one-time fee when documents are first uploaded to kore.ai. Is this search doc ingestion fee the only difference between on-prem and cloud deployment? i.e. it would be waived for on-prem deployments? (presumably?)  @Peter Wulfraat"
    ],
    "spaces/AAAABcXBTWI/threads/0YFuvecsEds": [
        "Question from client about pulling content from a specific ServiceNow knowledge base into SearchAssist:\n\nSpecifically, we have been waiting for documentation on only pulling one ServiceNow knowledge base, rather than the entire thing. We are looking to pull the knowledge base titled ‚ÄúEnd User‚Äù. Below are various paths, we weren‚Äôt sure what the scraper could work with.\n\nElement: <input id=\"articleKnowledgeBaseName\" type=\"hidden\" value=\"End User\">\nJs path: document.querySelector(\"#articleKnowledgeBaseName\")\nrel XPATH: //*[@id=\"articleKnowledgeBaseName\"]\nfull XPATH: /html/body/div[2]/input[19]",
        "This feature is in the roadmap and not yet available. We will explore filtering it based on the path you have mentioned",
        "@Aditi Bhadouria did this feature get added? LSEG (current paying client) want to run a fast experiment to ward off ServiceNow's RAG solution, but they don't want to share their whole Knowledge Base with us, just a specific one as @Gurpreet Singh requested above."
    ],
    "spaces/AAAABcXBTWI/threads/a9UMpAC4U0M": [
        "I am I am trying to understand what languages SearchAssist can generate answers in? I see this in the documentation but that is for indexing languages, not generating answers, correct?\n\nhttps://docs.kore.ai/searchassist/manage-indices/index-languages/",
        "I believe answers can be generated in any language that the underlying LLM supports (Azure OpenAi). Enable any two languages in the index settings (seems to work regardless of which second language you enable). I‚Äôve tried in Dutch and Slovak, works well."
    ],
    "spaces/AAAABcXBTWI/threads/xZUqcbMxxvA": [
        "I have an XO VA connected to a SearchAssist app using the search as a fallback.  I am getting some answers returned incomplete.  What am I doing wrong with the configuration?  See Screenshot.",
        "@Tim Burke Check your SA response to see if it is broken into more than one answer snippet. The default message node only returns one snippet. If this is the problem, I have code that will fix it.",
        "Good call.  Thats likely it.  I think I have three chunks?",
        "What does that response look like in the result sent to the bot? That's where it gets tough. Can you post the bot action service node result?",
        "This came from the Novartis demo sample code",
        "Tim go into debug mode and check the context object for the service node Json result and post it here",
        "{\"finalResolver\":{\"userInput\":\"What's the right way to clean the pepsi fountain?\",\"winningIntent\":[{\"activityType\":\"ANSWER FROM DOCUMENTS\",\"state\":\"configured\",\"autoGeneratedAnswer\":\"The right way to clean the Pepsi Ice Beverage Combo Fountain, as per the provided weekly cleaning guide from Pepsi Equipment Service, is as follows:1. Turn the key switch to the off position.2. Remove the nozzles and diffusers for all valves by turning them counterclockwise and pulling down.3. Separate each nozzle from its diffuser and rinse all parts with warm water.4. Soak the nozzles and diffusers in sanitizing solution for 60-90\",\"documentSearchResponse\":[{\"documentName\":\"Weekly Cleaning Guide of Pepsi Fountain.pdf\",\"uploadName\":\"Weekly Cleaning Guide of Pepsi Fountain\",\"pageNumber\":2,\"documentId\":\"ke-d44fd0d2-d8da-58e7-870f-6e519c8ce815\",\"similarityScore\":0.7445657874692158},{\"documentName\":\"Weekly Cleaning Guide of Pepsi Fountain.pdf\",\"uploadName\":\"Weekly Cleaning Guide of Pepsi Fountain\",\"pageNumber\":1,\"documentId\":\"ke-d44fd0d2-d8da-58e7-870f-6e519c8ce815\",\"similarityScore\":0.7324233979562402},{\"documentName\":\"How to Prepare Sanitizing Solution.pdf\",\"uploadName\":\"How to Prepare Sanitizing Solution\",\"pageNumber\":1,\"documentId\":\"ke-64fb1d04-9181-5f3a-968d-9ae5ebb38fff\",\"similarityScore\":0.575894474935948}]}]}}",
        "Thanks @John Nicholson for the assist!  Turns out, I had recently integrated SeachAssist as the fallback for this project.  But I had failed to remove my old Knowledge from Docs in the XO project.  So it was still pulling from there, and as such... truncating.   I removed those KfromDocs files and republished, all good now!"
    ],
    "spaces/AAAABcXBTWI/threads/iD2ACQVkDk8": [
        "Any issues with https://searchassist-pilot.kore.ai/accounts/? I am having trouble logging in.",
        "Yes, Andy, it seems there is an issue with the pilot login. \nWe are currently investigating it.",
        "How is the investigation?",
        "It's fixed. Please try logging.",
        "Rohan, also the standard banking demo is not working in that environment: https://docs.google.com/document/d/1TODKWq42CfgrpxEwCKWs2nBJEuX_CkdAMh8-DTLfSYI/edit?usp=drive_link",
        "@Rohan Chaurasia, I was able to log in, but I couldn‚Äôt access my connector. \n\nError: Connector API Fail"
    ],
    "spaces/AAAABcXBTWI/threads/qrBh7qXIBmU": [
        "Team, i am unable to find SearchAssist Onprem Architecture, Installation guide and capacity planning guide. can someone share it with me?",
        "Hi Sandeep,\n\nThis is a minimal configuration deployment.\n\nhttps://docs.google.com/drawings/d/1kypKlLt53iDfHlMJ5aJghnbA5UPesw4mhotowSxlwfo/edit"
    ],
    "spaces/AAAABcXBTWI/threads/_SBXvXczPEw": [
        "Hi Team, appears that SearchAssist Pilot is failing to Train. I am using Generative Answers, have tried OpenAI and Azure Open AI but it makes no difference. I get training failed in the log and no chunks. I have an urgent demo to prepare for so a fast response will be appreciated. Was working before.",
        "for me, the Pilot environment USED to be the best. But for the past 2 months, the Prod environment seems to be more stable.  Can you rebuild it there?  I saw where others are saying the Pilot environment is moving slow. Must be having issues??",
        "Agreed Tim. This is the second time it has happened. Looks like an issue with the chunk DB. I have lost chunks in all my other projects. I have raised a support ticket so will give it a little while. If I hear nothing then I will move.",
        "We are checking",
        "Not to pile on but I am seeing the same thing",
        "The system is recovering in phases.",
        "Will it take a long time?",
        "~ 20 min",
        "OK. Thanks.",
        "Please check if you can see the chunks",
        "System Health is yellow. Run time GenAi queries should work now.",
        "Yes. They have magically reappeared! Thanks for your help.",
        "Generative answers are now working again üôÇ",
        "@Surendra Subhash Salke what is in place to monitor health of both pilot and production environments.  Is there a notification system that indicates there are issues that someone should be aware of?",
        "There is tremendous productivity loss to SEs when the system is degraded or not performing well.",
        "It was disconcerting to learn that I couldn't demo minutes before my scheduled meetings. I understand this is just a growing pain. No worries!"
    ],
    "spaces/AAAABcXBTWI/threads/8ntk2fSTTUo": [
        "Team,\n\nI know we have the ability to search Sharepoint sites. Do we know if that includes aspx pages within Sharepoint or whether we have any issues with processing those?",
        "@Jon McCain aspx pages are supported for Sharepoint",
        "Thanks!!!"
    ],
    "spaces/AAAABcXBTWI/threads/7s7ywHS-TmY": [
        "Hi Guys, my SA instance is taking over 40 seconds to respond, from the ingested FAQ / Websites I ingested for the past couple of hours. What settings can I re-configure to accelerate the response times?",
        "Not sure if it is related:",
        "Disable streaming",
        "Related to assistants but you never know",
        "Thanks @David Gwartney .. however, I couldnt find it on my website (https://demo.kore.ai/searchassist-config/botdemo2/demo/index.php?id=58)",
        "Sorry was not clear this is in the open ai console. Again I think my issue was with the assistant api and not completions",
        "@Navdeep Grover are you using Azure OpenAI or OpenAI and which model?",
        "I'm also experiencing this - the delay ranges from 20 seconds to 2 minutes. \n\nUsing Azure OpenAI, GPT4 (Sales Engineer team credentials). Model - 2023-09-15-preview",
        "Azure",
        "@Aditi Bhadouria ^^",
        "We have observed higher latency with Azure OpenAI. If you use OpenAI with GPT 3.5 you will get a response quicker. As all services are up and running this is most likely not an issue from SearchAssist‚Äôs side.",
        "Thanks! not only the speed has improved but the responses are also more natural with OpenAI integration!",
        "I feel like the SE API document should be updated to reflect the above statement - at the moment, it only provides an Azure key for SearchAssist.  Which would suggest that the recommended method is Azure.  @Aayush Mediratta  or @Alenis Fiallo could that doc be edited to add the statement from Aditi above and recommend the SE generate their own OpenAI key and test both?  Could help with new hires and prevent moments like the above. Or is there a reason we only have the Azure key in that doc? \nhttps://docs.google.com/document/d/1mYxGWrIucnv5dVYiOTZ9ynrwhS6n3oQuOXGfwxhuOdE/edit?usp=sharing",
        "@Girish Ahankari is this the recommendation?",
        "@Aayush Mediratta \n\nUntil recently, Azure Open AI showed better response times. \n\nFrom the past few weeks, we've observed that Azure's responses are either failing or taking longer than usual. \n\nOpen AI's responses continue to perform same as before or doing better.",
        "Interesting.. @Tim Burke any issues with creating openai key? You have access right?",
        "@Aditi Bhadouria @Surendra Subhash Salke Can we just display the time taken by Generative AI LLM somewhere - just to make it easy for anyone to understand when it is not performing",
        "@Prasanna Arikala We are developing this feature as part of the Answer Analytics Story in SearchAssist. It will be released early next month as part of R1.2.1.",
        "@Prasanna Arikala Currently we show the completion time as part of the answer debug while testing. But this will only be visible to the user after the response is rendered.¬†\n\nAs @Surendra Subhash Salke already mentioned we are also planning to show this info through Analytics in the future releases. \n\nMeanwhile we will explore sending an automated message every 10-15 seconds to inform the user that we are waiting for the LLM to respond to enhance the user experience."
    ],
    "spaces/AAAABcXBTWI/threads/-mSfjrUK2L4": [
        "Hello Everyone \n\nI wanted to share a deck that contains details of the key activities we are focusing our efforts on, along with the plan for upcoming connectors, and the RACL framework for everyone's reference.Please let us know if you have any questions.¬†\n\n @Girish Ahankari  @Santhosh Kumar Myadam \nhttps://docs.google.com/presentation/d/1g1OiEPPpQmjU4D1oa_z2aNaSGtLNUHqHoQSPdQpV27k/edit?usp=sharing",
        "@Aditi Bhadouria PNC has raised the following FR https://koreteam.atlassian.net/browse/FR-1611 which is needed for optimization of the sync process using SalesForce Connector. Can we prioritize this feature request?",
        "Sure. I will let @Rohit Tambe communicate the ETA for this one",
        "@Shantanu Ghorai I have shared the details for FR1611 over the email",
        "@all note that this roadmap is only for cloud based connectors and not for the OnPrem versions of individual connectors. If any enterprise is using any on prem version of these, then reach out to us separately",
        "As each enterprise might be using a different version nd might have different APIs, Auth mechanism used, we will support those on the need basis. By default we will support the latest versions of these which are in GA in cloud",
        "Are there any plans for \"Custom Connector\"?",
        "Already there is API to ingest the content.  So, anyone can build a connector outside and push the content into SearchAssist using API",
        "@Aditi Bhadouria , thanks for sharing the info with us. We have raised and FR for Box.com and it was there in roadmap also but don't see currently on the list of connectors that will be available in future which you have shared.\n\nBox.com has a big market share and all our existing customers use it.\nFR was raised last year and was told by team that they will have it in future. \n\nhttps://koreteam.atlassian.net/browse/FR-1203\n\nbelow is the roadmap slide snapshot where Box.com is also named",
        "@Sandeep Singh Rana I will update the list and get back to you",
        "found it"
    ],
    "spaces/AAAABcXBTWI/threads/JTZ3iBMKAP8": [
        "@all note that this roadmap is only for cloud based connectors and not for the OnPrem versions of individual connectors. If any enterprise is using any on prem version of these, then reach out to us separately"
    ],
    "spaces/AAAABcXBTWI/threads/Ot7DWbmSUdU": [
        "As each enterprise might be using a different version nd might have different APIs, Auth mechanism used, we will support those on the need basis. By default we will support the latest versions of these which are in GA in cloud"
    ],
    "spaces/AAAABcXBTWI/threads/3VdUSVoNyT8": [
        "I have used mailinator.com to create a demo account. My demo will be tmr.. Today, i found my app is being deactivated as below in SearchAssist-app. Who can help to activate it again !!",
        "@Aayush Mediratta did you work out a process on this yet?"
    ],
    "spaces/AAAABcXBTWI/threads/DFFMVm3akaA": [
        "Had a chat with @Santhosh Kumar Myadam , we will get something after new pricing is implemented."
    ],
    "spaces/AAAABcXBTWI/threads/Hskhy5pPLpE": [
        "@Aayush Mediratta @Richard Passavant \n\n Is it possible to use a set of few accounts/workspaces for all demos? We can upgrade them to 'enterprise' license.",
        "I'll leave that to Aayush and or @Curtis Swartzentruber",
        "I dont think so. There are multiple reasons we have to create temporary accounts. for instance, my main account is still on smartassist v1 - so it's unusable. Additionally, this account has been added to so many workspaces that its performance has significantly slowed. Another factor is account sharing. Bot developers can't invite other users, so to save (overnight) time, we resort to using Mailinator accounts and share the passwords. Furthermore, having the ability to add credits would be beneficial during enterprise customer PoCs, most of the time, the customer runs out of money during the POC stage only (before the contract) and yes we can argue that they can put their credit card and continue using it, it reflects poorly on us. There are more reasons, but I hope this explanation is helpful."
    ],
    "spaces/AAAABcXBTWI/threads/FY8_CDbgHWQ": [
        "Question about Sharepoint integration - our documentation is specific to multi-tenant (hosted) Sharepoint instances - I had hearde at one point that there was. challenge with integration to on-premise Sharepoint servers, but we are doing that for Alaska.  What are the limitations/concerns/caveats for integration with an on-premise instance of Sharepoint?",
        "Can anyone help with this question? Thank you!",
        "We do not have support for Sharepoint on Prem connector in SearchAssist. \n\nFor Alaska there is an external utility that pulls in the data from the connector performs the required transformations and then uses the Structured data API to push the data in SearchAssist. \n @Graeme Dean",
        "Thanks @Aditi Bhadouria - to make sure I am clear, is that a utility we (Kore) developed?  If so, am I right in understanding that although this is not a standard connector, we can support this though a custom configuration?",
        "@Graeme Dean This can not be used via a custom configuration. But yes it was a utility developed by the Professional Services team. This was a custom implementation and will include additional cost."
    ],
    "spaces/AAAABcXBTWI/threads/Hl0p9GQlMS0": [
        "Are there any updated SearchAssist sales decks?  The files in Resource Portal are dated 8-5-2022 and 7-15-22"
    ],
    "spaces/AAAABcXBTWI/threads/W-EVu2my7dc": [
        "There are also many cases around third party integrations, including AgentAssist, where we need separate workspaces and accounts in order to properly segregate behavior, such as connections to third party environments, channel configuration, etc."
    ],
    "spaces/AAAABcXBTWI/threads/oAcJCmMAa3A": [
        "In case you are using GPT 3.5 and above for RAG use cases, you can use/refer to the below prompt curated by Microsoft engineer for ebay:\n\n[\n¬†¬†{\n¬†¬†¬†¬†\"role\": \"system\",\n¬†¬†¬†¬†\"content\": \"You are an eBay AI assistant who help ebay customer with their questions. Be polite and friendly in your response. You will use the content chunks provided in the user context to answer the ebay customer questions. When generating your response, please adhere to the following guidelines:\\n1. Answer ONLY with the facts listed in the list of sources provided in the user context. \\n2.If there isn't enough information in the sources, say you don't know the answer.\\n3. Your responses should be in markdown format to be displayed on HTML web page. \\n4.Always provide complete answers. For example: User: What is LendingPoint? Assistant: LendingPoint is a loan provider that eBay has partnered with to offer competitive loan options to sellers. \\nyour answer:answer to the user question with [chunk_id].\"\n¬†¬†},\n¬†¬†{\n¬†¬†¬†¬†\"role\": \"user\",\n¬†¬†¬†¬†\"content\": \"User query : ' {{query}} '. Sources: ‚Äò{{chunks}}‚Äô. \"\n¬†¬†}\n]"
    ],
    "spaces/AAAABcXBTWI/threads/Xx29LI-8eMI": [
        "Hi @Elizabeth Campos please check my response to the original question"
    ],
    "spaces/AAAABcXBTWI/threads/3oY43ovTFnI": [
        "Question about ASR: If we do an onprem install of SmartAssist, do we also install an onprem ASR engine, or does ASR function depend on sending the voice to the respective cloud vendor APIs (Deepgram, Google, Azure, etc.)? Most of my clients do NOT want their data, even for transcription, to be sent to the cloud.",
        "And is it the same if this was a Dedicated Cloud (VPC)? Do we still need to hit the vendor public cloud ASR services?",
        "FYI - this is to support AgentAssist over voice. (TTS is not needed to support AA)",
        "We can, depends on the vendor",
        "Let's say Deepgram",
        "Ruchi shared a spreadsheet with our support. The link is also on the SE drive",
        "oooh ok let me check",
        "and I just realized I posted this in the wrong space. oops"
    ],
    "spaces/AAAABcXBTWI/threads/NWP9MQgVHjY": [
        "i try to link a bot in SearchAssist. For the search-app, it points to the SIT and search-pilot points to the staging-bots.korebots.com but none of them points to https://bots.kore.ai/botbuilder. Do i miss something?",
        "searchassist prod(https://searchassist.kore.ai) point to https://bots.kore.ai/botbuilder"
    ],
    "spaces/AAAABcXBTWI/threads/EMubaEv8WPg": [
        "RE: Sharepoint integration \nFor on-premise SearchAssist deployment, what callback URL should I use? Would it be ok to use this URL or something else? \n\nProd Region Callback URL:https://idp.kore.com/workflows/callback",
        "We need to get the host from \"alertactionUrl\" from on-prem kore-config and append \"/callback\". Please check with the onprem DevOps team"
    ],
    "spaces/AAAABcXBTWI/threads/2_Bg5ZZWTak": [
        "When we link a bot in SearchAssist, shall we choose v1 or v2 in Webhook channel ?",
        "I think it is v2, asynchrnous"
    ],
    "spaces/AAAABcXBTWI/threads/lghOlAYkntE": [
        "Hi @Surendra Subhash Salke @Aditi Bhadouria are RFIs submitted to the RFP / RFI team OR are worked on by your team as of now?",
        "First draft will be by the RFP team. Product team review the response. Also product answers the questions which are not yet covered in the RFPIO site."
    ],
    "spaces/AAAABcXBTWI/threads/hhne3Rgzong": [
        "Thank You! How much time / number of days, your team needs to review it.. say for an average 50 Qs to 100 Qs. RFI?"
    ],
    "spaces/AAAABcXBTWI/threads/Sw9Ax8E63fY": [
        "Last time when we filled in CITI RFP with leadership pitched in, it took 2 weeks",
        "guys we don't need the product team to review the RFIs now",
        "RFI team and SEs can do that",
        "they will reach out to product team if they have any specific questions",
        "in the past product team has done that because it was not fully developed",
        "@Joel Baily ^^ we will need to send this to RFI for a final review.. I've put together a majority of the responses already."
    ],
    "spaces/AAAABcXBTWI/threads/BPs-KJC3RXM": [
        "From one of the SearchAssist Docs - \"Integrate with a range of embeddings model (Ada, LaBSE, E5, Claude etc.)\" is mentioned (supported) as Yes... Does it mean Kore.ai integrates to these embedding models (in additon to MPnet & LaBSE), by default OR it means an Organization has a choice and decide which model to integrate to?",
        "Hi @Navdeep Grover can you share which document you are referring to? So that we can make sure it's up to date. \n\nCurrently SearchAssist only has support for MpNET and LaBSE. Support for other embeddings is in roadmap",
        "@Aditi Bhadouria  Line 41 on Features List tab https://docs.google.com/spreadsheets/d/1yFhfE8pbUsrGOWIt93SPiuqbTdmF7ePKhTvXZBi4WYA/edit#gid=354630536",
        "Updated it. Thanks"
    ],
    "spaces/AAAABcXBTWI/threads/x3ab2EY5lt8": [
        "Hello Everyone¬†\n\nStarting April 1st, Office Hours will be held once a week instead of the current frequency of twice a week. This change is due to the decrease in attendance, which we interpret as an indication of a better understanding of the product. We will continue to monitor the situation and adjust the schedule as needed to ensure we provide the necessary support. \n\n @Santhosh Kumar Myadam  @Girish Ahankari  @Surendra Subhash Salke  @Rohit Tambe"
    ],
    "spaces/AAAABcXBTWI/threads/_IFwZVNaBoo": [
        "We have a customer who has intranet HR portal. This portal is SSO protected. Can we use this to crawl data? I see only basic auth and form based auth as 2 option for authentication. \n\n @Akshay Aggarwal for your tracking as well",
        "Thanks",
        "We would also need kore connector for this since the intranet won't be exposed to the public internet? assuming this is SaaS. Does SA supports Kore connector?",
        "This is on Prem",
        "@Aditi Bhadouria @Hariharan Velusamy @Surendra Subhash Salke your input here would be valuable",
        "following",
        "Currently for webcrawl we don‚Äôt have SSO support but we have support for authenticated websites. As long as the client website allows our server to crawl it, this can be done. If the client website blocks our server then webcrawl will not work.",
        "@Umang Shah \nIs this HR Portal a standard website or is an application powered by a HRMS platform? \n\nWe also need to know what kind of docs/files/articles are present on this portal.",
        "@Santhosh Kumar Myadam This site is built on top of dotCMS for which we don't have connector",
        "Following: I have a different prospect interested. They have an intranet built on Unily.com"
    ],
    "spaces/AAAABcXBTWI/threads/o1hjyXLDY80": [
        "For an on premise installation of SearchAssist, what is the practical size limit for a file? I believe we currently we limit the file size in SaaS to insure performance is decent."
    ],
    "spaces/AAAABcXBTWI/threads/b7_Qqj6tKNE": [
        "A couple questions from a POC\nIs there a way to download a sitemap to see what was ingested via the Sharepoint connector?\nWhat is the crawl depth of the Sharepoint connector? Does it automatically crawl child pages?",
        "When using Sharepoint connector we don't crawl the pages similar to web crawl. We use an API to get the list of all relevant content as per the site list selected by user and what is supported by SearchAssist. \n\nAll the content ingested can be viewed from the content tab of the connector.",
        "https://docs.kore.ai/searchassist/manage-content-sources/connectors/introduction-to-connectors/#View_and_Edit_Connector_Details"
    ],
    "spaces/AAAABcXBTWI/threads/G2gspB_H-eg": [
        "Hello! We have an opportunity with a mortgage insurance company. They follow federal guidelines that are available in a 2400 page document that is publicly available on freddymac.com, unless their own underwriting guidelines (UGs) provide a different instruction. This has created two challenges:\n\n1. The 2400 page document is > 15 MB in size, and therefore cannot be uploaded by file or by URL. The only solution I see is to break it down into two documents unless there's a better alternative?\n\n2. The more interesting question is: can we set up a \"supercedes\" relationship between these two documents? In the event information in their own UGs differs from information extracted from the Freddy Mac source, can I prioritize the answer from their UGs?",
        "Hi Todd \n\n1. We can increase the limit to maximum 35 mb for a document. So we will have to split it and ingest as 35 mb might still not be enough for 2400 pages. \n\n2. This is not possible OOTB currently. But a multi hop approach could be done as a custom implementation. I'll leave the questions of the cost, who will do it etc upto you. I attempted a high level diagram of a possible solution approach, based on my understanding.¬†\n\nBut please note there will be limitations: \n1. External service will have to be responsible for orchestrating this entire flow\n2. Analytics will be difficult to understand as there will essentially be 2 copies of it, as part of both apps. \n3. Latency due to 2 LLM calls being made sequentially.",
        "@Surendra Subhash Salke Please correct me if I'm wrong",
        "With the current tooling we can assigned the higher relevance to the chunks retrieved  from UGs than Freddy (best efforts, not guaranteed). This can be accomplish by boosting the chunks from a specific source.\n\nWhile the approach suggested by @Aditi Bhadouria is deterministic and will work.\n\n@Todd Lewis",
        "Thank you both!"
    ],
    "spaces/AAAABcXBTWI/threads/7xlYaay3Ers": [
        "Hi! I am working with Elsevier (this quarter deal). They are evaluating SearchAssist. They have a trial on search assist.kore.com - workspace colinstestsanbox. They have created an app called \"Legal Policies\". It consist of 36 PDF files and 56 FAQ questions. Generative answers is enabled (Azure OpenAI). It is generating no chunks when trained. I created a clean project with the same data using OpenAI (Azure OpenAI) is super slow and it works fine. Can someone please take a look and figure out why chunking is failing.",
        "Wild guess. They ran out of free credits?",
        "Hi @Jeff Pascoe \n\nI am assuming you are referring to US prod for the environment. Please correct me if I'm wrong.\n\n LLM model selection plays a role in the latency, but the extraction and indexing of chunks are unaffected by it. Please review and let us know if it's still not working, we'll be happy to help. Additionally I am internally checking if this could be because of the license. I'll let you know the update.",
        "Hi Aditi, It is still not creating any chunks I am afraid. Yes we are talking US prod (search assist.kore.ai). It was working a few days ago so not clear it is a license issue. I will quickly try with OpenAI. As I said a new project with OpenAI and the same documents/FAQs does work. Thanks.",
        "Quickly tried with an OpenAI key but still no chunks. Not clear if it is to do with the LLM/License. Thanks.",
        "In that case can you raise a support ticket for this?",
        "I will. Thanks."
    ],
    "spaces/AAAABcXBTWI/threads/xIu0NwMI0cA": [
        "Struggling to find a good Search Assist demo. I've been looking through Resource Portal, the video assets spreadsheet, and Loom, but not finding anything riveting.  \n\nSpecifically looking for a demo video of SearchAssist that shows well and depicts getting info from multiple sources in a \"conversational\" manner.  In this case in particular the customer is looking for an employee-facing solution in the asset management space.  If any of you have any SearchAssist videos that you are particularly proud of and seem to tick any of these boxes (in English), I would love to review them.  Thanks.",
        "@Jeffrey Wong - do you have stuff in your repository?"
    ],
    "spaces/AAAABcXBTWI/threads/f_HR3ocVo10": [
        "How can we respond to this Q. - \"Can the search API be used to feed RAG based LLM applications with the content?\"",
        "As part of advanced search API of SearchAssist, following can be done. \n1. Receive query in the request along with user context, metafilters. \n2. Return the answer and/or chunks qualified for the query(based on flag)\n\nThis can be utilised by users as per the use case.¬†\n\nFor more detailed information please check out our documentation https://docs.kore.ai/searchassist/public-apis/searchassist-apis-list/#Advanced_Search_API\n\nYou can also check out other public APIs available here https://docs.kore.ai/searchassist/public-apis/searchassist-public-apis/"
    ],
    "spaces/AAAABcXBTWI/threads/RDcTeHVcdRo": [
        "@Jeff Pascoe Also, we were recently told that OpenAI may be faster than Azure at the moment.  There seems to be no consensus yet that I know of.  Testing is the only way to determine.",
        "Unfortunately it doesn't work when I tried our OpenAI Key (deleted now). It is broken."
    ],
    "spaces/AAAABcXBTWI/threads/R5cPlWgAxSk": [
        "Does our ServiceNow Connector work on-prem?"
    ],
    "spaces/AAAABcXBTWI/threads/_jMbgvuhuzE": [
        "Can we use the Microsoft Graph API to crawl MSTeams chat messages?"
    ],
    "spaces/AAAABcXBTWI/threads/BYYNzUfx9io": [
        "Sounds like Cory already looked in the spreadsheet. I‚Äôm including @Chris Carson incase he has anything in the queue",
        "None of our current demos/videos come to mind in regard to asset management or answering from multiple sources. Typically what we‚Äôve shown is answering from knowledge base with snippets. \n\nThe closest thing I can think of is a vision clip we did for health that responded differently to a question depending on whether it was a doctor or a patient asking the question. It would dynamically summarize the answer both technically and in laymen‚Äôs terms.",
        "@Chris Carson is there a link which I can access to see through this vision clip. One client is looking for persona based responses. I think this fits.",
        "https://vimeo.com/909298308/54b9a95d88"
    ],
    "spaces/AAAABcXBTWI/threads/Pjw5CVWaUoQ": [
        "Hello, we have a prospect for search assist in Banking. Can someone share a success story of a customer using searchAssist in the present? Or share how they are using it and the impact to their business? Thank you!"
    ],
    "spaces/AAAABcXBTWI/threads/nkyria5Kdag": [
        "You can get another OpenAI key - go to https://platform.openai.com/ and login with your Kore account.",
        "Thanks Tim. Our key if fine. It works in the duplicate project I created. The chunking is broken in their project."
    ],
    "spaces/AAAABcXBTWI/threads/5feahlPqP_w": [
        "Error message showing up in SearchAssist this morning:"
    ],
    "spaces/AAAABcXBTWI/threads/fDBghN-u5LM": [
        "I need answers to these questions. Can someone please help?¬†\n @Girish Ahankari  @Surendra Subhash Salke  @Rohit Tambe \n(Customer) Questions/Pressing Issues:\nHas KoreAI inbuilt any caching mechanism to keep predefined answers in it to get faster response (for selective search queries/ questions) rather than getting it from LLM? Though we see one option is, keeping the question and answer pair in datatable of bot Builder and fetch\nFacing latency (20 sec delay) while fetching Azure Open AI (GPT4 ‚Äì hosted in CanadaWest) from Kore AI. Is it because Kore sits in US (region) AWS and trying to connect to Azure Open AI (GPT4 ‚Äì hosted in CanadaWest)?\nUsing Kore AI connector (custom) for GCP connectivity ‚Äì ticket raised with Kore for Auth Issue :¬† https://support.kore.ai/hc/en-us/requests/40849 . No response yet - Ticket #40849\nWhat we can do with custom configurations in SearchAssist as mentioned below.¬† What is the purpose of this configuration? What key value pair can be used to customize the search ?",
        "Cache: The generative AI caching feature is in the near roadmap. However, caching can be implemented as a custom solution with another searchassist application to keep the cached content and manage the cache coherence with the insert and delete content API. \n\nLatency: the delay in the generative AI solutions is mostly attributed to the generative AI response latency. Response time can be tracked using \"answers snippets -> simulation.\"\n\nSupport request: please allow me a day to come back on this.\n\nCustom configuration documentation: https://docs.google.com/document/d/1kqSH_g0GZ8A6LvLZyCr2EB4Y7FlAj5Rdxo4TekQVunM/edit?usp=drivesdk\n\nhttps://docs.google.com/document/d/1jXVmBbPJPZxDedtsStFjnXVQtmK2gsiO6Y4naHWp4po/edit?usp=drivesdk",
        "@Surendra Subhash Salke - how difficult is it to implement the cache solution you mentioned? We are working w/ a rather unexperienced (when it comes to Kore) partner to make this happen",
        "@Martin Jahn TravelAssit team has implemented this custom caching solution for the Alaska project.",
        "@Surendra Subhash Salke Who from the TravelAssist team implemented the custom caching solution for that project?",
        "Ramesh Antony Raj"
    ],
    "spaces/AAAABcXBTWI/threads/8F3dpIuvPAc": [
        "@Surendra Subhash Salke @Girish Ahankari"
    ],
    "spaces/AAAABcXBTWI/threads/m6l8jOdFqAY": [
        "Can we use OpenAI in search assist only for externally crawled content? and Not use it for internal repo data?",
        "I use source_url and build a rule to filter internal repo data"
    ],
    "spaces/AAAABcXBTWI/threads/bWqKZ_OhKZQ": [
        "Hi All,\n\nWe'd like to apologize for the inconvenience caused by the temporary issues we're experiencing in the Pilot environment following the recent 2.0.0 major release. As part of this release, we upgraded the Node and Angular versions to address security vulnerabilities, which has unfortunately led to a few issues for new applications. However, existing applications appear to be unaffected.\n\nOur team is actively working to resolve these issues, and we expect to have them resolved before the start of the US morning hours. In the meantime, we kindly request that you use the PROD environment for any new application demos.\n\nIf you encounter any issues or require assistance with demos during this period, please let us know, and we'll be happy to provide support.\n\nWe sincerely apologize for the disruption and appreciate your understanding and patience as we work to resolve these temporary issues promptly."
    ],
    "spaces/AAAABcXBTWI/threads/XWmFSrYiV60": [
        "Team,\n\nWe have successfully resolved the issues. We are currently validating the environment and will provide an update on this soon."
    ],
    "spaces/AAAABcXBTWI/threads/sS2j1CRtBjM": [
        "Can we please get \"Bussiness Rules\" corrected?",
        "@Todd Lewis May I know which environment are you seing this? \n\nIt looks correct in production\n\n @Rohit Tambe",
        "Good call. searchassist-pilot",
        "Thank you. Will rectify it. \n\n @Bharat Rekha",
        "Thank you @Todd Lewis, we will get it corrected."
    ],
    "spaces/AAAABcXBTWI/threads/fnoOPPLxRbI": [
        "We‚Äôre involved in an RFP that includes SearchAI and the prospect uses ProcedureFlow for their agents and branch employees.  Rather than converting their docs into PDFs, which they said wouldn‚Äôt render properly, would it be possible to connect via APIs to access the proper info?\n\nhttps://help.procedureflow.com/article/152-api-documentation",
        "As long as the output of the API being referred to here is in a JSON format. We can ingest it in SearchAssist as structured data. Please involve partner/implementation team for further details."
    ],
    "spaces/AAAABcXBTWI/threads/LtjRnsslVM4": [
        "If a prospect is already using Elastic Search (ES) to index their documentation on their website, and jussst do not want to stop using it.. is there a way, we can augment SearchAssist on top of Elastic Search? If yes, how? .. Since we create our own index upon ingestion, it will be create a situation of redundancy. ES has APIs and is integrated to their AES (Adobe CMS) & PIMs (Product Information Management System like from Agility). We've got their attention and I look forward to hear some creative ways!"
    ],
    "spaces/AAAABcXBTWI/threads/FpYuTUIXSJ4": [
        "@Navdeep Grover what is the usecase here?",
        "Thanks @Girish Ahankari What do you mean \"using their Elastic but not Index\"? Keysight (https://www.keysight.com/) has over 25K products and from the past couple of quarters, they've started to see lot of new/existing customers trying their Search bar (powered by Elastic Search) but not getting the results, leading to complains and DSAT. They want them to be able to search for any type of product / support info over natural language, ask followups and then interact with a bot (when they are on a specific webpage, which I know we can propose bot) for both presales / postsales. Cx has been a pain, leading to execs involvements and they're planning to invest time / money into revamping their whole website but still need a Search solution."
    ],
    "spaces/AAAABcXBTWI/threads/QeTKji_l7DE": [
        "We can use their elastic but we cannot use their index and how we index will be different from what they might have done"
    ],
    "spaces/AAAABcXBTWI/threads/ICBs1PR_QvQ": [
        "do we have an updated searchassist roadmap? thanks",
        "Please use this presentation to view the roadmap. As we regularly update the same. SearchAssist Roadmap",
        "Is this shareable with customers or internal only?",
        "It can be shared with customers"
    ],
    "spaces/AAAABcXBTWI/threads/lLgKENyatqI": [
        "@Girish Ahankari what do you think?"
    ],
    "spaces/AAAABcXBTWI/threads/3eAIwf7M6C0": [
        "Has SearchAssist (https://searchassist.kore.ai) gone down. I can login but it shows me no apps."
    ],
    "spaces/AAAABcXBTWI/threads/nWRmhAkn9KQ": [
        "i have the same issues"
    ],
    "spaces/AAAABcXBTWI/threads/eh6O173t5n4": [
        "all my app gone away"
    ],
    "spaces/AAAABcXBTWI/threads/tpk_jtz5btI": [
        "I have tried multiple time on different browsers/PCs but all it get is the above."
    ],
    "spaces/AAAABcXBTWI/threads/PcRGeA9ZL5A": [
        "@Jeff Pascoe Are you still facing this issue?\n\n @Bharat Rekha",
        "Yes. Still occurring.",
        "I can now access the customers workspace Colinsanbox OK. Still cannot access my Kore workspace.",
        "Weird.",
        "Tried in Safari browser. The URL is https://searchassist.kore.ai/home/ (checked no additional parameters). Still not showing my apps after I login. If I then change Workspace to the customers I can see the Apps (this was not working before but now is).",
        "@Akhil Sainath Maddala please check",
        "@Jeff Pascoe Can you please share the User ID if possible to debug more?",
        "jeffpascoe@kore.com",
        "Google login.",
        "Sorry jeff.pascoe@kore.com"
    ],
    "spaces/AAAABcXBTWI/threads/2rKlqUME-xc": [
        "@Jeff Pascoe looks like the URL has been appended with a few additional fields in the API path. can you please try once with this URL : https://searchassist.kore.ai/home/",
        "Any progress on this. I have a this quarter deal with a customer and I cannot access my work for that customer. Please can someone advise."
    ],
    "spaces/AAAABcXBTWI/threads/uaH1DpDyCHI": [
        "For the SearchAssist connectors such as Azure Storage, Salesforce, etc. how are the client tokens stored behind the scenes and how are they protected? Are they in our MongoDB encrypted?"
    ],
    "spaces/AAAABcXBTWI/threads/j98pkeBU-fU": [
        "Is it feasible to enable a single app to accommodate customer document sizes of 80MB for SearchAssist? If not currently possible, are there any plans to implement support for larger file sizes in the future?"
    ],
    "spaces/AAAABcXBTWI/threads/_uTsqTINdAc": [
        "BETA Feature: dev_Enable_Query_Rewrite_Type\n\nTeam, I'm reading this document previously shared by the SA team: Beta Features in SearchAssist \n\nI've enabled query rewrite like so (attached).\n\nMy understanding is that this should send the previous 2 questions as context. So that the following should be possible: \n\nUser: What is the stock rating of Microsoft? \nBot: The stock rating of Microsoft is BUY\nUser: and Salesforce?\nBot: The stock rating of Salesforce is HOLD. \n\nBut instead the Bot does not respond with the Salesforce rating, but an overview of the company."
    ],
    "spaces/AAAABcXBTWI/threads/Xm-Ovl47Z5E": [
        "SearchAssist Office Hours\n\nI just wanted to say a big thank you to @Aditi Bhadouria who led a very interesting and insightful session today going into the technical details of RAG and exception handling queries from clients like: 'Why wouldn't I build a Search app in house'? \n\nSharing the diagrams shared with me https://docs.google.com/presentation/d/10yjfXYuDgP6nE6tZoKelCjbWnOH8rv--74kiSA4OU7E/edit#slide=id.g2c4c41a543c_0_0",
        "@Laurence Schoultz was this session recorded?",
        "Yes will share it once available",
        "Can you please share the link?",
        "https://zoom.us/rec/share/OelZpTkPfSaH-N9Kc654XGyD5ZpuCd3RYpHFR-zoWCEnWQMcjf1nxypXSYwyBNzp.dnOKRbrPuQJ5gF4n\nPasscode: Wc!is8tt",
        "@Navdeep Grover"
    ],
    "spaces/AAAABcXBTWI/threads/X0gXxAFtr2g": [
        "Well done @Aditi Bhadouria"
    ],
    "spaces/AAAABcXBTWI/threads/N0YKxQMoquw": [
        "Thank you Raj"
    ],
    "spaces/AAAABcXBTWI/threads/skHkarp4hYA": [
        "Hi Team, any idea why this may happen in SearchAssist - XO bot connected using API?\ntwo identical requests are being returned: one with no results the second with a result. same happens in SA Preview:"
    ],
    "spaces/AAAABcXBTWI/threads/by7ekeYDFiM": [
        "Hi Guys, I've a customer meeting coming up and I'm not getting descriptive answers in one App whereas the other app is running absolutely fine, within the same SearchAI instance",
        "Make sure the openAI key is configured and Generative model is enabled at answer snippets"
    ],
    "spaces/AAAABcXBTWI/threads/-WnUW_NHjHc": [
        "Yes its all done, the other app is working perfectly with the same key and settings.",
        "Do we also have to add the Search Settings | Custom Configurations  such as: \ndev_Enable_Vector_Search   =truequery\ndevChunk_Vector_Search ¬† =true\ndev_Enable_DocSnippets ¬† =true\ndev_Enable_Query_Rewrite_Type ¬† query\nThe above is basic search assist custom settings as of Aug 2023",
        "No all of these settings are not required. You can enable answer snippets and train the app. That will take care of all the basic configurations. Any further fine tuning should be done using the beta features"
    ],
    "spaces/AAAABcXBTWI/threads/XA_SG2dAscM": [
        "I have a customer workshop coming up, and SearchAssist is intermittently totally unresponsive.  Our status page says it is \"operational\", but that appears not to be the case.",
        "Is this US prod?",
        "yes",
        "@Harini Bandaru Can you please look into this? \n\ncc:  @Surendra Subhash Salke  @Bharat Rekha",
        "@Aditi Bhadouria we are looking into it",
        "Thank you",
        "FYI - seemed to have resolved - the workshop went well"
    ],
    "spaces/AAAABcXBTWI/threads/asXjrcJtuFM": [
        "Are there any live in production SearchAI customers?  Alaska Airlines?  Any others?",
        "FB (Fortune Brands) uses for answering HR questions.\nIDFC (bank in India) uses it for answering Banking queries.",
        "Morgan Stanley",
        "@Dalton Trout other potential Customers for Enact - Morgan Stanley and Fortune Brands",
        "@Dalton Trout  Morgan Stanley just won awards using our SearchAI solutions: https://finance.yahoo.com/news/morgan-stanley-wins-three-2024-143000758.html",
        "Thanks guys. The prospect was also asking how the generative model affects ROI from a cost perspective. Morgan Stanley might be able to provide some light on that from their experience"
    ],
    "spaces/AAAABcXBTWI/threads/uoQ6akpvU4g": [
        "For SearchAssist used through an XO bot is there any good reason to have Small Talk enabled in SearchAssist? Small talk would be handled by XO and will only cause problems from what I can see. For instance when the user asks in a casual way \"I use good old Firefox, do I need to download Chrome instead\" that will trigger Small Talk but when its disabled the correct answer is generated.",
        "Yes that's right. In this case, it's best to have small talk disabled."
    ],
    "spaces/AAAABcXBTWI/threads/MbVH1YMV7Is": [
        "is SearchAssist down?\n\nhttps://searchassist.kore.ai loading blank screen and API calls (was working yesterday) returning 404",
        "@Anton Bolkhovitin we're looking into it!",
        "@Anton Bolkhovitin Pls check now",
        "yep it works now"
    ],
    "spaces/AAAABcXBTWI/threads/tkSgOirspVM": [
        "Do you know if this is an on-premise system installation or SA configuration issue? CBRE received the error message below when clicking the SharePoint integration content URL. If you notice, the URL was appended with another URL.",
        "Here is an example from my setup. I don‚Äôt have this issue using our SaaS solution when I click on the URL below.",
        "cc: @Surendra Subhash Salke @Melissa Prince",
        "@Andy Pham Could you please ask CBRE for a screenshot of the SharePoint Connector content page? Additionally, could you obtain any URL from the content list?",
        "@Rohan Chaurasia, I will ask and cc you on it. Have a great weekend.",
        "Please include me in the mail as well",
        "Ideally it‚Äôs best to raise a support ticket"
    ],
    "spaces/AAAABcXBTWI/threads/5FXE6Ae32S8": [
        "Do we have a recording of Workbench stages explaining \"Why does each stage exist?\" and \"What is the use case / benefit / value of it OR you know How does it help?\" along with the conditions & outcomes use cases."
    ],
    "spaces/AAAABcXBTWI/threads/z_n3uxCViTs": [
        "How do we segregate customer data on our cloud instance? For example on the XO platform we have store the information in MongoDB, and each customer's data is encrypted at rest using their own key. I'd like to think that we use the same method with data that has been ingested by SearchAI.\n\nWhat's the real answer? Thank you!"
    ],
    "spaces/AAAABcXBTWI/threads/noKdXwf6DBU": [
        "This doesn't look correct. \nhttps://docs.google.com/document/d/14oty120QPJI5-6SbUO0LTBSIOX210B3bPNAkJqX9rdE/edit"
    ],
    "spaces/AAAABcXBTWI/threads/pjyUoo9G6HY": [
        "Since this feature is deprecated, should we remove it from the list?",
        "Hi @Andy Pham \n\nI am not sure which document this is. This is the document for beta features that is regularly updated by SearchAssist product team. https://docs.google.com/document/d/1kqSH_g0GZ8A6LvLZyCr2EB4Y7FlAj5Rdxo4TekQVunM/edit?usp=sharing"
    ],
    "spaces/AAAABcXBTWI/threads/yik0OmWF_6c": [
        "Is the between from 0-9 or 1-9?"
    ],
    "spaces/AAAABcXBTWI/threads/YCVarKKcK1M": [
        "It looks like I can add these suggestions directly to the document. I will add them there."
    ],
    "spaces/AAAABcXBTWI/threads/9zGmLD7c4vU": [
        "I have a customer that is asking for skill gap training, and for a one-pager/documentation for when SearchAssist is giving the wrong answer. Does anyone have any documentation for this? Videos, Documentation, etc. where can this be found?",
        "@Reilly Hughes We have an internal document for triaging various issues. \n\nWe are in the process of structuring it better and making it available for all customers. This will be ready in the next 2 to 3 days. \n\n@Rohit Tambe Let us fast track this.",
        "Sure Santhosh",
        "I also have a couple of customers that will benefit from this. Do we have a rough ETA on this?",
        "@Laurence Schoultz \n\nWe can have this ready in another week's time. \n\n @Rohit Tambe Let us track this on priority.",
        "@Santhosh Kumar Myadam @Rohit Tambe how is it looking?"
    ],
    "spaces/AAAABcXBTWI/threads/cnodlyb1wCw": [
        "Hi Guys, While we understand that SearchAi offers two ways to find the info - via a bot looking search interface OR regular website search bar.. How is the latter option integrated / configured to allow end users to ask Qs. in the organization's website existing searchbar?",
        "It can on their existing, or a new custom one."
    ],
    "spaces/AAAABcXBTWI/threads/ojBhtEwN7_g": [
        "\"How\" is it accomplished?"
    ],
    "spaces/AAAABcXBTWI/threads/qaysmynlPzs": [
        "Try this in case you haven‚Äôt seen it: https://docs.kore.ai/searchassist/administration/deploying-searchassist-app-administration/developers-corner/",
        "They will replace the HTML code in their web page with the code we provide from either the Web channel details... or a custom WebSDK they setup (or using BotKit)."
    ],
    "spaces/AAAABcXBTWI/threads/bH6DTJPD2sU": [
        "Team, would anyone be available at 1:30pm BST (18:00 IST) to help troubleshoot a SearchAssist chunk extraction issue with a customer?",
        "@Laurence Schoultz Please raise a support ticket. That will help in routing in the right direction.",
        "Thanks @Santhosh Kumar Myadam"
    ],
    "spaces/AAAABcXBTWI/threads/QDxJeKQlNN4": [
        "Is it possible to configure more than one instance of a Connector in the same SearchAssist app? for instance 2 separate SNOW instances. Are would that need to be 2 different Search AI apps?",
        "@Curtis Swartzentruber This is not available today. \n\nWe did see this request from a few other customers too. \n\nWill add to the roadmap. \n\n@Aditi Bhadouria"
    ],
    "spaces/AAAABcXBTWI/threads/5vQaAzCB6Jw": [
        "Are there any plans to support Dynamic chunking where the system is intelligent enough to evaluate whether it has performed chunking correctly like if any chunk generated is partial, if there is a contextual loss between two chunks etc.? I also came across this document that challenges the traditional chunking methods' effectiveness https://capria.vc/gain/dynamic-chunking-in-vector-augmented-search-a-deep-dive-into-vectaras-approach/",
        "@Navdeep Grover Thank you. Will check this. \n\n@Aditi Bhadouria @Rohit Tambe"
    ],
    "spaces/AAAABcXBTWI/threads/UI8HY1GvxUc": [
        "Another Q. (asking them as separate to maintain the chat threads) - I understand we support MPnet embedding model that has 768 dimensions, our prospect has done a lot of testing and tried with embedding models with 1,024 dimensions & even higher 3,072 dimensions and they're very confident they want to use these ones due to significant increase in accuracy, relevancy of responses. Are there any plans to support models of such dimensions and also are there any plans to let the customer use their own embedding models?",
        "@Navdeep Grover We do have a plan to allow customers to use their own embeddings. Will share an update soon. \n\n@Aditi Bhadouria"
    ],
    "spaces/AAAABcXBTWI/threads/Be1Jm3eQP8c": [
        "@Subrahmanyam Donepudi @Sri Vangala Slides for Basic & Advanced RAG\n SearchAssist Presentation_Updated"
    ],
    "spaces/AAAABcXBTWI/threads/d-mklSD2oPI": [
        "Hello¬†@Sunil Singh¬†@Aditi Bhadouria¬†, wanted to check feasibility on content management capabilities as part of RFP response which we can and plan to support in near future:¬†\n\n1¬†Content Approval workflow\n\n2¬†Content Version control\n\n3¬†Content Archiving\n\n4¬†Audit trail\n\n5¬†Preview before publishing\n\n6¬†Publisher management for content directories\n\n7¬†GUI HTML formatting for creating content\n\n8¬†Digital asset management\n\n9¬†View permissions and control\n\n10¬†Scheduled release\n\n11¬†Scheduled expiration\n\n12¬†Portal IA/taxonomy manager\n\n13¬†Portal layout & components manager\n\n14¬†Components library (as resources to #12)\n\n15¬†Portal usage statistics & dashboard",
        "this is a part of larger requirements of using EVA together with HR& IT workflows across multiple group of companies and we are competing against leena.ai . your prompt response would be appreciated , have also dropped email regarding same."
    ],
    "spaces/AAAABcXBTWI/threads/bKf9o5h78Uo": [
        "@Girish Ahankari @surendra"
    ],
    "spaces/AAAABcXBTWI/threads/HYlozhhO0M8": [
        "@Surendra Subhash Salke"
    ],
    "spaces/AAAABcXBTWI/threads/h81T1SFeA3Q": [
        "Hi @Varun Vaidya \nPlease share the edit access to the discovery document. I will update the compliance code for CMS features."
    ],
    "spaces/AAAABcXBTWI/threads/dVu9Yvpm0Ug": [
        "Have shared edit access",
        "@Raj Koneru currently this is available only for the FAQs. We had discussed earlier to see if we should use the WorkAssist as the CMS or build something but had not decided on the roadmap and timelines. @Santhosh Kumar Myadam please correct me if I am wrong. @Prasanna Arikala"
    ],
    "spaces/AAAABcXBTWI/threads/lN6ies6ZrNQ": [
        "@Uttam Bhatta When training updates are made in SearchAssist, I'm told the default index is reset back to the first one. To overcome this, a client has asked if they can pre-select a default index (by index ID or any other key) in the SearchAssist embed code. @Girish Ahankari you mentioned at KK that this might be a trivial change.  Let me know if this change can be done, as it will only offer more flexibility."
    ],
    "spaces/AAAABcXBTWI/threads/KVDVR4i-LJo": [
        "@Surendra Subhash Salke we should allow passing the index id as part of query parameter"
    ],
    "spaces/AAAABcXBTWI/threads/afwedEM_KZw": [
        "Show the index ID(allow copy) from UI @Aditi Bhadouria"
    ],
    "spaces/AAAABcXBTWI/threads/0hJaNPyPGAE": [
        "@Raj Koneru \n\nWe did see interest from a few participants during KK about offering full scale content management capabilities, including authoring, collaboration and access controls, versioning and publishing. \n\nWe do have a 2-step workflow for FAQs in SearchAI but it is a very basic functionality. We do not have any other content management capability for unstructured data - webpage, files , articles etc. \n\nPrasanna suggested to explore open source systems that we can customize and offer as part of our product. \n\n @Girish Ahankari  @Prasanna Arikala"
    ],
    "spaces/AAAABcXBTWI/threads/SP3Db56djiU": [
        "Juniper is running a code-based homegrown RAG maintained & run by their Data Science team. At the moment, they're only using it for one LOB and when tried expanding it across the enterprise, the results fell short of expected outcomes in terms of response accuracy, relevance & context retention / management. They are evaluating vendors asking them to ingest Juniper's public documentation & support websites (below) into their respective solutions, give Juniper Testing team an access to their solutions (for 2-3 weeks) that they will evaluate / compare by asking Qs. their end customers ask & submit recommendations to their executives by June - July timeframes.  @Surendra Subhash Salke @Aditi Bhadouria Can you guys please take a quick look into these websites, and guide if we're able to support these tiered webs with HTML pages / .pdf pages and what Qs. should we ask them around these two links, in the follow-up meeting we're setting up soon? We're deciding whether to position a POC or Pilot.   https://www.juniper.net/documentation/¬†for Product Documentation and https://support.juniper.net/support/¬†for support information",
        "@Girish Ahankari its the same 100K HTML / .pdf pages opportunity we discussed during SKO.",
        "@Surendra Subhash Salke @Aditi Bhadouria did u guys have a chance to take a look into these websites structure?"
    ],
    "spaces/AAAABcXBTWI/threads/ISBCAS02MKo": [
        "I have a SearchAssist app built that is pulling back answers form PDF documents I have uploaded.  When I click on the document link (in Preview Mode and with the Web Client URL), I get the error attached (for every document).  Any idea what might be going on?",
        "I‚Äôve seen this too in some of my bots",
        "Hi @Graeme Dean \n\nThis is due to a \"one time access url\" feature we have developed. As part of this feature any url part of the answer and search results can only be accessed once and automatically expires once accessed or after 15 mins. \n\nThis is so that any sensitive information that is part of uploaded documents is not exploited.",
        "@Aditi Bhadouria should this not be an optional configuration?",
        "Since this is due to security reasons, we thought it's better to have it on be default. We can take up a task to make this optional",
        "But these are static PDFs.",
        "I didn't understand",
        "@Aditi Bhadouria Something is not working right here - when I ask the question and click on the link, it never works.  Other SEs are having the same issue.  Even the first time I ask a question the link is broken.  I need to do a demo in the next couple of days and can't show the link to source content working.",
        "@Graeme Dean thanks for pointing it out. While we will work on making this optional @Bharat Rekha @Surendra Subhash Salke  can you Please assign someone to test this so we can find a solution for Graeme",
        "@Aditi Bhadouria \n\n#1 Link not working for the first time is a defect and it should be analyzed and fixed. \n\n#2 Making the link one-time use - Let us discuss with InfoSec about making it optional. Ideally, we should not.",
        "Sure",
        "@Vamsi Lankisetty please test this and create a tracking bug for hotfix."
    ],
    "spaces/AAAABcXBTWI/threads/sUfnKQBmXOY": [
        "Hi Team, Answers / responses with Azure OpenAi is taking forever. I've a Colgate brief tomorrow and must use MS Azure key.. this is what is configured in my instance Cc @Alenis Fiallo .. \n\nAzure OpenAI¬†\nAPI Key¬†8d1f72432de24b0aae1448285e4934db¬†\n\nUser Sub Domain¬†seteam-azure¬†\n\nDeployment ID¬†gpt-4¬†\n\nAPI Version¬†2024-02-15-preview",
        "Hi @Navdeep Grover,\n\nI tested the above credentials, and they are working fine. Could you please share the app with us so that we can check the app settings?\n\nAlso, create a support ticket for the same.",
        "I added you in the pilot instance of colgate. everytime I switch to OpenAi, it generates responses just fine. try asking a Q. \"how can I find a notary?\".. \"what is the process to get an STA?\"",
        "@Rohan Chaurasia ^^",
        "Hi Navdeep,\n\nCan you please create a plat ticket? tracking the issue for closure via this channel is difficult for the customer issues. \n\n@Sunil Singh",
        "@Bharat Rekha The issue lies with the Azure OpenAI model (GPT-4), whose response time is exceeding a minute. Consequently, we requested @Navdeep Grover to utilize the 16k model.",
        "Can we document the initial debug information for these type scenarios? \n\n@Shruti Kukkar",
        "@Rohan Chaurasia @Bharat Rekha Raised the ticket [Request received] 42004 | MS Azure OpenAi LLM does not generate responses. OpenAi works well]. Tried different Azure OpenAi models but to no avail. It works for a couple of Qs. after I enabled GPT-3-turbo-16K, but stops generating answers. The moment I switch to OpenAi, everything starts working and the responses are much faster too.",
        "Thanks for sharing! We will check and update here. \n@Sunil Singh - please delegate to on call."
    ],
    "spaces/AAAABcXBTWI/threads/A9OhNi5c7Vw": [
        "@Navdeep Grover as mentioned earlier, we should avoid doing Free POC for 100K HTML pages.\nHave you or any SE tried it? Are you facing any issues?"
    ],
    "spaces/AAAABcXBTWI/threads/lvAFNhZRc-c": [
        "Doing a paid Pilot is fine but I would not recommend doing free POc for such large.l set of pages. Showcase a SPOC with few pages and ask for paid pilot"
    ],
    "spaces/AAAABcXBTWI/threads/lt1BncVx0ac": [
        "I agree and I'm leaving that decision with Sales. Yes, I tried web crawling, the first one only crawled around 9 pages which seem to have extracted a partial info and the second one only extracted 1 page. We want to make sure if we have any specific Qs. around the website layout we must ask in our follow-up."
    ],
    "spaces/AAAABcXBTWI/threads/zUt_0SY5CrY": [
        "Have u tried enabling JavaScript rendered check box?",
        "Yep.."
    ],
    "spaces/AAAABcXBTWI/threads/nGerZ7cObAE": [
        "Have you tried adding a delay?\n\nI had some website crawling issues in the past and the SA team had me add this custom config, which helped",
        "Thanks Dave! Lemme give it a try!",
        "@Shruti KukkarIs this    documented",
        "Yes Santhosh, some commonly seen issues and their solutions are listed here: https://docs.kore.ai/searchassist/manage-content-sources/managing-web-content/#Troubleshooting",
        "@Navdeep Grover we need to have @Aayush Mediratta approve any POC's. Please setup a meeting with yourself, the AE, Aayush, and myself to discuss",
        "Yep! I will setup a call once we've taken a final decision as to whether this will be a PoC or Paid Pilot."
    ],
    "spaces/AAAABcXBTWI/threads/oMw3j7Vm0KM": [
        "Just noticed in SearchAssist - \"Configuration the assiociated app to use HS256 algoritm\" contains two spelling errors (associated and algorithm) and an improper use of \"configuration\" vs \"configure\"."
    ],
    "spaces/AAAABcXBTWI/threads/HZOHXkag-_c": [
        "Thanks a lot @Graeme Dean",
        "@Aditi Bhadouria @Vamsi Lankisetty  how is This passing your quality check?",
        "We will fix this asap @Girish Ahankari",
        "We will do spell check review, @Vamsi Lankisetty please have bug created for this for hotfix.",
        "My sincere apologies @Girish Ahankari . It is missed from our QA side. I take full responsibility for this and will ensure there are no further grammatical errors in the SearchAssist application.",
        "Created Ticket under : https://koreteam.atlassian.net/browse/FLY-11155",
        "Why can‚Äôt we just scan the code repo?"
    ],
    "spaces/AAAABcXBTWI/threads/8xDZ7aBFoSc": [
        "Anyone having issues with web crawling?\nI am trying to crawl the following sites and continue to get a failure: No Pages Found to Crawl\nhttps://www.prudential.com/personal/life-insurance/find-life-insurance-policy/prudential-life-insurance\nhttps://www.prudential.com/personal/life-insurance/find-life-insurance-policy\nhttps://www.prudential.com/personal/retirement"
    ],
    "spaces/AAAABcXBTWI/threads/EHWf01BKUQ0": [
        "Two questions: Is there a resource for understanding how RAG architecture works and can be utilized? Do we have any externally shareable documents with a brief overview of our capabilities with RAG architecture?",
        "@Santhosh Kumar Myadam can we share our search ai presentation?"
    ],
    "spaces/AAAABcXBTWI/threads/UUOJGwMKQ90": [
        "@Surendra Subhash Salke can you confirm that RACL functionality for ServiceNow is going be available at the end of April and for Sharepoint it will be available at the end of May.",
        "@Joel Baily first version would be available by end of May. @Bharat Rekha when is Sharepoint available with RACL? @Joel Baily let is know if there is any deal depending on this for us to prioritise"
    ],
    "spaces/AAAABcXBTWI/threads/otdnDLJezsQ": [
        "Sure, will do."
    ],
    "spaces/AAAABcXBTWI/threads/EvpZ-g1RNZQ": [
        "@Girish Ahankari Yes, Equinix has a large Search use case and this is a P0."
    ],
    "spaces/AAAABcXBTWI/threads/kgMZFov7SH8": [
        "Thanks @Joel Baily will prioratize it. \n\n@Bharat Rekha can we discuss this in the morning for us to revert back to @Joel Baily",
        "thanks @Girish Ahankari. @Shantanu Ghorai FYI",
        "Sure Girish."
    ],
    "spaces/AAAABcXBTWI/threads/rpwz5ZYZ4N8": [
        "@Girish Ahankari Equinix developer Jayesh shared a screen shot from the SearchAssist roadmap from KK where ServiceNow RACL was slated for end of April. The SNow with RACL is required for their HR team. SP RACL they are fine with it coming in May end which will be required by their Treasury team.",
        "@Shantanu Ghorai Please share the screenshot. We did include RACL but it was mentioned as Apr to Jun 2024.\n\nWe are prioritizing it. Will confirm the ETA in a couple of days. \n\n @Girish Ahankari  @Prasanna Arikala \n\n @Aditi Bhadouria Please track this",
        "Sure"
    ],
    "spaces/AAAABcXBTWI/threads/ehfh6fWFuZg": [
        "@Bharat Rekha @Girish Ahankari lets get the racl for ServiceNow be available by end of the month",
        "Hi Prasanna,\n\nWe are currently on track for Google Drive, as per the plan to enable it for SA in US production anytime between mid-May. We will expedite and keep you posted on the progress. Since the RACL is needed for some of the EVA scenarios, we want to ensure that the feedback is addressed. We will initiate the reviews.\n\nServiceNow we will prioritise and share the updated timeline for this. Based on the current progress, end of April looks difficult to cover the serviceNow specific permission scenarios, reviews and to complete the QA cycle.  We can definitively try to enable in lower dev environment for early access for end of April. \n\n @Aditi Bhadouria, can you also please expedite the specs for RACL?"
    ],
    "spaces/AAAABcXBTWI/threads/0T5Q7z_JPhw": [
        "https://flip.it/thTWDF"
    ],
    "spaces/AAAABcXBTWI/threads/rNIMrBgvIgQ": [
        "Hi team, do we have any plans to support to integrate Custom LLM with SearchAssist?",
        "Hi @Ichiro Fukuyama \n\nYes, we do have a plan for it for May-June. But this feature is not going to be the same as the custom LLM in the XO Platform. It will be a different approach to let the user connect to a LLM of their choice.",
        "Hi @Aditi Bhadouria , Thank you for your answer. Let me make sure one thing. SearchAssist already supports this integration with OpenAI and Azure OpenAI, we can use Custom LLM with SearchAssist in the same way, is it correct?",
        "Yes, but the experience of the feature is different compared to XO Platform",
        "Got it. Thank you!",
        "You can set up a call between me and the client whenever we need to start implementing this, so we can go over the technical aspects.",
        "Cool, if my customers hope so, please kindly let me ask for your help. And Japanese customers may prefer documents rather than conversation. In that case, please let me ask you if there are any materials in English that we can show to the customer at that time. (I will translate it in Japanese)",
        "Sure",
        "Hi @Aditi Bhadouria I have a similar requirement for a strategic government entity in Abu Dhabi. They want to deploy a life coaching human avatar bot in English and Arabic connected to XO & search assist that answers employees' work-related questions and helps improve their well-being. Due to data security concerns, they prefer using a custom LLM and wants to host the solution on-premise. Is the feature of using a custom LLM in SearchAssist now available?",
        "+"
    ],
    "spaces/AAAABcXBTWI/threads/EFFqHbAQ404": [
        "Hi team, I am following the steps in this document to integrate SearchAssist and SmartAssist.\nhttps://docs.kore.ai/agentassist/settings/configure-knowledge-retrieval-via-searchassist/#How_Does_It_Help_Agents\n\nI completed the steps to 5. and connected without problems, but SearchAssist search results do not appear in AgentAssist. (with chat channel) I tried both AgentAssist V2 and V3 and nothing shows up in AgentAssist. Also tried entering search words directly into AgentAssist, but it was same.\n\nDo I need to do more thing? The documentation does not describe the steps after a successful connection.",
        "@Ichiro Fukuyama please check you have enabled fullsearch API scope in the searchassist application for client credentials.\n\n@Madhuluck Kumar",
        "@Ichiro Fukuyama - Apart from API scopes , please double check this FAQ as well \n\nhttps://docs.kore.ai/agentassist/frequently-asked-questions/faq/#:~:text=q%3A%20why%20searchassist%20results%20do%20not%20show%20up%20despite%20being%20configured%20with%20agentassist%3F"
    ],
    "spaces/AAAABcXBTWI/threads/pZUTW-Hi74A": [
        "Do we have a coveo connector for Search.AI?",
        "@Michael Di Troia Coveo is a competitor for us in this space. \n\nPls let me know the use case for this connector.",
        "My former company is building their own genAI based solution and ingesting the data from Coveo.",
        "@Santhosh Kumar Myadam , I just encountered a prospect inquiring about ingesting Coveo data or accessing a Coveo index. This is just an FYI -- no action needed.",
        "In other words:  I'm locked into a contract with Conveo, my data is there, but I don't like using their tools??? And Kore's product is better, but I don't want to loose what I've already built.   Challenging."
    ],
    "spaces/AAAABcXBTWI/threads/30CJpZHHrew": [
        "Is there a way to export the results from \"Analytics\" -> \"Answers Insights?\" More importantly: is there any way to retrieve the results from that feedback form that gets displayed if you give a response a thumbs down?\n\nIn the past, I tracked the network traffic in the developers tools in Chrome, and that form wasn't actually sent back to our servers. If that's still the case, then we need to KILL THAT FORM. It is costing us a lot of goodwill with prospects.",
        "I have a prospect who wants to retrieve the comments behind these negative results",
        "@Surendra Subhash Salke ?",
        "SearchAssist API Swagger\n\nhttps://searchassist.kore.ai/searchassistapi/public/api-docs/#/",
        "Thank you @Martin Anibal Bonardi! I'll take a look. The goal is to retrieve the comments. Might be possible with /searchassistapi/external/stream/{streamId}/analytics",
        "No joy. In fact, the Swagger shows the Schema of the response to be:\n\n{\n  \"result\": [\n    {\n      \"query\": \"Propstream\",\n      \"clicks\": 0,\n      \"searches\": 1,\n      \"thumbsUps\": 0,\n      \"thumbsDowns\": 0\n    }\n  ],\n  \"totalCount\": 1,\n  \"moreavailable\": false\n}\n\nYou'll notice that \"comments\" is not an included field. The results I received reflect that same schema:\n\n{\n  \"result\": [\n    {\n      \"query\": \"Does Enact insure loans with previous bankruptcy?\",\n      \"clicks\": 0,\n      \"searches\": 1,\n      \"thumbsUps\": 0,\n      \"thumbsDowns\": 0\n    },\n    {\n      \"query\": \"what are the requirements for underwriting loans for 2 borrowers\",\n      \"clicks\": 0,\n      \"searches\": 1,\n      \"thumbsUps\": 0,\n      \"thumbsDowns\": 0\n    },\n    {\n      \"query\": \"what are the guidelines for cash advance from real estate sale\",\n      \"clicks\": 0,\n      \"searches\": 1,\n      \"thumbsUps\": 0,\n      \"thumbsDowns\": 0\n    },\n    {\n      \"query\": \"Does Enact insure loans with previous foreclosure?\",\n      \"clicks\": 0,\n      \"searches\": 1,\n      \"thumbsUps\": 0,\n      \"thumbsDowns\": 0\n    },\n    {\n      \"query\": \"What are the requirements for standard manual non-occupant co-borrower loan?\",\n      \"clicks\": 0,\n      \"searches\": 1,\n      \"thumbsUps\": 0,\n      \"thumbsDowns\": 0\n    }\n  ],\n  \"totalCount\": 5,\n  \"moreavailable\": false\n}",
        "@Todd Lewis \n\nI am sorry for the discrepancy between the UI form and the analytics table. This story is planned to be delivered in two phases. The feedback message and answer debugger will not be persisted in the first phase.\n\n@Rushivar takhur please disable the comment box in the Sdk feedback form until both phases are delivered.\n\nThank you for your understanding. We will take  up analytics export as FR.\n\n@Aditi Bhadouria @Bharat Rekha",
        "Sure @Surendra Subhash Salke"
    ],
    "spaces/AAAABcXBTWI/threads/WEeSII7jjQ0": [
        "there are following questions from prospect customer who has implemented Product Search (search assist) . This is in pilot now\n\nBot (search assist) have scanned about 630 URL pages to train its knowledge. Now certain pages are no more valid and also specify pages will be updated. \n\nHow does Kore AI KB will retrain to remove the knowledge from the URL that will need to be removed and no more valid? Please explain technically at the level of Vector DB.\nHow does Kore AI KB will retrain to update the knowledge from the URL that will have new information in few days? Please explain technically at the level of Vector DB."
    ],
    "spaces/AAAABcXBTWI/threads/tkRtxf8HRcw": [
        "I removed the files, disabled the Sharepoint connector, and trained the App multiple times, but I still see the chunks. Do you know if this is normal? How do I remove old chunks without deleting the App?",
        "This is not expected. We will fix this bug and update you",
        "CC: @Surendra Subhash Salke @Bharat Rekha",
        "Disabling the SharePoint connector with stop the sync but keep the existing data.\n\nRemoving/ deleting the  connector will delete the chunks.\n\n@Aditi Bhadouria @Andy Pham @Bharat Rekha",
        "@Surendra Subhash Salke, as mentioned, I removed all the files from Sharepoint and Synced the app. I shouldn‚Äôt have to disable or delete the connector. Right?",
        "Hi @Andy Pham \n\nThanks for the additional details. This is a bug. Being tracked for the closure.",
        "Thanks! I deleted the S.P. connector and trained the app multiple times, but I still see the old chunks."
    ],
    "spaces/AAAABcXBTWI/threads/zyVZlGjrwYc": [
        "Can we detect and respond to user dissatisfaction with the search responses beyond mathematical metrics and explicit feedback? I‚Äôm interested in exploring the use of behavioral and contextual cues, such as:\nQuery reformulation (e.g., rephrasing the same question)\nFollow-up questions (e.g., asking related questions)\nTime spent on results (e.g., dwelling on a particular response)\nNumber of queries (e.g., repeatedly asking similar questions)\nOther contextual signals (e.g., user location, device, previous interactions)"
    ],
    "spaces/AAAABcXBTWI/threads/W0nEZHh9PqI": [
        "good ideas @Andy Pham I will ask team to add these into roadmap and prioratize"
    ],
    "spaces/AAAABcXBTWI/threads/BupGoi9OLX0": [
        "I have a customer asking for SFDC Case search and providing generative answers from case data fields. Is there a plan to allow Case Data extraction as part of our standard connector or using any alternate method?"
    ],
    "spaces/AAAABcXBTWI/threads/ds5cr-4VHco": [
        "I remember there is a way to disable to show the Files  as below but i forgot where I configure.. anyone can help?",
        "Use XO to customize the response when no content is available.",
        "You can customize the result templates. Just delete the required fields and you will stop getting search results",
        "@Aditi Bhadouria ... i tried to find the search template in v11 but cannot locate it . Any clues ? I can find in v10 and it works but just do not know where is it in v11"
    ],
    "spaces/AAAABcXBTWI/threads/S1zYSzbrItc": [
        "what are the differences for following models?"
    ],
    "spaces/AAAABcXBTWI/threads/yR0tyhh2_Fc": [
        "In v11, I have trained the SearchAI (Answer AI). I can see the chunk. When I test it using the bot , it always returns \"I do not understand\". With the same documents and questions in v10 SearchAI, i can get the result. Do I miss something?",
        "Have you enabled the embeddings and selected the model for answer generation in \"Answer Configuration\"? Can you also share which environment is this? \n\nSearch AI should not be available in XO 10. It is only available in XO 11",
        "and",
        "i am using https://platform.kore.ai/builder/app/generativeaitools with my mailinator.com testing account",
        "Can you confirm the embedding model? We are currently having issues with E5 model. Please use MPNeT and try again",
        "yes it is",
        "i have confirmed all settings and retrained.. still cannot get tne answers",
        "Thank you for the confirmation. @Surendra Subhash Salke can we please have someone look into this",
        "@Sunny Lun Can you add record_title in index-->source-fields and train the application.",
        "@Surendra Subhash Salke .. try your suggestion as below and train again. but still do not return any response during the Testing"
    ],
    "spaces/AAAABcXBTWI/threads/WVHR6owL6JM": [
        "Team:\n\nI have an issue with the SearchAssist API Call timing out for a number of queries for a Customer's Paid Pilot that is launching tonight. I have entered a ticket for this but need help getting this resolved ASAP.\n\nhttps://support.kore.ai/hc/en-us/requests/42427",
        "@Bharat Rekha can we get on call to look into this?",
        "Team is looking into this issue. This looks very specific to this app and not noticing the similar issues with other apps. \n\n@Sunil Singh / @Mani Kumar Nadella please update the ticket post the analysis.",
        "Thank you"
    ],
    "spaces/AAAABcXBTWI/threads/hIeySHbhsK0": [
        "SA Team - For Search AI, what SharePoint versions does our connector support??",
        "Hi @Gurpreet Singh \n\nPlease refer to this for the version details https://docs.kore.ai/searchassist/manage-content-sources/connectors/sharepoint-connector/"
    ],
    "spaces/AAAABcXBTWI/threads/kd0nhK2lcSM": [
        "@Justin Williams"
    ],
    "spaces/AAAABcXBTWI/threads/Vps05Jx9M6k": [
        "Outside of Alaska Airlines/Morgan Stanley - are there any current live customers of SearchAI that could speak to a prospect of ours?\n\n @Dalton Trout",
        "Carestream Dental"
    ],
    "spaces/AAAABcXBTWI/threads/OyqMC88o8Io": [
        "@Jon McCain  we are joining the bridge https://meet.google.com/zsq-cfvo-quz?pli=1&authuser=0 , wh can join this bridge to help in investigation"
    ],
    "spaces/AAAABcXBTWI/threads/dENDPoU858w": [
        "redirecting this issue to a different bridge \nhttps://meet.google.com/jpd-hcfc-nsx",
        "@Sunil Singh  - what is update here. what recommendations we provided. Client has come back to me that we suggested to prioritize extractive approach over LLMs. Client is not agreement with this approch",
        "Why have we recommended Extractive answers over Generative answers? @Sunil Singh can someone brief me on this please?\n\ncc:  @Bharat Rekha",
        "It is not recommended @Aditi Bhadouria. They tried to check the Llm latency while debugging. Issue is resolved as per latest update",
        "Ok. Thank you Bharat."
    ],
    "spaces/AAAABcXBTWI/threads/_MntabdN-Bc": [
        "Hi Team, I have a prospect who is working through a PoC with SearchAssist. They are seeing roughly 85% accuracy with their underwriting guidelines but want to do some additional tuning. What documentation do we have to help this prospect tune the bot? \n\n+ @Adam Warshaw",
        "@Girish Ahankari @Surendra Subhash Salke Do we have a document that educates customers on how to help the tuning of SearchAI?  If not, can someone from the product team get on a call to help our prospect?  Trying to close this ~$200k Search deal in May.",
        "@Adam Warshaw \nWe do have a few internal documents. We are now consolidating it and making it ready to be shared with customers. This got delayed for some reasons. It will be ready by Monday/Tuesday. \n\n @Rohit Tambe",
        "Ok, in the meantime - is there someone available to help us now?",
        "@Adam Warshaw can you check if any other SE can help you in this. If there are any specific questions, please post and we will answer",
        "@Adam Warshaw and @Dalton Trout which deal is this for? You should be going through your SE first and let them pull in resources and escalate to their manager/me/Aayush. This is also why we need to get all required resources accounted for before embarking on a POC.",
        "Enact.  Im surprised we dont have any documentation on how customers can do additional tuning.  Thats what they are looking for.  Todd is the SE",
        "@Adam Warshaw let's setup a meeting to discuss on Monday and come up with a strategy until we have the documentation available. We slammed the SearchAI team with deal support over the past 6-8 months, they were at one point probably spending more time helping us with POC's than working on the product or documentation.",
        "HI Santosh - are these documents available?",
        "@Santhosh Kumar Myadam any update on this?",
        "@Matt Panaccione Yes, this is now ready for internal consumption. \n\nPlease do let us know if there are any other areas that we should focus on\n\n Search AI - FAQs - Internal \n\n @Rohit Tambe  @Aditi Bhadouria",
        "@Santhosh Kumar Myadam This says internal. Is there an externally shareable document?",
        "@Santhosh Kumar Myadam just following up to see if this be shared externally? Thanks"
    ],
    "spaces/AAAABcXBTWI/threads/HeMPWYu3eVg": [
        "SearchAssist team: check out this cool video of SearchAssist integrated with Confluence, Slack, and Jira! https://www.loom.com/share/835ec43cdb3e4ebc952abfd242f18a83?sid=752be9c0-dd7f-4252-8be2-43c01940fb0b\n\nThis demo is for a dev team within Capital One. I know that I'm going to be asked the question, \"Can you crawl our past issues (tickets) in Jira?\" The documentation for our Confluence connector specifically states that it only crawls \"manually created Knowledge articles in Confluence\"¬†(https://docs.kore.ai/searchassist/manage-content-sources/connectors/confluence-connector/).\n\nHow can we add support for crawling issues to our connector for Confluence?\n\nOr perhaps more specifically, can we add a connector to crawl Jira?",
        "Good use caseüëç",
        "I am aware that crawling issues in Jira will require me to either create a new OAuth credential with Jira-specific scopes, or add those scopes to an existing credential being used by SearchAssist (which is what I did here). My hope is that the data mapping of the various elements within an issue isn't too difficult.",
        "We will be presenting this demo to Capital One tomorrow, 03 MAY at 13:00 EDT.\n\nI sincerely appreciate your thoughts about crawling Jira well before then!",
        "@Todd Lewis Jira connector is in our immediate roadmap. We will be adding it as a new integration, and yes that would require you to get JIRA specific credentials and configure a new connector apart from Confluence.",
        "If you have any inputs from the client on how to use that connector and perform the data mapping, I'd be happy to take that input and use it in the development of the feature.",
        "That's great! There isn't a way to create a page in Confluence that takes all of its information from a Jira issue. I saw there was an option to create a page, but it opens a blank template; the issue information isn't summarized or copied over.\n\nI only mention this because there isn't a built-in way to move this information over to Confluence if I wanted to provide a short-term solution. Having a new connector to Jira is the right answer.",
        "That looks cool - but be sure to use \"Search AI\" and not \"SearchAssist\", especially when engaging the customer - need to switch our language over to the new naming and not use the old product names",
        "@Todd Lewis can you also add the answer that SearchAI provided to Jira ticket? That would close the loop.",
        "Take 2 @Aayush Mediratta @Richard Passavant https://www.loom.com/share/835ec43cdb3e4ebc952abfd242f18a83?sid=752be9c0-dd7f-4252-8be2-43c01940fb0b",
        "@Aditi Bhadouria Capital One's team also wants the AI to crawl Github.\n\nIt's an interesting question because their answer takes this bot in one of two directions. If they're thinking about crawling the code then they might be thinking the LLM can help them with code generation.\n\nIf they're interested in the reported issues, then that's a different story. I'll find out what data elements they are specifically looking for.",
        "Perhaps the name of this chat should be changed üôÇ"
    ],
    "spaces/AAAABcXBTWI/threads/jyoxwQPGxiQ": [
        "Hi Team: Is it possible to use Kore XO GPT to rephrase Text/Answers extracted by SearchAssist from Knowledge Base using Extractive Model..? (I am looking to avoid Commercial LLMs Usage)",
        "Work is in progress on that. If the customer is ready to be part of the Pilot, then let us know. This will need customer to be involved in sharing the feedback with us."
    ],
    "spaces/AAAABcXBTWI/threads/vmHnGHFwbkA": [
        "Hello, our customer FL Blue is evaluating Search AI in our public cloud, but they seem to have lost access (see screenshot). Please help",
        "@Chiti Musonda Please describe the issue in a few more details. Did they lose any apps that they have created? DO they have 'enterprise' account on our cloud?",
        "@Santhosh Kumar Myadam FL Blue is currently on-prem so they do not have an enterprise account on our cloud. However, they were 'checking out' the Search capabilities on the public cloud. There's currently an active project to migrate their on-prem footprint to VPC. I'm waiting for confirmation if any Apps/data was lost with the access",
        "Adding to this, customer has confirmed that they did create a test App and would like to pick up where they left off and explore further"
    ],
    "spaces/AAAABcXBTWI/threads/qVrAQ1OmXm4": [
        "Hey team! Is there a way to prioritize one type of content for answers over another? For example, if an answer can be addressed by an FAQ then use that answer instead of what might have been extracted during a web crawl or an uploaded document.\n\nIf so, then how?"
    ],
    "spaces/AAAABcXBTWI/threads/A3R_DXcvXC0": [
        "Hi Team, Does anyone have correct url of SearchAssist in EU? I have to share it with LSEG who are in EU cloud."
    ],
    "spaces/AAAABcXBTWI/threads/IDV45SzO_Sw": [
        "Don't think we have SearchAssist set up in EU cloud. @Santhosh Kumar Myadam ??"
    ],
    "spaces/AAAABcXBTWI/threads/MzHi5qK-_fE": [
        "https://de-searchassist.kore.ai",
        "I am aware of 'DE' instance. I need 'EU' please"
    ],
    "spaces/AAAABcXBTWI/threads/VhtWplAVJUI": [
        "That's Frankfurt. Komal is asking for UK I believe."
    ],
    "spaces/AAAABcXBTWI/threads/1hm-6QIH-Ek": [
        "Hi Komal,\nWe don't have EU instance for searchassist.",
        "When can we have that, please?",
        "@Vidit Gupta  @Surendra Subhash Salke",
        "@Komal Joshi the du would be eu instance? you need uk instead?",
        "Frankfurt/EU/DE are the same",
        "No.. https://eu-bots.kore.ai/botbuilder/ - is hosted in Dublin for UK . It was called EU prior to Brexit. Then we created de-bots.kore.ai/botbuilder/ for Frankfurt to comply with GDPR",
        "No. We cannot use \"De\" instance for UK customers due to GDPR. for UK customers we need it in \"EU instance\".",
        "Ok - @Aditi Bhadouria",
        "I think Komal is looking for the searchassist for the eu-botsinstance.",
        "Frankfurt/EU/DE is the same for SearchAssist and usable in the European Union. Post Brexit, there was a new instance for the UK, which SearchAssist does not have. XO platform has that, you can enquire in the platform group.",
        "Sorry I am confused. Should I ask for SearchAssist set up in the \"EU\" instance for UK in the XO platform group?",
        "As mentioned above, there is no EU instance for the UK due to Brexit. The instance available to use in the European Union is referred to as Frankfurt or DE. There is no UK instance for SearchAssist. It is, although available for Platform.",
        "What about XO11?"
    ],
    "spaces/AAAABcXBTWI/threads/jxX0jqJfDfA": [
        "Q: My client has a website portal based off sharepoint, with hyperlinks to documents (pdf, docs, etc). Can the web crawl pick up both the webpage content as well as the linked documents?",
        "Only the web pages will be crawled. Linked documents will not be crawled",
        "Ok good to know. The documents may be stored in multiple doc libraries on sharepoint. Does the sharepoint connector allow to choose more than one directory?",
        "You can choose multiple sites in Sharepoint. Not sure what directory means here",
        "Thanks, that is helpful. These sites may have folders (directories). Are we able to select at the folder level too?",
        "This is not available currently",
        "But we can add it to the roadmap",
        "I think Eva has such capabilities, but not sure how extensive they are.",
        "Can you crawl the website and also use the Sharepoint connector? To put it another way, SearchAI can do that. Can your client?",
        "Did u mean ‚Äúif a webpage has a downloadable link to say a datasheet, we won‚Äôt be able to crawl it?‚Äù And those datasheets need to be ingested separately?",
        "@Aditi Bhadouria ^^ Keysight would like to know the answer to the above. Also, if we are not able to crawl / ingest the \"content\" in the linked datasheet / document, do we ingest the link itself? Pls take a look at the snapshot for more understanding. The idea is to return the link back to end user as a SearchAi response and let them open it manually."
    ],
    "spaces/AAAABcXBTWI/threads/qd0jD53HYWw": [
        "Will structured data be added as a source similar to that which is currently in SearchAssist??",
        "Yes. It is planned for June"
    ],
    "spaces/AAAABcXBTWI/threads/Avk6nFZaUp4": [
        "Team, the following page lists the type of documents supported by searchassist. Do we have plans to support excel files? https://docs.kore.ai/searchassist/manage-content-sources/managing-data-from-files/"
    ],
    "spaces/AAAABcXBTWI/threads/pXiVqo5Kzlg": [
        "Webcrawl doesn't seem to be working, I've tried several sites that have been known to work in the past. It just sits \"in-queue\" indefinitely. I've tried bookstoscrape.com, MS support site, etc..",
        "See the same issue"
    ],
    "spaces/AAAABcXBTWI/threads/Frm633mXul4": [
        "On call team? Please check asap"
    ],
    "spaces/AAAABcXBTWI/threads/VYl5ZKBCidk": [
        "Hi Girish, We are looking into it"
    ],
    "spaces/AAAABcXBTWI/threads/VylcXXXu220": [
        "XO11 works when I crawl the bookstoscrape.com website"
    ],
    "spaces/AAAABcXBTWI/threads/JilGBwAZwbg": [
        "@Girish Ahankari Crawling issue is fixed now.\n @Matt Panaccione  @Martin Anibal Bonardi Please check once.",
        "@Mounika vemula Of course, I'll test it now",
        "The partner reported that it is now working normally\n\nWe will carry out more tests, thanks so far!",
        "Thanks, it works now."
    ],
    "spaces/AAAABcXBTWI/threads/TlPNz-JRkD4": [
        "Szenario: Customer from 2-3 years ago is up for renewal. XO platform only. I get them to buy-into the new subscription (Enterprise SKU) to have access to RAG. But they do not want to move to XO11 right now...Can they stay on v10 and we enable SearchAssist for them?",
        "@Santhosh Kumar Myadam @Girish Ahankari",
        "@Martin Jahn yes"
    ],
    "spaces/AAAABcXBTWI/threads/7CEBQl85lJc": [
        "when will we support video format in Answer AI?",
        "@Sunny Lun did you get an answer on this? I've got a customer asking about multimodal (images, video). \n\n @Aditi Bhadouria  @Rohit Tambe  @Surendra Subhash Salke",
        "@Laurence Schoultz .. not yet",
        "I've a couple of customers asking for this too! Do we have this planned in near future? @Surendra Subhash Salke @Santhosh Kumar Myadam"
    ],
    "spaces/AAAABcXBTWI/threads/K5xVfSN6eoA": [
        "Hi Team, is it possible to use Azure Active Directory to control access to certain documents within an organization?",
        "H Team, I received additional context from my prospect in what they're looking for:  \"They said Microsoft is going to deepen their API capability so that you will be able to connect right down to the semantic kernel that they have, which will allow you to pull in the permissions at like a like one drive level.\"  Will they be able to leverage their Azure Active Directory to control access to certain documents?\n @Graeme Dean"
    ],
    "spaces/AAAABcXBTWI/threads/7pesPesQJ7Y": [
        "@Martin Jahn is this an upsell?",
        "That what I am trying. They currently pay us 30K. I would like to get them to the enterprise SKU for 40k plus sessions so they can use RAG/SearchAssist. Do they need to migrate to v11 then or can we enable SearchAI w/ XOv10 until they move to v11 (whenever this will be)",
        "@Martin Jahn we can enable SearchAssist as long as we have an upsell üòÄ",
        "So that's a yes?!",
        "But just for 10k of upsell? I think you might want to check with @Peter Wulfraat",
        "It's 16 to be precise lol",
        "Totally get the financial aspect...I just want to become stickier in the account and help us consume more sessions",
        "And create more use cases",
        "I am fine, as long as other leadership is fine with it",
        "@Manav Khandelwal for info"
    ],
    "spaces/AAAABcXBTWI/threads/dMlnQEnBSGA": [
        "Trying to ingest data from web pages in German but facing issues. Seeing the error ‚ÄúEncountered HTTP error while processing the request‚Äù. Looks like there is some issue with the URL's. When I try to access the URL, the webpage doesn't have any content in its body, which is why it's not crawled. However, if we set \"dev_Enable_Clean_Page_Body\" to false in the custom configuration under indices, we can crawl the URL. But even after successfully crawling it, the body remains empty. There is an open ticket for this and the decision to use Search AI or depends on this live extraction. \n\nIs there an issue with the HTML structure of the websites? What to convey to the customer to correct? This is an enterprise website, any ideas how we can crawl the data?",
        "I am assuming this is in SearchAssist as we don‚Äôt have custom configurations in XO 11. Have you tried using the crawl delay custom config?"
    ],
    "spaces/AAAABcXBTWI/threads/XC_e1_sfJ8s": [
        "https://www.shell.de/punkten-und-sparen-mit-shell-clubsmart",
        "@Amit Baweja I used Javascript enabled option along with the crawl delay set to 9. I was able to successfully crawl this website.",
        "You can refer to this for understanding why this feature helped https://docs.kore.ai/searchassist/manage-content-sources/managing-web-content/#Troubleshooting",
        "Hi @Aditi Bhadouria. Thanks for the suggestion. I have reset the crawl delay to 9 and it‚Äôs working for few of the Web Page URL‚Äôs but still it‚Äôs not working for all the URLs on both DE and UK locale. Also, pls confirm if I need to set the Crawl Depth and Max URL value as ‚Äú0‚Äù for this configuration.",
        "These are the webpages where its still failing. Pls suggest. Let me know if you need access to the app or want to get in a call. Thx.\n\nDE\nhttps://support.shell.de/hc/de¬†\n¬†\nUK\nhttps://support.shell.com/hc/en-gb\nhttps://www.shell.co.uk/help-and-support/help-centre.html#help-centre=category/",
        "@Aditi Bhadouria Pls advise.",
        "Can you share the app. I'll go through it and we can set up a meeting if required",
        "done"
    ],
    "spaces/AAAABcXBTWI/threads/p7BUspTuWvE": [
        "Hi @Aditi Bhadouria , when are we releasing Box connector? Do we have any latest roadmap info on new connectors?  It was requested last year around August and partner wanted to know if we are really going to support Box or not.",
        "@Sandeep Singh Rana We are maintaning the overall roadmap including the connector roadmap in the below link. Search AI - Product Roadmap - Updated Mar 2024",
        "Thank you, @Aditi Bhadouria"
    ],
    "spaces/AAAABcXBTWI/threads/cOyRrgfOil4": [
        "Hi, team.\nI have one question from using search AI of XO11.\nAfter training with the chuck sizes set to pages, each time I train one more time later, the chucks overlap and the number of identical chucks increases. Is this just a bug? Or was it intentional?\nAddtionally, chuck is the maximum token size 1000? In version 10, more size settings were possible.\nI would appreciate your reply.",
        "Duplicate chunks should not be created. We will look into this. \n\n@Vaishali Addala Can you please try to reproduce this issue?\ncc:  @Surendra Subhash Salke  @Bharat Rekha",
        "Already we raised bug for this issue @Aditi Bhadouria - developers are working on it \n\nBug id: https://koreteam.atlassian.net/browse/XOP-9234",
        "Thanks for the update. @Inseon Park We will update you when this is fixed",
        "Thanks for comfirm"
    ],
    "spaces/AAAABcXBTWI/threads/r4btnKVcqjM": [
        "@Billy Reilly We are currently actively developing RACL. RACL allows us to honor the permissions that have been set for a document as part of the third-party connector within the search application. \nE.g.: User D can not get an answer from a document that has only been shared with users A,B, and C within Google Drive.",
        "This feature has to be developed from scratch for each individual connector. Currently, we are focusing on adding this for Google Drive, Confluence, and SharePoint. We can prioritize Azure Storage next based on other priorities. To commit to any ETA, though, we would need to do a more in-depth exploration of this.",
        "@Aditi Bhadouria That's helpful, thank you."
    ],
    "spaces/AAAABcXBTWI/threads/HE_UvmA3MMk": [
        "Trying to integrate ServiceNow and SearchAssist - the documentation states OAUTH creds are required but is it possible to integrate searchassist with Servicenow knowledge using Basic authentication (Service account)?",
        "@Santhosh Kumar Myadam @Aditi Bhadouria",
        "We don't currently have support for basic auth for ServiceNow"
    ],
    "spaces/AAAABcXBTWI/threads/eM47yKOcKKc": [
        "API help \n\nTeam, I've got two issues using the Full Search API. \n\n1) I've published the bot and the API no longer responds with any payload, but returns a Status 200. In the Dev console it returns an answer payload just fine. See attached JSON. \n\n2) When I search 'whats your returns policy', I get a perfect answer. If I modify the search slightly, 'What is your returns policy?', it does not return an answer 50/60% of the time... Why would such a small variation in punctuation/format have such an effect? This seems to be intermittent, it weas working earlier this morning and now is no longer working. I've attached a second JSON in the thread below.",
        "JSON for second issue:",
        "@Aditi Bhadouria @Rohit Tambe @Surendra Subhash Salke I have a demo tomorrow so any help today would be appreciated.",
        "UPDATE: fixed issue #1. When connected to SmartAssist, a different lastmessage variable is used.",
        "Still need to understand why issue #2 is happening.",
        "@Venkata Naresh Divi Can you check the second issue?",
        "@Venkata Naresh Divi did you find anything? Performance is even worse today. Even directly in the app...",
        "Hi @Laurence Schoultz I tried the scenarios you mentioned from the app you shared, Im getting answers for all of them",
        "I changed the Model to 3.5turbo from GPT4 around 1.5 hours ago and it performs far better",
        "Why is there such a discrepancy? Are we doing any filtering/anything different with responses received from the two models?",
        "We dont do any sort of filtering w.r.to results returned from LLMs. GPT3 is a deprecated model, so please use the current 3.5 turbo which is ocnfigured",
        "I'm not using GPT3 at all. I originally had GPT4 (poor results), then moved to 3.5urbo (good results)."
    ],
    "spaces/AAAABcXBTWI/threads/3fi2rdi33RQ": [
        "Do we have a one pager that explains Data AI?"
    ],
    "spaces/AAAABcXBTWI/threads/aLZwHOwpfos": [
        "One of the Bank Customers who were not ready to use GenAI in SearchAssist previously, now want to at least get into internal discussions to see if it's feasible to use - they want us to help them \"define how it works and why it is 100% secure and no risk\". Do we have any documents/write-up we can share with them to reassure them on the security aspect ?"
    ],
    "spaces/AAAABcXBTWI/threads/OjX6o08GU3E": [
        "When we enable 'Answer from Documents' feature , this feature acts as the fallback task and the actual fallback dialog task is never triggered. How can we trigger the actual fallback task when the reply is not found in 'Answer from Document' feature as well?",
        "Give me a few minutes and I‚Äôll send you what I‚Äôve done for demos",
        "I'm using Answers on XO10, so that solution won't work. Thanks for trying. Any ideas @Santhosh Kumar Myadam?",
        "@Amit Baweja \n\nWhen nothing is identified from 'answer from docs', then the platform will trigger the fallback event. That is the expected flow. If that is not the case, please raise a support ticket. \n\n @Hariharan Velusamy"
    ],
    "spaces/AAAABcXBTWI/threads/kVDvfD3FFtc": [
        "Is SalesForce Case Data part of SalesForce connector? If not, is this planned on roadmap?"
    ],
    "spaces/AAAABcXBTWI/threads/bVL6hpSDIec": [
        "Can we read files from subsites within SharePoint? See the example from the customer below.\n¬†\n\"For example, we have a parent site called \"CBREIMInsightIntelligence\" and a subsite called \"IntelMarketReports\" (highlighted in red). Kore doesn't seem to be able to access files stored in \"IntelMarketReports.\"\n¬†\nLink :¬†https://cbre.sharepoint.com/sites/intra-CBREIMInsightIntelligence/IntelMarketReports/Forms/2024.aspx \"",
        "Hi, @Aditi Bhadouria. I have started a support case like you suggested. As the pilot evaluation is set to conclude in less than two weeks, we kindly request a confirmation (either yes or no) regarding the status of this capability as soon as possible. Thank you so much for your help.\nhttps://support.kore.ai/hc/en-us/requests/43179\ncc:  @Surendra Subhash Salke  @Melissa Prince"
    ],
    "spaces/AAAABcXBTWI/threads/B-_so6wZhd4": [
        "Hi team, Is there any Index field created automatically with the name of Directory? or.. could you please let me know how to -> making a index field and map the name of directory as a value by workbench ? Appreciate your help",
        "sourceName is an existing field that stores the name of all sources(Webcrawl, directory, connectors etc)"
    ],
    "spaces/AAAABcXBTWI/threads/tNLXe_W5YrQ": [
        "Hi Team,\nI encountered an issue \"No pages found to crawl\" in Web Crawl. Could you provide any advice on how to resolve this?\nThe target URL is an FAQ site for a customer, which can be accessed normally via a browser.\nhttps://teikibin.acuvuevision.jp/subscription/faq.html",
        "Error: The crawler did not find any pages to be crawled.\n\nYou can try the following:\n- Uncheck Respect Robots.txt directives in which case the crawler ignores the contents in the file and crawls all the URLs that are reachable.",
        "@Aditi Bhadouria We narrowed down the issue by checking the bahavior between US and JP production environment. It worked in US prod but doesn't in JP prod.",
        "Could you please support Ichiro to fix this as soon as possible? The zendesk ticket is is 43350.",
        "Hello @Aditi Bhadouria \n\nThank you for your advice. Based on your guidance, we checked the issue and identified the following. I appreciate you take a look this:\n\n1. We confirmed that the SearchAssist can crawl with the following settings in the US region. However, in the JP region, we encountered a different error message (Crawling Failed). This seems to be an issue with the JP region's SearchAssist.\n\n2. This prospective customer has numerous FAQ web pages under the following target URL. They want to crawl all FAQ pages in bulk using Web Crawl, but only the top page was crawled even EN region. Since they have many FAQ pages, setting up crawling manually for each page is unacceptable. How can we crawl all pages in bulk in JP region?\nTarget URL: https://teikibin.acuvuevision.jp/subscription/",
        "Hi Ichiro\n\nWhile the team looks into this, can we ask the prospect  to upload the URLs as a CSV file for crawling?",
        "@Santhosh Kumar Myadam \nThank you for your support. While we cannot obtain the complete list of URLs from the client, based on my checking the site, I would like the following pages to be crawled automatically at least.\n\nhttps://docs.google.com/spreadsheets/d/1CDx0ZOMs-Q13H_P-fGwPiglwxnnKlhpa/edit?usp=sharing&ouid=109684385282791499868&rtpof=true&sd",
        "Please raise a support ticket so the team can look into this. Meanwhile, you can use the Upload URL option and use the csv file you have shared",
        "Hello @Aditi Bhadouria \nThank you for your comment. I already have the following Jira & support tickets for this issue. Could you take a looks these tickets?\nhttps://koreteam.atlassian.net/browse/PLAT-29291\nhttps://support.kore.ai/hc/en-us/requests/43350\n\nI'll also try uploading the URLs as csv file.",
        "Hi @Aditi Bhadouria \nFollowed your advice, I uploaded the URLs with a CSV file and attempted crawling. It was successful in the US region, however, it still failed in the JP region. Since we need to provide a solution in the JP region for this prospect, I would appreciate your support with the ticket.",
        "@Bharat Rekha We need to look inti this ticket. \n\nLooks like there is a difference in the functionality between US and JP clouds.",
        "Hi @Santhosh Kumar Myadam, Sure we will check this. \n@Sreekar choppalli  can you please check this? \n\n Architecturally both US prod JP are same, we may be seeing an error which probably is not shown to user.",
        "Sure checking now",
        "Hi Ichiro,\ncan you please tell me which configuration for crawling you are using",
        "Hi @Sreekar choppalli ,\nPlease find screenshots, I crawled with \"JavaScript rendered\"+ \"Crawl Beyond Sitemap\". I succeeded it in the US region, but failed in the JP region.",
        "@Sreekar choppalli ,",
        "Can you try now once because I am able to crawl the url with the same configuration you provided in JP and US-Prod",
        "Here is the reference screenshot",
        "Hello @Sreekar choppalli \nThank you for the update.\nI confirmed that Crawling is now working correctly at my end as well. It is quite strange that it suddenly started working well after many failed attempts.\nIn any case, since the issue has been resolved, I will close the ticket. Thank you for your assistance."
    ],
    "spaces/AAAABcXBTWI/threads/YkqMQBMDiKI": [
        "Team, one of my customer is facing the issue where they had created the app few weeks back and was working fine. Now when they search no files are showing up in the answers. \nAlso when they are uploading files they are getting this failed Status and the preview of files is blank.\n\n*This issue is not happening if you create a new App.",
        "Please create a support ticket/customer incident so team can debug"
    ],
    "spaces/AAAABcXBTWI/threads/QkolZGyRVbw": [
        "Hi @Aditi Bhadouria, CBRE is inquiring if we plan to add this capability to our roadmap as it is not currently supported. Please advise. cc: @Melissa Prince"
    ],
    "spaces/AAAABcXBTWI/threads/ML7H4GmTOws": [
        "Hi @Andy Pham \n\nPlease create a FR for this. We will add it to the backlog. However, I can not comment on the ETA, estimated effort, etc, unless we have analyzed the requirement in detail. \nBased on the current available bandwidth, it might take time to prioritize it. \n\ncc:  @Santhosh Kumar Myadam  @Girish Ahankari",
        "@Andy Pham we will discuss internally and come back to you. Would this help in any upsell with the customer?",
        "How critical is this to make the implementation successful?",
        "or is it a nice to have?",
        "Also, can this not be solved by adding the othe links as another set for crawling?",
        "@Girish Ahankari CBRE is piloting our solution currently and is scheduled to end this month. This customer has many subsites, and they have emphasized the importance of a solution that offers this capability. \ncc:  @Melissa Prince",
        "@Andy Pham Sure, we will add it to the roadmap. Until then they can use the workaround of adding the link of subsite manually",
        "Hi @Girish Ahankari, @Aditi Bhadouria Have we committed this feature to our roadmap? Do we have an ETA?"
    ],
    "spaces/AAAABcXBTWI/threads/RVkPHp9Y4JU": [
        "Team, I'm using SearchAssist + Open.ai, with PDF documents loaded\n\nIt's working very well, however, even after refining the prompt to respond only in Spanish, sometimes this message appears in English.\n\nDo I need to open a ticket?",
        "@Martin Anibal Bonardi Yes, please create a ticket."
    ],
    "spaces/AAAABcXBTWI/threads/_NA8UJR0Vw8": [
        "@SearchAI Team - quick Q, if I crawl a website and find an answer that originally had a link to a document. Could I maintain the link in the gen ai response? This way, the user can click on that link and get to the document?",
        "Hi @Gurpreet Singh \nThis is currently not a feature available OOTB.",
        "Hey Aditi",
        "So all links are lost when crawling? Just text instead?",
        "Also let me know if you have a few min to talk. I Have a design question.",
        "Should we discuss in Office Hours?",
        "Sure",
        "Thx"
    ],
    "spaces/AAAABcXBTWI/threads/GQBdBezWpWE": [
        "Question 2 - FloridaBlue has a use case where a member interacts with a bot to search for information using SearchAI. The response should only consider a certain subset of documents/webpages that pertain to that member. Currently, FloridaBlue's website only shows certain UI elements to a member based on what is relevant for them. FB want to enable search using the same idea. I thought of a few approaches to solve for this:\n\nOption A - I can create multiple indices (or apps), each one based on a member type, and execute a search against that member type's index to get the relevant scoped response\n\nOption B - create a single index, and use advanced API and use the filters to consider which pages/documents are in or out of scope for that query, all based on the member interacting with the bot.\n\nOption C - create a single index, and use business rules to include or exclude certain pages/documents.\n\nOption A seems the least complex, but may require crawling some same content across the indices/apps. Options B and C are more complex and require more configuration and could be more cumbersome to maintain.\n\nI wanted to know what the SearchAi team recommends, or what other consideration I should look into before deciding the solution appoach."
    ],
    "spaces/AAAABcXBTWI/threads/UayDMaomePk": [
        "I am training Search App in pilot environment with 12 documents. Training has been running for more than 20 mins and all chunks are empty. Is there a known issue here?"
    ],
    "spaces/AAAABcXBTWI/threads/rl1IuRPiZV8": [
        "Hi Guys, is there a number i.e. \"number of documents / URLs\" that are considered enough to do a free PoC / showcase the value of our SearchAi solution? For instance, Keysight is giving us a sitemap which has about 29K URLs / Webpages and we're asking them for much less amount, what do you think would be an ideal number of URLs / Webpages we should ask to do this PoC?",
        "IMHO if they cannot see the value of SearchAI with 10 or fewer URLs... then they have no imagination or intelligence.  (don't tell them I said that LOL).  üôÇ \nSeriously, we should not be doing a full integration for them.  And SearchAI requires tweaking, A/B testing of different settings or even different LLMs to get the answers right, etc.  Its not as simple as upload and go. \n\n@Santhosh Kumar Myadam  could give his thoughts on this topic or your SE leadership should also guide you on this free POC request.",
        "why is a free POC being positioned?",
        "Its in discussion and we've not committed to customer anything as yet but I still wanted to understand what is the best threshold, in case we end up doing it FoC.",
        "Agree with @Tim Burke about the number of docs. \n\nCustomer should be able to understand the value by ingesting just a few docs. \n\nThe larger the volume , the longer would be the tuning process to improve the accuracy. Tuning may be required at any of the stages - extraction, enrichment , chunking, retrieval , thresholds or the prompt. \n\nThe fewer the better.",
        "It's not a production POC.  Only a 1 week internal \"test\" of SearchAI and accuracy.",
        "I doubt the prospect shares your view. A \"Production POC\" would be surely be labeled an \"oxymoron\". And I know stop calling me Shirley.",
        "Joel, Accuracy (which is most important) will require indepth knowledge of all of the levers to be pulled for \"temperature\" of the LLM, A/B testing of different Indexes, etc.  as Santhosh described above. Probably enablement on the toolsets. You would want to get assistance from the Demo team and Product teams to ensure success.  Don't just give them the tool and hope its successful.  üôÇ",
        "I agree with you.",
        "Is the deal in question still Juniper Networks?",
        "No, it's Keysight",
        "The problem is the veracity of the data",
        "\"Hey, I need a O scope capable of handling a 20 MHZ signal\". That can map to a lot of different models past and present",
        "Imagine a RAG system as a librarian tasked with finding a specific book in a library to answer a patron's question. As the library grows, the librarian's job becomes increasingly challenging",
        "@Navdeep Grover @Graeme Dean lets take this offline. Number depends on the success criteria. @Joel Baily i want to understand the scope and success criteria this before we commit to anything.",
        "I'm laughing at the example of an O-scope. How many people are going to track that one?",
        "At times I forget I am a complete tech nerd. Plus there is a Tektronix analog just above eye level in home office desk."
    ],
    "spaces/AAAABcXBTWI/threads/mnUsVLgmKo4": [
        "any new updated SearchAI videos or vision clips to share?"
    ],
    "spaces/AAAABcXBTWI/threads/W01_MVwVYUU": [
        "Hi All, Do we have a timeline for when Unified Xo will be available in the UK and EU regions?"
    ],
    "spaces/AAAABcXBTWI/threads/2Zxcu6GkNbM": [
        "XO11 is already there"
    ],
    "spaces/AAAABcXBTWI/threads/gpD5l_DEPaA": [
        "DE - https://de-platform.kore.ai \nEU:¬†https://eu-platform.kore.ai",
        "Thanks. Do they have XO GPT enabled in these regions? Are we ok to recommend customers to move to XO11 with multi-langauge?"
    ],
    "spaces/AAAABcXBTWI/threads/V5z-flWzl0A": [
        "Will SearchAssist actually crawl into documents that have been posted as downloadable links?",
        "No this is not currently possible out of the box",
        "Thank you @Aditi Bhadouria.",
        "When you say it‚Äôs not available OOB, do u mean it can still be accomplished via some custom config or 3rd party utility tool? @Aditi Bhadouria"
    ],
    "spaces/AAAABcXBTWI/threads/SjLAe0RLzss": [
        "A customer is trying to onboard publicly available help content from Zoom, Slack and Google websites, as they  have a number of troubleshooting questions that could benefit from the latest vendor content, but when trying to capture and train the crawler, the bot has trouble capturing javascript rendered content and even if we deselect to stick to the robot.txt boundaries it doesn't seem to grab the content in itself, only footnotes. \n\nIt isn't an error in itself, it is more of not getting everything from the page. Gmail is skipping the main content and going for the accessibility links in the end of the page for example. Slack is straight an error, it just states that there's no page to crawl. \n\nAny suggestions for doing this type of web crawling successfully?",
        "@Aditi Bhadouria",
        "@Amit Baweja \n\n1. For the error where we are unable to ingest the all available content/getting empty content. We can use the Javascript rendered option. Along with the javascript option it is important to use the crawl delay option as well. This is to ensure we are giving sufficient time for the website to load before crawling the content. \nIf you are still unable to ingest the required content you can try using the below custom config",
        "2. For the connectivity issue with Slack could you please open a support ticket so team can look into it",
        "https://support.kore.ai/hc/en-us/requests/44307",
        "@Aditi Bhadouria Ticket raised for Slack issue, can you please check",
        "@Aditi Bhadouria While this is taking its own course, customer has asked this. Do you have anything other than the doc site that may help them?\n\nBig part of my issue with the webcrawler is my lack of familiarity with the tool in itself, like the custom configs I have a grasp of why you suggested, but the help available on documentation isn't enough for me to understand how Kore's crawler works. I assume it behaves like some sort of SEO tool, but my knowledge on the subject is super limited. Could you share some knowledge sources that might help me understand better how to crawl on public pages, please?",
        "@Amit Baweja https://docs.kore.ai/searchassist/manage-content-sources/managing-web-content/ \n\nCan you confirm if they have referred to this?",
        "Yes they did! And confirmed that it has been helpful enough with overall settings, but they're trying to understand what type of web crawler¬†Kore uses in the backend, so they can improve the chances of getting the data out of the sites when trying to find what level the texts sit and troubleshoot when there's no result coming back. They have a limited knowledge on crawlers as a whole, but there are different tools for troubleshooting so they're wondering which one Kore resembles most to make life easier.",
        "Any thoughts here @Aditi Bhadouria ?",
        "Sorry I missed this. I‚Äôll try to find an article on this give me some time. But one thing you can mention to them is that schema.org based websites will be best suited for the crawler we use"
    ],
    "spaces/AAAABcXBTWI/threads/2G1YrH6qkXQ": [
        "Team - any chance we can get start and end timestamps as part of the status?  Maybe even total run time.",
        "Thanks for the suggestion we will work on adding this to the status"
    ],
    "spaces/AAAABcXBTWI/threads/RHUmK-__Iik": [
        "I can see a timestamp when I hover. Is this start or end time?"
    ],
    "spaces/AAAABcXBTWI/threads/F2h_kj_mt-g": [
        "Maybe full timestamp would be helpful, with seconds and milliseconds, for both start and end times.."
    ],
    "spaces/AAAABcXBTWI/threads/Wt6OStHwG7s": [
        "Hello team,\n\nWhen uploading a pptx file larger than 6MB to SearchAssist, it failed with the error \"Content Extraction failed.\" However, when I reduced the content to make the file size under 6MB, it succeeded with the status \"Success.\" After testing with various slide patterns, it appears that \"Content for Extraction failed\" occurs regardless of the content when the file size is exactly 6MB. \n\nAccording to the product documentation, each file should not exceed 15 MB in size. Is there actually a 6MB file size limit in practice?\n\nhttps://docs.kore.ai/searchassist/manage-content-sources/managing-data-from-files/",
        "@Manasa Cheruvu / @Eswara Prasad Bonthu can you please take a look at this?",
        "Hi @Ichiro Fukuyama,\nWe don‚Äôt have any limit for 6 mb. Which environment are you using?",
        "Will check the issue Bharat",
        "Hello @Bharat Rekha \n\nThank you for taking a look this issue. \nThis issue has occurred in both the JP and US regions. Our prospect is using the JP region.",
        "Could you please share the app to @Manasa Cheruvu to investigate?",
        "Any app that you are able to reproduce this issue is fine",
        "Hi @Ichiro Fukuyama , can you please share the app with me",
        "Hi @Manasa Cheruvu I just invited you the app. Please find the invitation. I appreciate your support.",
        "Hello @Manasa Cheruvu ,\nDid you find the invitation of the app? If you didn't get the invitation, please let me know.",
        "Hi @Ichiro Fukuyama , I got the invite, checking the issue , will get back to you post analysis",
        "Hi @Manasa Cheruvu Thank you for your response& help! I look forward to your update. I need to have answers/solutions for an our prospect by the end of this week. Best regards.",
        "Hi @Ichiro Fukuyama , the issue has been reproduced in both US and JP instances. On further analysis , I could see that this file consists  of both images and data for which content extraction is failing .As part of PLAT ticket, fix will be provided. We will let you know about the release version cc : pruthvi.senapathi@kore.com",
        "Hi @Manasa Cheruvu ,\nThank you for the update! Can I see the PLAT ticket?",
        "Hello @Manasa Cheruvu\nDo we already have an ETA for this fix? I need to tell the prospect who is currently in the PoC phase about the plan. Best regards.",
        "Hi @Ichiro Fukuyama , will get back to you with the details in some time"
    ],
    "spaces/AAAABcXBTWI/threads/i6fIX3fRLFU": [
        "Hello Team, is Arabic supported in SearchAssist? I have uploaded an HR policy PDF file in arabic, but the results returned to the bot are not relevant to the submitted keywords or questions. Any idea?",
        "Are you trying Snippers(Extractive) or Generative Answers? Generative should work",
        "Hi Zaher \n\nThis url contains information about the various language supported for SearchAssist https://docs.kore.ai/searchassist/manage-indices/index-languages/\n\nYou can raise a Feature Request if required"
    ],
    "spaces/AAAABcXBTWI/threads/GQpkm2djD3g": [
        "In v11, we have unified the SearchAI and XO platform, is there any easier way to reformat the layout from the response from SearchAI (AnswerAI) in the Virtual assistant?",
        "Any good ideas on how to reformat the response from AnswerAI in v11 ?",
        "Hi @Sunny Lun \n\nYou can reformat it by writing a javascript under standard responses."
    ],
    "spaces/AAAABcXBTWI/threads/NjwF9Y4PrsA": [
        "Hi Team,\n\nI've created a new XO 10 Search Assist application and I'm attempting to upload auto manuals. It will let me upload them but then fails to consume them. Here is one of the pdfs. Do I need a specific setting enabled?",
        "A lot of images in there. Perhaps more importantly, there is \"side text\" on several pages, where they have included the portion of the manual like \"Introduction\" or \"Illustrated Index.\" I have had problems with loading documents with this format before.\n\nThe answer turned out to be to open the document in a pdf editing application, and then re-save it. I found https://www.libreoffice.org/ could do the trick and is open source. The results didn't look great, but the content was properly ingested.\n\nI tried it out on your file so you can see if it will work:",
        "@Aditi Bhadouria"
    ],
    "spaces/AAAABcXBTWI/threads/YA-MdcIX2IQ": [
        "Team - I have a search app where I'm not getting any search results. I AM getting Answers (snippet responses) though.  I checked result templates section but web is listed there. Any ideas?",
        "I created a new app, re-crawled the same pages and now I‚Äôm able to get answers and search results. However, my business rules for search results are not working. I have the same EXACT business rules for answers using ‚Äúvi_‚Äù notation and that works fine. Anything specific I need to do for search results to abide by my business rules?",
        "Please share the app with me",
        "Done",
        "Thank you. Please let me know if you have a few minutes to talk.",
        "@Aditi Bhadouria I think I found a bug (unless it's intended behavior). Whenever I add Spanish in the index settings, the training is auto-executed, and after that none of my queries have search results, only Answers.  When I removed Spanish and re-trained, the search results come back. So, is this a bug?  This at least explains why I lost search results last time."
    ],
    "spaces/AAAABcXBTWI/threads/05tF4MoJomQ": [
        "vi_ rules are for answer index. This rule is created on answer index fields.\n\nFor search index (search results) please  create a rule which does NOT start with vi_ and on search index fields.",
        "Hi Surendra - I did exactly that. Create the same rule conditions without vi_ but that doesn‚Äôt seem to work.",
        "Anyone have a few mins from the SA team that can help me with this?"
    ],
    "spaces/AAAABcXBTWI/threads/D7_20Zj70Qc": [
        "Hi All, My on-prem customers are keen to use XO 11. Do we have any information on the below two points: 1. What is the recommended migration path for on-prem customers. Is there any documentation? 2. Support for non-english languages for XO GPT and SearchAI."
    ],
    "spaces/AAAABcXBTWI/threads/Mw1lHhTBv6U": [
        "XO-GPT (Mistral) for Answers\n\nTeam, is this model also going to be available in the standalone SearchAI app? If so, when?"
    ],
    "spaces/AAAABcXBTWI/threads/1VUE1EHFbjc": [
        "We are currently testing this for quality and scaling."
    ],
    "spaces/AAAABcXBTWI/threads/4sIfZXwaZh0": [
        "We will update the ETA after some preliminary testing is complete",
        "Thanks Girish. Docusign (existing customer) have a short-term project that they need to move quickly on, but they're unable to use 3rd party commercial LLMs so naturally they're interested in using a local fine-tuned model. Please let us know a rough ETA asap.",
        "Do we have an ETA for XO-GPT (Mistral) for Answers in standalone SearchAssist?"
    ],
    "spaces/AAAABcXBTWI/threads/jWaEPZ1X8P0": [
        "I had told them that its available in XO11, if they want to do a POC.",
        "@Amit Baweja they want to connect it into their existing XO10 instance so would need standalone.",
        "Just got off a call with Aptia (opportunity with Mphasis) who've said they can only use local models for answers, Azure OpenAI/Custom LLM API is not an option. This is a near-term gateway opportunity (larger contact center and automation play later on) that we need to move quickly on. @Theo Baxter @Ranjit Prithviraj - to discuss. We will need to go with XO11 Answers module (which doesn't yet have all capabilities of standalone SearchAI)."
    ],
    "spaces/AAAABcXBTWI/threads/wdj85ReyR9E": [
        "One of my customers, Carestream Dental,  wants to trigger a feedback mechanism for autonomous learning. They're using SearchAI and want an autonomous learning 'event' to be kicked off when the user selects 'thumbs up' on the feedback survey. Is this something we can support? If so how? \n @Reilly Hughes  @Laurence Schoultz",
        "@Santhosh Kumar Myadam @Girish Ahankari @Reilly Hughes",
        "@Martin Jahn This is part of the Search AI roadmap. Tentatively, Oct-Dec '24\n\n @Aditi Bhadouria",
        "@Reilly Hughes - please convey this to Zuby from CSD"
    ],
    "spaces/AAAABcXBTWI/threads/p23TvQa2aq4": [
        "Maybe a GALE solution?"
    ],
    "spaces/AAAABcXBTWI/threads/c2XsonjT2SQ": [
        "I am getting this error when testing Search AI/Answers. Any thoughts?",
        "Please re-train the app. It seems there was an issue while generating the embeddings",
        "I will try a few more times tomorrow.",
        "Hi @Andy Pham \n\nThe unfortunate spelling mistake is being fixed.\n\nIn the interim, please check if you have enabled the embedding model in GenAI Features -> Dynamic Conversations -> Vector Generation, and train.",
        "@Surendra Subhash Salke is this not turned on by default?",
        "Yes, it is turned on by default for new apps.",
        "I trained the App a few more times this morning, and the results were the same. Let me create a new app and try it again. Let me know if there are any other tips/tricks you'd like me to try.",
        "I figured out the resolution. I changed the Vector Model from E5 Embeddings to MPNet Embeddings.",
        "I can now switch back to E5 Embeddings without any issues. However, the response didn‚Äôt contain the snippet reference using E5 Embeddings."
    ],
    "spaces/AAAABcXBTWI/threads/irHqCiWUS_0": [
        "Our customer NetApp has recently licensed Search AI to augment automation currently provided by their HR Bot. In the process of completing the necessary steps for SharePoint/Azure portal (with partner ANG Infotech), they have two questions from their IT Security Team they would like our help to answer - see below (Link to Doc)",
        "Hi @Chiti Musonda,\n\nThe permissions \"Directory.AccessAsUser.All\" and \"Group.Read.All\" are not required to retrieve the documents. However, these permissions are necessary for adding new features like RACL, which is currently a work in progress. You can remove both permissions now to sync the data, but please be aware that the new features will not function without them. Therefore, we recommend retaining these permissions for smoother future upgrades.\n\nPlease let us know if you need any further help."
    ],
    "spaces/AAAABcXBTWI/threads/WpPCMBxGhG0": [
        "@Sathya Priya Turaga work with @Chiti Musonda on collecting the usecase description, SPOCs, and solution architecture for NetApp",
        "Sure Girish."
    ],
    "spaces/AAAABcXBTWI/threads/jaf-18K52gY": [
        "@Bharat Rekha can we answer @Chiti Musonda 's questions",
        "Sure Girish, we will check and get back on this."
    ],
    "spaces/AAAABcXBTWI/threads/YrVaH2MUIFI": [
        "RE: Search AI\nWhen I switch the App from the dropdown, I continue to see the name of the original App. For example, from the home screen, I selected DevApp_2 and used the dropdown to switch to DevApp_3. When I try to perform a test by clicking on the Test Answers button, I continue to see DevApp_2 instead of DevApp_3. To see DevApp_3 displayed, I must access the App from the home screen."
    ],
    "spaces/AAAABcXBTWI/threads/jK3sxzifMRs": [
        "Although I removed all of the files, the chunks persisted. Also, can we use this space to list more chunks?"
    ],
    "spaces/AAAABcXBTWI/threads/UHol_prbHaE": [
        "We have a prospect with 50K documents, each ranging from 20 to 50 pages, in PDF, Excel, Word, and DOC formats, stored on SharePoint. Although SharePoint is in Azure, it can only be accessed privately. Additionally, they have a 10% year-over-year growth. Here are a few questions I hope you can assist with:\n\n1. Are there any issues using our connector to ingest 50K documents?\n2. What options are available to directly connect with their private cloud?\n3. Are there additional fees such as connectivity, storage, data ingress/egress, etc.?",
        "Cc: @Adam Warshaw @Melissa Prince",
        "Thanks @Andy Pham.  Team, we need to get back to the prospect ASAP, as this is a Q1 deal we are trying to bring in. Your help is appreciated.",
        "@Andy Pham Melodie this Going to be an OnPrem or private cloud deployment or our US cloud?",
        "#1. No issues with the volume",
        "#2. As long as their private cloud allows access to our connector, there should be no problem. If required, we can host searchAI in their private cloud too.\n\nPS: we have tested our connectors only with the public cloud versions of the Sharepoint. If they are using some older version, it‚Äôs untested",
        "#3. If it‚Äôs their private cloud, there is no additional fees. Let us know the deployment requirements for us to comment more",
        "@Girish Ahankari Do you have a few minutes to discuss over Zoom?",
        "These questions are specific to our SaaS offering. Let me rephrase the second question: What inter-cloud networking options do we offer, such as direct peering, gateway-to-gateway VPN, etc.?",
        "I believe we have done both. @Sai Krishna Dasari can confirm",
        "We can do via private link , vpn in aws"
    ],
    "spaces/AAAABcXBTWI/threads/a-Iat_1q7i4": [
        "@Girish Ahankari @Santhosh Kumar Myadam @Surendra Subhash Salke"
    ],
    "spaces/AAAABcXBTWI/threads/-v9tYkJgks0": [
        "@Andy Pham please find my reply and let me know if there are any further questions. Happy to help"
    ],
    "spaces/AAAABcXBTWI/threads/1_sl5UlFjXc": [
        "Team, I would like to confirm if a customer has intranet portal not exposed to the public internet, can we use connector to crawl data ?",
        "What technology are they using for Intranet portal? (Sharepoint or any other CMS). Is this portal protected by any kind of SSO or username password. These 2 factors would help you know whether it can be crawled or not"
    ],
    "spaces/AAAABcXBTWI/threads/PATgEkl6wa0": [
        "Team, I would like to confirm if FAQ from SearchAssist can support creating field as XO platform does (like Parent node). My current customer wants to create custom fields for FAQ as shown below.",
        "@Su Hyeok Seong \n\nIf you referring to the 'Ontology/Knowledge Graph' of the XO Platform, then it is not available in Search AI. We use a different approach (semantic similarity using embeddings) for identifying FAQs in Search AI. Support for graph/ontology is not available. \n\n @Aditi Bhadouria",
        "Thank you @Santhosh Kumar Myadam, Is there any way we can create Index field (or metatag) for FAQs ? what customer would like to do is using multiple categories for the faqs."
    ],
    "spaces/AAAABcXBTWI/threads/bXRmJkqmr8Y": [
        "Hi All, quick question - one of my customers is switching their payment processor from One,Inc. to TranzPay. In the workflow that we have already deployed they will need to replace One, Inc. Has anyone been through this or a similar process? I believe it is just configuring their tokens to the new provider but not entirely sure. @Peter Berbee @Santhosh Kumar Myadam",
        "@Reilly Hughes \n\nIs this about a change in the integration used in Service Node? Or, is it about a change in BankAsssit pre-built integration?\n\nAlso, this may not be the right group for this topic."
    ],
    "spaces/AAAABcXBTWI/threads/fW_847rXFfY": [
        "SearchAI in XO11 - Answer Analysis\n\nTeam, it appears answer analysis isn't showing up in the debug logs. Is this a known bug? I've tried with the local Mistral model and OpenAI GPT3.5, I get the same. Cleared my cache and I get the same result. \n\nhttps://www.loom.com/share/1b17341ff25348adbc9f3c47bb053514",
        "@Vaishali Addala @Aditi Bhadouria",
        "This is a bug @Laurence Schoultz. I'll update you with an ETA when this will be fixed"
    ],
    "spaces/AAAABcXBTWI/threads/tFDJaax5J-M": [
        "Analytics API -> Offset and Limit doesn't appear to be working\n\nI have set the Offset to 0 and the Limit to 100. And various other Limit values... But, the response only ever returns at max 15 results when the totalCount is 68.",
        "@Bharat Rekha can someone please check this issue?",
        "@Jon McCain PLease raise a support ticket for this",
        "@Aditi Bhadouria @Santhosh Kumar Myadam \n\nhttps://support.kore.ai/hc/en-us/requests/44301",
        "@Vamsi Lankisetty / @Rohan Chaurasia  - please check this issue.  @Sreekar choppalli",
        "@Jon McCain could you please try using \"offset=0&limit=100\"",
        "@Sreekar choppalli does that work for you in your test environment?",
        "I changed my query by making those parameters all lower case... and the result was the same for me.",
        "HI @Jon McCain,\n\nCurrently, we are unable to access the support ticket. Could you please share the APP or cURL with us?",
        "Below is the working cURL from our test app:\n\ncurl --location --request POST 'https://searchassist-pilot.kore.ai/searchassistapi/external/stream/st-f3fb277d-f2e8-5889-b644-7b804b409532/analytics?offset=0&limit=5' \\\n--header 'accept: application/json' \\\n--header 'auth: eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJhcHBJZCI6ImNzLTM1ZjFkYzVmLWYyMGYtNWQwMS1hNTI0LTFiODliOGM2M2NkMiJ9.Uzb8-uAiWo59uJQkycEHbu-2pBHWc5hhAC3bxvHUTZI' \\\n--header 'Content-Type: application/json' \\\n--data-raw '{\n¬† \"type\": \"QueriesWithResults\",\n¬† \"group\": \"hour\",\n¬† \"filters\": {\n¬† ¬† \"from\": \"2024-01-15T07:44:19.867Z\",\n¬† ¬† \"to\": \"2024-01-19T07:48:54.350Z\"\n¬† }\n}'"
    ],
    "spaces/AAAABcXBTWI/threads/LMpUTUM6GbM": [
        "Can a customer use BedRock as a custom integration?",
        "Maybe the info are here ...https://docs.aws.amazon.com/bedrock/latest/APIReference/welcome.html",
        "Moving this to the top. Has this been done? Do we have an environment where it's working?"
    ],
    "spaces/AAAABcXBTWI/threads/WW54Gj1aP2g": [
        "@Bharat Rekha any updates?"
    ],
    "spaces/AAAABcXBTWI/threads/QgHD3Te0CHU": [
        "Hi @Chiti Musonda, given these permissions are added specific to each of the connector API we have to do a POC ( explore the all API‚Äôs and test ) to confirm this. This work is active and is in progress, let me get back with an ETA for this, I am expecting a week. \n\nCan you please create zendesk ticket for this? It will help us to track, please feel free to indicate in the ticket to route to the engineering team."
    ],
    "spaces/AAAABcXBTWI/threads/T9gjlzjCJAY": [
        "Multilingual issues\n\nTeam, I've previously setup multilingual Search demos which have worked fine. However, in a new app I've switched on French and Spanish in Index Settings, switched to the Multilingual prompt in Answer Snippets, then I retrained but the app does different weird things: 1. It says 'Ok bye' when I give it a question in French. 2. It says 'Cannot find results'. 3. It gets stuck continuously loading. The app works fine in English. The app was built on searchassist.kore.ai. \n\nCould somebody help me troubleshoot?",
        "@Laurence Schoultz Can you try disabling small talk",
        "If it's still not working for french and Spanish do raise a support ticket",
        "Didn't work. I'm going to recreate the app from scratch. If it still doesn't work, I'll raise a support ticket",
        "@Aditi Bhadouria Is this related to issue that Gurpreet raised when he enabled Spanish? Reference - https://chat.google.com/room/AAAABcXBTWI/YA-MdcIX2IQ/emxQcq271mo?cls=10",
        "Thanks Umang for bringing that up. \nSpanish language could be causing the issue.  @Laurence Schoultz please create a support ticket so team can debug further",
        "Meanwhile if you try by just enabling French and English you should still be able to work on the app",
        "@Aditi Bhadouria removed Spanish. Same issues. I will raise a support ticket.",
        "@Vamsi Lankisetty - please check these scenarios. \n\n @Rohan Chaurasia/  @Sreekar choppalli  /  @Nikki Harjani",
        "Sure Bharat.",
        "@Laurence Schoultz - Could you please share the app with us."
    ],
    "spaces/AAAABcXBTWI/threads/smBySrzMeVI": [
        "SearchAI Source Custom Connector \n\n @Girish Ahankari  @Aditi Bhadouria - are there any plans to include a custom connector for a source, along with a field-mapping facility to map index fields? \n\nWe are currently speaking with Jaguar Landrover who have a bespoke knowledge base, but it does have an API that can be used to retrieve content. \n\nI'm aware that we have the Ingest API that can take structured data/content, but this means an intermediary application would have to be built between Search and their bestpoke app.  https://searchassist.kore.ai/searchassistapi/public/api-docs/#/Public%20Apis/post_searchassistapi_external_stream__streamId__ingest\n\n @Serkan Ibrahim  @Hannah Gore",
        "@Laurence Schoultz do we know the API structure? Will it be a pull or push? Will it share only the changes from next refresh or complete content? How do we know when to refresh? Will it be a scheduled job? Is the response payload a json?",
        "The API endpoint requires a request (pull). Content delivered in JSON format. \n\nWe've only had high-level discussions up until this point. Critical to understand is whether we can support such a setup without having to build an intermediary application.",
        "If I build a capability where you give REST endpoint support with JSON as expect output and a screen where you can provide mapping(may be that too in json format to start) and option to configure sync schedule. Will that be good?",
        "Will this be OnPremise or Our cloud?",
        "This sounds like a great start and would be generically applicable. We ought to poll the wider audience here first to make sure this is appropriate. I've seen a few others asking for something similar.",
        "our cloud - SaaS",
        "This would surely help @Girish Ahankari as we can tell customers that for all non OOTB connectors, here is a way to pull data. There maybe few exceptions as always but can help greatly to start with.",
        "Following",
        "@Girish Ahankari another customer, Sage Accounting, are using Upland RightAnswers (https://uplandsoftware.com/rightanswers/) they will need this custom connector too. Unless we're planning to build a connector to RightAnswers. \n\n @Marenza Douglas FYI - SAGE",
        "Following too",
        "@Girish Ahankari can you advise on latest status here. \n\n @Marenza Douglas  @Serkan Ibrahim  @Hannah Gore - bumping this thread as it is applicable to the SAGE and JLR opportunities.",
        "@Laurence Schoultz we will work on this and try to release it by end of July.",
        "Thanks @Girish Ahankari",
        "@Girish Ahankari can we have an update on this, did we release in July?",
        "@Marenza Douglas @David Schreffler FYI - SAGE"
    ],
    "spaces/AAAABcXBTWI/threads/3VcByUVUOl0": [
        "Also I did not understood the  second question, can you please elaborate? what is SPN?\n\n\"Will the connector application from Kore.ai creates an SPN in our tenant instead of registering our own application?\"",
        "@Chiti Musonda"
    ],
    "spaces/AAAABcXBTWI/threads/SuYvWi8uqZ4": [
        "Yes, it has been done. We have it running and it is part of kitchen sink example bots.",
        "Would be able to share the instance with me?",
        "@Trevor Vaughn Hauck can help Kevin to use the bot you created with AWS bedrock.",
        "@Kevin Mullay, I added you and invited you to the Bot that integrates with the AWS Bedrock. I also gave you access to see our private kitchen sink repo: https://github.com/Kore-ai-SE-Tools/kore-app-examples/tree/main/kore-custom-llm\n\nIn the part 2, I specifically go over the bedrock integration.",
        "https://www.loom.com/share/cd03f96671f44dc7a05a5b11655d0043?sid=c85b5e72-e9f0-4fb4-acbf-cc1e4b2fcfe4",
        "@Trevor Vaughn Hauck Can you invite and add me as well?",
        "@Andy Pham added!",
        "This repo has gone private. Who can add SEs to it? @Curtis Swartzentruber",
        "@Umang Shah, I didn't have to sign in to access it.",
        "@Trevor Vaughn Hauck Can you share part 2 of the video?",
        "Strange",
        "https://www.loom.com/tag/kitchensink",
        "quick FYI, we have a private internal repo that will have some things we won't share publicly. Bedrock is one of these since technically they are GALE competition. to get to these code samples, you'll need to be added to our SE organization and given access"
    ],
    "spaces/AAAABcXBTWI/threads/hBED8t7p0_s": [
        "Hi team,\nA prospective customer is considering an environment where they publish the XOP V10 Bot on a Teams channel, allowing this Bot to call the SearchAssist API to search for content.\nThe assumed content sources include:\nKnowledge AI (XOP)\nSpecific SharePoint sites (SearchAssist)\nWeb Crawling (SearchAssist)\nEnd users will interact with the Bot within the Teams channel. Among these end users are Leadership members, and they want to ensure that specific SharePoint sites are only searched when Leadership members perform a search. When other members access the Bot, these SharePoint sites should not be included in the search.\n\nIs it possible to achieve this behavior?",
        "@Mounika vemula can you please discuss the meta-filter's approach feasibility internally and suggest the recommended approach?\n\n @Mani Kumar Nadella,  @Aditi Bhadouria",
        "@Ichiro Fukuyama \n\nThis feature is currently not available OOTB. But we can achieve it via some additional effort and configuration (Involves using workbench and business rules) Team will get back to you on the same. \n\nThe OOTB feature is currently in the roadmap. RACL for Sharepoint is targeted for Aug-Sep 2024. \n\nRACL stands for Role-Based Access Control List which refers to the method of controlling access to specific resources or information based on the roles of individual users within the organization. Through RACL, the enterprise search application can ensure that users only see search results and access documents or information relevant to their roles within the organization. This helps maintain data security, confidentiality, and compliance with organizational policies and regulations.",
        "Hi @Aditi Bhadouria , \nThank you for the good news!\nThis prospect will implement a workflow where Teams -> XOP (Dialog Task) -> (REST API) SearchAssist.\nIs the RACL for SharePoint feature capable of controlling access based on Teams users or roles?",
        "@Ichiro Fukuyama \n\nIf the request is going to come via the bot, then I suggest exploring hte following alternate:\n\n1. The user needs to be authenticated via the bot and determine whether it is a management user or a regular user\n2. This logic needs to be implemented within the bot definition\n3. Whenever you are calling SearchAssist API from the bot (as part of fallback or any other scenario), use the Advanced Search API (https://docs.kore.ai/searchassist/public-apis/searchassist-apis-list/#Advanced_Search_API)\n4. This API allows meta filters to get content only from specific sources\n5. So, you could have 2 separate Service Nodes - one for management users and another for regular users\n6. Each of the service nodes should send the right payload to fitler the required content \n\n @Aditi Bhadouria  @Surendra Subhash Salke",
        "@Santhosh Kumar Myadam Since they will have multiple sharepoint sites, some accessible only to leadership, what is the way to identify certain sites to add to the meta filters in the Advanced Search API?\n\nAlso, can the single sharepoint connector access multiple sites on the same sharepoint server?"
    ],
    "spaces/AAAABcXBTWI/threads/lrAwv04UAoM": [
        "Hi team, \nI'm working with a customer who has questions on Search AI data ingestions fees. Can you help to provide clarity on these questions:\nWhat scenarios is this ingestion applicable to ?\nIf a website is crawled, how does it work with all pages being read?\nIf website has attachments on there, ¬†what happens?\nWhat happens if a minor change happens on a document that was already scanned before?¬† Does kore charge again?\nTake case of Data Custodian ‚Äì REI ‚Äì if they have 500,000 documents, to scan, how would this scale?\nHow often does rescanning happen for doc changes?¬†¬†¬†\nHow about multiple versions of same document?",
        "@Melissa Prince I think these questions are also posted in CBRE group. I have responded in that group.",
        "Yes, thank you Santhosh.",
        "@Santhosh Kumar Myadam Can you post your response here as I am not part of the CBRE group?  I have the same questions.  Thank you",
        "Otsuka has questions about SearchAssist costs and Document requirements gathering.¬†  @Santhosh Kumar Myadam  If you can respond here to the same questions Melissa Prince had asked for CBRE, I would appreciate it.¬†¬†¬†\n\nAdditional questions:\nDo we have guidelines or best practices for filling out the requirement gathering template? What is the expected level of detail needed from Otsuka?¬† Meaning during the implementation, does the client need to list every document location/url/file type, etc.¬† What is the best way to capture the list of documents that need to be ingested without manually listing them?\nWhat are our recommendations for handling and ingesting images, videos, and/or audio files that are from the internal website without manually listing them and associating them to the webpage?\nRelated to questions 1 and 2, Each webpage has a number of links, pics & docs (of various sizes and formats) housed within each page - how are we expected to account for these details, into the requirement gathering template?¬†\nWhat is the tolerance/threshold (in terms of # of docs) that can be ingested for the first time and / or when there are updates/changes?",
        "@Gah Bird  Here is the response we received for CBRE.  Still waiting for updates on #2, #3, and #5.  SSO and OCR were included but figure I would share, as someone may have similiar questions.\n\n#1 - SSO: As Aditi mentioned it need not be a blocker as we already supported crawling authenticated pages. Based on the current priorities, we can take up this in Q3 2024 (Oct - Dec). Please raise enhancement request for this. \n\n#2 - OCR: We are implementing a new functionality to support layout aware chunking that supports OCR. Will discuss internally about whether this meets CBRE requirement and will share an update in a day or two\n\n#3 - Website attachments - Will share update soon\n\n#4 - Do we charge again for minor changes - Yes, it will be considered as an update as we have to go through the full extraction pipeline to extract the content. There is no way to know if it is minor or not before the extraction is done. \n\n#5 - Scaling for 500,000 documents - Will share update soon\n\n#6 - How often does rescan happen - This is a configuration in the application and the customer can choose as they need.   \n\n#7 - Multiple versions of the same document - if the same document is updated with latest content, then we replace the previous content with the new one as part of the rescan. However, if the new version is provided as new document then the system will maintain them as 2 separate documents as there is no information available to compare",
        "Thank you very much, @Melissa Prince!  I really appreciate it.",
        "Follow-up question @Santhosh Kumar Myadam With regards to #4, \n\nAre we able to track ingestion of updates?  \nSecondly, are you saying we need to charge again for every update?  \nCan you provide an estimate based upon other clients what percent of documents are being updated?  The client needs to budget for this.",
        "Hello Search AI + XO Answers Can someone please respond to my questions and @Melissa Prince questions.  Client is waiting for guidance to make their decision and budgetary planning for SearchAI.  Thank you.",
        "Team - As Gah stated, do we have the ability to track every time there is document ingestion, how many new docs were ingested, and how many existing docs that had updates were ingested? Where would we get this info?  Analytics? Some backend process?\n\n@Richard Passavant - is this sufficient to determine what we would charge the client?",
        "Reposting from another group for visibility \n\n@Melissa Prince \n\n#2 - The upcoming functionality will have OCR capability for PDF documents to extract content from tables and charts. The initial results are encouraging and we are confident of its capabilities. The coverage can vary based on the complexity of the documents. To get better assessment, we may need a few documents from the customer to validate and confirm. Do note that this is an upcoming feature and ETA is Sep 2024. \n\n#3 - We do not have support for automatically indexing the attachments on webpages\n\n#5 - In general, the platform should be able to scale large volumes of data. However, it also depends on the type of documents, number of pages in each of these documents etc. We also need to consider this in to the pricing/licensing.",
        "@Santhosh Kumar Myadam - following up on #2.  Is OCR functionality still tracking for September?",
        "@Santhosh Kumar Myadam @Aditi Bhadouria, The customer is ready to move forward, and I need to meet with them to finalize the requirements and complete the discovery document for ProServ. In preparation for the meeting, could you please let me know the status of the SSO requirement? Also, please confirm that OCR is ETA for September. Thank you! cc: @Melissa Prince",
        "@Andy Pham @Melissa Prince OCR, image and table support is available in XO 11. Can we ask the customer to use that instead?\n\nFor the SSO-based authorization for web crawl, we are aiming for October.",
        "I understand we can support up to 15MB size of document on cloud deployments, do number of pages still matter as long as the doc size is under 15MB?"
    ],
    "spaces/AAAABcXBTWI/threads/2uYUmMj67yA": [
        "For clarification, do we have a delivery date for integration with Confluence Cloud along with Confluence Server?",
        "I also have a prospect (with Retail) for Commerce Cloud on Salesforce",
        "@Bharat Rekha @Aditi Bhadouria for ETA",
        "@John Nicholson @Tim Burke the following connectors will be available earliest by end of June, and latest by July. \n\nConfluence Cloud \nSharepoint \nAzure Storage \nSalesforce\nOracle Knowledge",
        "Do we have Oracle Knowledge connector available now @Aditi Bhadouria ?",
        "Yes Oracle Knowledge connector is available now"
    ],
    "spaces/AAAABcXBTWI/threads/cNnToA46cP0": [
        "Do we have a document detailing how data on Sharepoint is sent to our platform for ingestion, specifically how we secure the data?",
        "Do you mean how data is secured in-transit?"
    ],
    "spaces/AAAABcXBTWI/threads/7ik1Z8-olMM": [
        "In v11, where can I add the parameter: dev_Enable_Query_Rewrite_Type ?",
        "Custom configs are not yet externalized in V11. Dev in progress.\n\n@Aditi Bhadouria @Bharat Rekha",
        "What are the current default value of those parameters?",
        "@Sunny Lun In XO 11, query rewrite has to be handled at the Platform level, as they are managing the entire end-user orchestration. Platform already has a query rephrasing feature available. We are working on making it available for the answer generation feature as well. I'll share an update with an ETA soon. \n\nDue to this while Custom configs will be available soon in XO 11, Query Rewrite will not be available under it.",
        "Actually, I would like to create the contextual questions by looking the past 2 or 5 questions similarly to either \"query\" or \"conversation\" . Is it something  that rephrase response can help ? @Aditi Bhadouria",
        "Please refer to this for understanding how Query rephrasing works in XO 11\nhttps://docs.kore.ai/xo/generative-ai-tools/dynamic-conversations-features/#rephrase-user-query",
        "Thank you..sounds I need to wait for the availability of the custom config .. as stated, what is the ETA?"
    ],
    "spaces/AAAABcXBTWI/threads/7pK5jiMB_yU": [
        "Am I correct in that we do not currently support OpenAI GPT 4o yet in any capacity? I only see GPT-4 32k.",
        "Some of our fellow SE's have created custom connections to GPT-4o and are using it in demonstrations.",
        "Todd - in SearchAI using custom connector? I tried to get it to work on the original \"AgentAssist\". but wasn't able to enable it. Any ideas?  haven't tried with SearchAI in XO11 yet.",
        "straight API calls in Service Nodes direct to the endpoints",
        "more for Dialog Tasks, probably not for Search AI",
        "I made a New Prompt, selected GPT 4, in the request I changed it to GPT-4o and it showed the response.\n\nIt could be a path to what you are looking for..."
    ],
    "spaces/AAAABcXBTWI/threads/yiIBhS5lDDY": [
        "We currently have a prospect using MS Azure AI who is looking for a new AI solution. They have the following questions: 1. PDF documents when converted to text may not preserve the structure of the text in a fashion that is desirable for creating vector embeddings? How is that handled? 2. Generative and extractive models will skip over images for extraction. Question to SearchAssist team: If the image is associated with extracted content, will it be presented with the text? Does image presentation only work for FAQ queries? 3. When the web crawler scrapes the content from the web ‚Äì some of the content may be very raw ‚Äì is there a way to structure and beautify that text? 4. - Does web Crawler scrape and store images from the site crawled ?   **I will join the SearchAI office hours looking for answers to this set of questions.",
        "@Michelle Winston \n\nPlease share the questions via an email to the following\n\n @Aditi Bhadouria \n @Surendra Subhash Salke \n @Bharat Rekha \nsanthosh.myadam@kore.com\n\nMakes it easy to track and respond.",
        "Thanks. I did receive answers to my questions during this morning's Office Hours. I will summarize what I heard and email the group  above. If there are corrections, I will incorporate them and then re-post to this space for future inquiries."
    ],
    "spaces/AAAABcXBTWI/threads/L5y0M2gdivk": [
        "In v11, What is the file size that can be uploaded to a Document?\nWhen I tested it, I could only upload up to 3MB.\nHowever, I know that in v10 I can upload up to 15MB.",
        "During onboarding and set up guide the limit is 5 MB. If you go to the Search AI module the limit is 15 MB"
    ],
    "spaces/AAAABcXBTWI/threads/ajw1yvavmfQ": [
        "Team,  do we have a way to redact PII data  from the documents uploaded to SearchAssist these docs data will also be used to generate answers from Azure OpenAI also?"
    ],
    "spaces/AAAABcXBTWI/threads/roO9CcE8tQg": [
        "We do not redact PII data from documents OOTB. But you can add a workbench stage with a hook to a service which does that or even write a ‚Äúpainless‚Äù script within workbench."
    ],
    "spaces/AAAABcXBTWI/threads/jExgB2Du_UQ": [
        "For queries coming from XO, there is a redaction of PII data"
    ],
    "spaces/AAAABcXBTWI/threads/zgjR4C7EWU4": [
        "Girish, Thank you"
    ],
    "spaces/AAAABcXBTWI/threads/Ohs7BHrYBlU": [
        "Is there any audit log /report that shows who upload / delete the documents from the Source > Directory tab?",
        "This is currently available in SearchAssist under Manage>Change logs.",
        "@Aditi Bhadouria .. how about v11?",
        "V11 currently does not have this capability for Search AI. It is in the roadmap"
    ],
    "spaces/AAAABcXBTWI/threads/mhMDo8GRhf0": [
        "I found we have the \"Train API\" (https://docs.kore.ai/searchassist/public-apis/searchassist-apis-list/#Train_API) .. is there any API to track the Training status?",
        "Yes there is a jobs API, that can tell you the training status. Please check out the API list in documentation/ Swagger",
        "@Aditi Bhadouria .. i have lookup the online API doc for SearchAssist (https://docs.kore.ai/searchassist/public-apis/searchassist-apis-list/) but still cannot find the jobs API.",
        "https://searchassist.kore.ai/searchassistapi/public/api-docs/#/Public%20Apis/get_searchassistapi_external_stream__streamId__jobs",
        "You can find the API reference here"
    ],
    "spaces/AAAABcXBTWI/threads/m6Q9TkF6rwg": [
        "I may overlook something but I can't find those report/dashboard for SearchAI in v11. Is any pointer to locate those SearchAI specific analytics report/dashboad?",
        "@Sunny Lun it is not currently available we plan on making it available soon"
    ],
    "spaces/AAAABcXBTWI/threads/EUGyKdkjynk": [
        "@Aditi Bhadouria - one of the AA demo requires limiting the searchAI output to only answers and exclude the webpages. How do we configure this inside of Search App ? Any documentation link or internal loom video showing the same will do.",
        "You can edit the Result Templates and remove the values as needed.\n\n @Shruti Kukkar can you include this in the result templates documentation?",
        "Any doc on how to edit the results template ?",
        "https://docs.kore.ai/searchassist/design-search-experience/result-templates-2/"
    ],
    "spaces/AAAABcXBTWI/threads/3vqbcONwrng": [
        "Hi Guys, on \"https://searchassist.kore.ai\" environment we see training is \"in queue\" but never takes place. Any hints to solve it?",
        "Hi Axel Brauns, how long it is in progress?",
        "30 minutes and more",
        "It looks it is working againüòÄ",
        "üëç"
    ],
    "spaces/AAAABcXBTWI/threads/PIf9inJg0IU": [
        "A prospect asks:  AgentAI / SearchAI - \"How is the feedback provided by the user, used to further refine the answers for future responses? How does RLHF applies to this scenario?\"  - My question to you is:  What is OOB and how much of the RLHF is a PS effort?   I know I can use the Alaska airlines example for our call on Friday, but wonder what we have done to add this feature to AgentAI / SearchAI, because I know they will ask.   Thanks!",
        "*Subscribed* üëÄ",
        "If SearchAI is being used as part of AA, we provide option of collecting feedback and provide customisable reasons (along with comment) for negative feedback. All this data gets stored in the AA dashboard as of right now. The refining part would happen at SearchAI end so @Aditi Bhadouria can comment on it. If SearchAI needs this feedback data, we build a pipeline to transmit it back to SearchAI",
        "@Aditi Bhadouria could you let us know please? We have a call tomorrow.  Thx",
        "We have answers insights available under Search AI. That gives information about the queries asked debug information, feedback etc. This can be used to further understand and fine tune the answers that got negative feedback.",
        "We have a Feedback API available that can be used to propagate the feedback information back to Search AI",
        "Currently this has to be a manual process. We don‚Äôt have an automated way of extracting insights and updating configurations from the analytics.",
        "Alaska Airlines example/ Caching can be an automated way of doing it. But we aren‚Äôt doing complete fine tuning here., the configurations stay the same",
        "Okay, so still a manual process (PS efforts) to setup a separate curated \"cached answers index\" that is used as \"verified\" answers to agents.  And there is a team of SME's who validate answers before putting them into the cached answers index.   \nHow do the SME's get their initial list of potential queries?  Are they reviewing queries made by agents that had \"no answer\" or a thumbs down?",
        "+1.. Another customer asked for the same capability and mentioned a few of the CMS vendors they met with, have a feedback pipeline where the end users feedbacks along with their comments are automatically passed on to a dedicated team for further actions.",
        "@Tim Burke @Aditi Bhadouria ^^",
        "@Navdeep Grover that feedback loop into another CMS can be built via Professional services.  Its just not a feature of the platform.  IE: Someone gives feedback, which can be custom coded to call an API to send the data to.",
        "Thanks Tim!!"
    ],
    "spaces/AAAABcXBTWI/threads/MLqivNmB3uA": [
        "Greetings Team,\n\nWill Role-based Access Control be available for SearchAssist, i.e. XO 10?",
        "Hi Jon \n\nYes, RACL will be available in Search AI standalone and XO 11 both. The dates might defer by a month or so.",
        "Also, correction this is Search AI standalone V2.0.3 (currently). V10 refers to the Platform version that does not include Search AI OOB"
    ],
    "spaces/AAAABcXBTWI/threads/uui3vsJTACM": [
        "It is for v10.. I have enabled the Generative Model (not Extractive Model). When I click the Chunks, it still asks me to enable the Generative model or Extractive model.",
        "Please ensure to train the application after enabling Generative/Extractive model to extract the chunks",
        "Also, correction this is Search AI standalone V2.0.3 (currently). V10 refers to the Platform version that does not include Search AI OOB",
        "i think this bot is corrupted.. When i created a new one, it works now"
    ],
    "spaces/AAAABcXBTWI/threads/HxL13ARYAog": [
        "Hi team,\nKintone is a SaaS groupware with over 32,800 user companies in Japan. One of our customers wants to use Kintone as a source for SearchAssist.\nKintone provides a REST API that allows you to retrieve multiple records as an array using parameters like those listed below. Is it possible to implement a Kintone connector on SearchAssist?\n\nhttps://cybozu.dev/ja/kintone/docs/rest-api/records/get-records/ (Sorry, it's Japanese)\nRequest Parameters:\nappId: The application ID of the product\nfields: The field codes to include in the response\nquery: The query string specifying the conditions of the records to include in the response\ntotalCount: A boolean indicating whether to retrieve the total count of records in the response\nResponse:\nrecords: An array of records\ntotalCount: The total count of records",
        "It sounds like the customer connector we need for Sage and JLR could also be applicable in this situation @Girish Ahankari ?",
        "@Laurence Schoultz We are working in the design for custom connector. \n\nWill share updates in the next few days. \n\n@Aditi Bhadouria",
        "@Santhosh Kumar Myadam @Aditi Bhadouria \nThat's excellent information! I'm looking forward to the next update."
    ],
    "spaces/AAAABcXBTWI/threads/pFAQOVfZNDE": [
        "XO & SearchAI  LLM Config question:   Why does the \"Prompt Library\" show many pages (in this example, 7) of the same configs, over and over again?   It shows 10 at a time per page.  I have 11 green active and the other pages are all InActive.   The other pages are all duplicates showing various model options that are inactive.  Why not stop at the 11 active?  Its not as if I can have two models active for Zero Shot ML Model (for example).  \nI've wondered this for some time now.   Its confusing to look at.",
        "for every provider,  you need a prompt for each feature you want to enable",
        "So for example, Setting up which model you want to use for Zero Shot ML Model...  I can just click the edit and choose from the drop down.  Why do I need 7 pages of \"Zero Shot ML Model\" showing as inactive?  Seems redundant.  Of course I don't have all of the others enabled.  And it shows me on page 1 which model is active.    I just don't understand the logic in the UX.",
        "probably why they changed it in XO 11. I agree, it's not intuitive.",
        "That interface is XO11 - unchanged from XO 10.",
        "i must've been thinking of a different interface. i think your recommendation would be to only show active, at least in the \"default\" view?",
        "yes, not 7 pages of inactive.  \nHow do I explain that to a customer when doing a demo?",
        "‚ÄúThose are inactive‚Äù üòú",
        "@Deeksha singh @Hariharan Velusamy"
    ],
    "spaces/AAAABcXBTWI/threads/sD5IrWDCA9Q": [
        "Hi team,\nOur customer is considering purchasing SearchAssist, but they said that the product does not support xlsx files, which does not fit their use case. Is there a plan to support xlsx files in the SearchAssist roadmap?\n\nhttps://docs.kore.ai/searchassist/manage-content-sources/managing-data-from-files/\nhttps://docs.kore.ai/searchassist/concepts/personalizing-results/answer-snippets-support-across-content-sources/#"
    ],
    "spaces/AAAABcXBTWI/threads/PLhXb0mmCfI": [
        "We have custom utility to ingest. However I can only confirm after seeing their data. Is it possible to get the sample files?",
        "@Sathya Priya Turaga, thank you for your message. \nThis is one of the sample files provided to us by the customer. It is written in Japanese. \n\nThe file contains several matrices, including a calendar-like matrix and a pricing matrix for their services. While we will gather more detailed use cases from the customer, we assume that they want to search for service charges over specific periods within these matrices. \n\nCan such files be included in the search targets?"
    ],
    "spaces/AAAABcXBTWI/threads/rGTmBoXfgSQ": [
        "Only simple tables with basic rows and columns are supported. Complex or merged table structures will not function correctly. And considering japanese language, it would be difficult for us to check the feasibility."
    ],
    "spaces/AAAABcXBTWI/threads/zHYXmKPNX-o": [
        "Hi @Sathya Priya Turaga , thank you for the explanation. I understand the Ingest tool. We can discuss simple use cases with the customer. Is there a plan in our roadmap to provide the Ingest tool for Japanese xlsx files?"
    ],
    "spaces/AAAABcXBTWI/threads/5IrCpQuT8Xg": [
        "Is there any API or way that I can get the matched chunks programmatically when a question is asked in the bot?",
        "https://docs.kore.ai/searchassist/public-apis/searchassist-apis-list/#Advanced_Search_API",
        "@Aditi Bhadouria .. thank you for your response. May I confirm it applies to GenerativeAI Model ?",
        "Please use the \"answerSearch\" and \"includeChunksInResponse\" parameters to receive the relevant chunks",
        "yes"
    ],
    "spaces/AAAABcXBTWI/threads/8RgCWZrd4K0": [
        "We can provide the external tool for ingesting purposes, and it works well with simple rows and columns of any language that we support. However, it's important that we collaborate with the client to validate the japanese results using sample data before making any final commitments. If you are looking for internal support, we are adding spreadsheet answering as a extraction strategy as part of UXO in the coming months."
    ],
    "spaces/AAAABcXBTWI/threads/Ya7_1QV7SOo": [
        "Hi. Im trying to crawl a website but getting above SSL related error. Is it because the website doesn't allow non-ssl requests, and from our cloud we have ssl disabled for all external calls? Can we enable it from our end? Or any other way to crawl this?",
        "Hi @Nibhrit Vij, \n\nCan you please share the web page url that you are crawling?\n\nCC:  @Riyaz Ahmed",
        "@Bharat Rekha @Riyaz Ahmed -- https://apparelglobal.com/en/",
        "@Nibhrit Vij This is due to crawler is using tls v1 to make calls, while the webpage requires tls v3. \nPlease raise a PLAT ticket for this.",
        "@Riyaz Ahmed would I raise it as a bug or fr or something else ?",
        "Please create plat ticket for this",
        "@Riyaz Ahmed @Bharat Rekha https://koreteam.atlassian.net/browse/PLAT-30915\nI have raised a ticket, didnt know who to assign to so currently marked it to Riyaz. Please re-assign to the relevant team, thanks!",
        "@Bharat Rekha @Nibhrit Vij Is this issue fixed? I am getting an SSL Error using v11. https://www.taxhawk.com/answers-search",
        "Hi @Andy Pham, We have provided the work around to support other TLS versions. While we are working on supporting the TLSv3 version.",
        "what is the workaround? @Bharat Rekha",
        "The workaround is to enable tlsv2 / tlsv1",
        "Are you suggesting the customer enable tls1.1 or 1.2? @Bharat Rekha",
        "Yes currently tlsv3 is not supported. We are working on this.",
        "What is the ETA to support v1.3?",
        "I can get back to you on this early next week. Can you please create one PLAT for the tlsv3 support for crawler?"
    ],
    "spaces/AAAABcXBTWI/threads/G69igoMRSwc": [
        "Can I configure Kore.ai XO GPT Module as Custom Integration on SearchAssist? If YES, what is the configuration?"
    ],
    "spaces/AAAABcXBTWI/threads/oD5kw26Yiyk": [
        "I am getting this error. Please let me know what you think, as I need to ensure there is nothing wrong with this week‚Äôs demos. Even with a new App on the v11 platform, I am getting the same error.",
        "I also am seeing this today.  XO 11 Platform upon login or landing on this page.",
        "Same ..got this error but sounds there is no impact to other functionalities",
        "@Andy Pham @Tim Burke \n\nThis is a defect and it is being looked into. It does not impact any other functionality."
    ],
    "spaces/AAAABcXBTWI/threads/z0O35OBiKPE": [
        "@Aditi Bhadouria As relates to industry insights in the 'Search/RAG' space, we discussed a few weeks back on the SearchAI office hours call about differing approaches to RAG. Has the team been researching the different approaches like GraphRAG. Microsoft have released this: https://www.microsoft.com/en-us/research/project/graphrag/ \n\nSearch apps based on RAG are proving to be very popular - I suspect we'll start to encounter more detailed questions about the different disciplines and what's in our roadmap. \n\nAny insights/comments?",
        "Thanks for bringing this up @Laurence Schoultz. I'll discuss with the team and get back to you about our approach towards this and the roadmap plan.",
        "@Aditi Bhadouria any further updates on this?"
    ],
    "spaces/AAAABcXBTWI/threads/honhm4HPWos": [
        "Team - 2 questions:\n\n1) Can we define which prompt to run from the search API's?\n\n2) How can I refer to custom tags inside the prompt? \n\nSo if my payload is below, is my reference \"userContext.user_designation\" ?\n{\n  \"query\": \"what is medicare\",\n  \"customData\": {\n    \"userContext\": {\n      \"user_designation\": \"individual\"\n    }\n  }\n}",
        "For point 1), do we have any suggestions?",
        "1) Currently this is not possible. Whichever prompt is selected under Answer Snippets will be used for answering. \n\n2) I need to check and get back to you on this. Please give me some time",
        "Followup to this, I need to show my client (FloridaBlue) the ability for the agent to run a search query on our agent desktop with the bot already understanding the context of the user. So instead of the agent typing \"how do I update a billing address for off marketplace members\", the agent just needs to type \"how do I update a billing address\" and the bot should already know the context of the user (that this user is an off marketplace member). How do I solve for this?"
    ],
    "spaces/AAAABcXBTWI/threads/p0iQ20W_K7o": [
        "We are still using SearchAssist v2.0.4 in Japan. An inquiry from an end customer asks if there is a limit on the number of FAQs that can be uploaded. The customer is on the enterprise plan.",
        "For enterprise we have soft limits applied for all sources. But this can be increased as per the requirement"
    ],
    "spaces/AAAABcXBTWI/threads/qvH19lsQtLY": [
        "Hi Team, this is my first time trying to customize the pipeline. Whatever I try, I get this message:",
        "@Vaishali Addala can you please take a look at this?",
        "@Michael Piotrowski -could you please help me with additional information??\n\n1. In which instance you are referring to this issue?\n2. If possible could you please share that app with me \n\nIt helps me to understand the issue more ‚Ä¶ and provide you the quick solution"
    ],
    "spaces/AAAABcXBTWI/threads/wUqugwjwMQo": [
        "This includes setting up the example shown in the help video, or resaving an existing stage. It also includes a trying to do this on an customer's working search assist instance, or in a newly created instance. I am trying this on an XO-10, Any help or insights would be greatly appreciated."
    ],
    "spaces/AAAABcXBTWI/threads/_pn--ZaOa6M": [
        "In Chunk Browser in v11, Can't browse by only Korean. For example, ‚ÄúÏã¨Ìîå ÏöîÍ∏àÏ†ú‚Äù\nBut I can browse by a combination of English and Korean. For example, ‚Äú5G Ïã¨Ìîå ÏöîÍ∏àÏ†ú‚Äù\nAre these issues uploaded in JIRA?",
        "@Inseon Park could you please create a support ticket for this?",
        "@Aditi Bhadouria I have raised ticket #45410. Please refer to Ticket for additional information."
    ],
    "spaces/AAAABcXBTWI/threads/gJiWF7ol8Mo": [
        "Any idea how to get a custom integration to work in SearchAssist?",
        "@Gurpreet Singh Please refer to this github and documentation link for more details around custom integration and how to set it up. If you are facing any issues we can discuss further. \n\nhttps://docs.kore.ai/searchassist/administration/custom-integration/\n\nhttps://github.com/Koredotcom/SearchAssist-Toolkit/tree/master/Answering",
        "You need to use an intermediate utility/Service to perform the orchestration between the LLM and SearchAssist. You won't be able to provide the Open AI endpoint and use it directly.",
        "Hi @Gurpreet Singh , I followed the instructions as outlined on https://github.com/Koredotcom/SearchAssist-Toolkit/tree/master/Answering and able to successfully connect to Azureai with gpt-4o using custom integration.\nPlease let me know if you need any details and I'll be able to help"
    ],
    "spaces/AAAABcXBTWI/threads/lc38EMP0mCA": [
        "Do we have any experience integrating w/ LMS Bridge?\nhttps://www.getbridge.com/cpc-lms/?utm_source=google&utm_medium=cpc&utm_campaign=bridge-2024-q2-brand-learning-technologies=&utm_term=bridge-lms&gad_source=1&gclid=CjwKCAjwnK60BhA9EiwAmpHZw4pdKNgDkpXe7a2UIldkFS8ut079gzBC1xpJlEN8Xd113pUgv-PqRBoCYJUQAvD_BwE",
        "I'm aware of it as a product, lol",
        "What's the question?",
        "Curious whether we have a customer using Bridge",
        "In general?  Or as a source of Search answers?",
        "You might try the All GTM group too"
    ],
    "spaces/AAAABcXBTWI/threads/fLxMUpITh-o": [
        "Hi team, my customer has encountered the following issue while training the application. can anyone explain how to resolve this issue?",
        "@Pulkit Gupta @Akhil Sainath Maddala",
        "Hi @Su Hyeok Seong, We are actively working on this issue, we will update you once the issue is resolved.",
        "Hi @Bharat Rekha , Thank you for letting me know. A similar issue found in another App",
        "These issues are resolved now. Please let me know if see any issues. \n\n@Harini Bandaru",
        "Hi @Bharat Rekha, i can still observe this issue on Jp instance. I've tried training FAQs and was able to replicate issue (failed time 7/10 6:32 PM JST)",
        "@Mani Kumar Nadella - please verify this",
        "I have raised a ticket (PLAT-30580)",
        "Hi @Bharat Rekha , @Mani Kumar Nadella do we have update on this ? It's been a while since the issue is reported and the client complaining that the issue is still ongoing",
        "Hi @Su Hyeok Seong, we are working on the fix for this. We will expedite the patch fix for this. \n\n@Harini Bandaru",
        "Also, can you please check if the latest training is successful state.",
        "Hi @Bharat Rekha , I can still replicate this issue",
        "The issue has been resolved. Could you please check it now?",
        "@Su Hyeok Seong",
        "@Harini Bandaru I would say this is partially fixed, as I can see some applications can be trained and failed. It is really unstable that even with the same application, Training fails and succeeds randomly. Does capacity of JP instance cause the issue ?",
        "@Su Hyeok Seong  Can you please share the workspace name and application name?",
        "@Harini Bandaru  this is not an application specific issue. If i train multiple applications from different workspace at once, all of them will fail. However, If i just train an application, it will succeed. Hence i was thinking that the capacity of JP server has limit on concurrent training",
        "Hi @Su Hyeok Seong, \n\nWe have received the training failure alerts. We are working on a fix for this.",
        "We have noticed that snippet extraction stage is causing the issue. Please disable this stage if enabled.",
        "Sure, thank you",
        "@Su Hyeok Seong To successfully train the application for now, you can disable the snippet extraction stage in Workbench if you are not using extractive answers. This is a temporary workaround.",
        "@Harini Bandaru Thank you for the explanation. Snippet extraction stage is only affecting extractive answers? because i've seen that snippet extraction is a stage where index values are inputted into fields. Would search Assist work without this stage enabled?",
        "Yes, that will work. We'll use generative chunks for generative answers and extractive chunks only for extractive answers. If you're not using extractive answers, you can simply disable that stage in Workbench and proceed with training the application.",
        "Sure it's clear now. I will guide clients to disable snippet extraction. Thank you so much"
    ],
    "spaces/AAAABcXBTWI/threads/qSWQHx9LDG4": [
        "A large luxury retailer is asking if we can do chat in their Search Bar in addition to GenAI powered Search.  Seems a bit odd but their POV is that customers are already trained to go right to the search bar so why not move chat to the search bar as well.  Is this possible?",
        "@Girish Ahankari @Surendra Subhash Salke"
    ],
    "spaces/AAAABcXBTWI/threads/aRz4wH6BN8o": [
        "Yes, it‚Äôs possible. I will check if we have a demo application ready and share. We had done a demo for a prospect earlier using search bar"
    ],
    "spaces/AAAABcXBTWI/threads/BaC9_pHKons": [
        "John Brandes, Tim has developed a dual play with search bar to show case a demo. This is getting popular in the retail space to include Gen AI search for use cases like recommend a gift for someone..",
        "Thanks, Gopi.  I have the Dual Play stuff.  This is Chat in Search Bar.",
        "Please talk to Tim, we have a demo setup that we did for Belcorp.."
    ],
    "spaces/AAAABcXBTWI/threads/k52KkMtZyNY": [
        "@Girish Ahankari Bumping this up as we have other customers asking.  FYI @Corey Erkes .  Or, can it be configured as a Custom Integration?",
        "@Girish Ahankari - this is an urgent need for Frontier as they assumed it was available and have work planned in their current sprint. FYI @Shantanu Ghorai",
        "@Corey Erkes we never announced the release of XO GPT answers, then where was this communication gap?",
        "We will prioritise it. We are benchmarking the quality of answers against ChatGPT",
        "@Girish Ahankari - during onsite with Frontier yesterday they requested to pivot from using commercial model to XO GPT due to data sharing concerns raised by new AI leader. Appreciate the prioritization.",
        "@Girish Ahankari - this documentation led to some of the confusion with the customer yesterday.",
        "That‚Äôs in XO 11",
        "FYI - This is actually in the standalone SearchAssist documentation."
    ],
    "spaces/AAAABcXBTWI/threads/mjrm4kYLx4g": [
        "Thanks @Girish Ahankari  Please let me know",
        "Hi @Venkat Pavan Kumar Ichapurapu \n\nCan you please check and share the demo application. Lets review it before sharing. \n\nHi   @John Brandes,  We have sample app, this requires to be updated with latest features. We will update these features and share it with you.  Can you please create PLAT ticket and request team to route to us directly. \n\nCC:  @Ravinder Bheesam to route the tickets to us.",
        "Hi @Bharat Rekha @Venkat Pavan Kumar Ichapurapu Are you referring to PLAT? I suggest you create a Zenddesk ticket, we will create a PLAT and send it to you",
        "Ok. @John Brandes I request you to create a zendesk ticket.",
        "@Bharat Rekha how do I create Zendesk ticket? This is something my prospect is interested in at Coach (cc @Kevin Mullay @Tim Loewenstein )",
        "@John Brandes you can reach out to product support team. They will help you raise a support ticket",
        "Hi @Bharat Rekha was it ever shared with John? Can you share a recording copy of it‚Äôs on this chat group here?",
        "Hi @Navdeep Grover / @John Brandes, is the PLAT or zendesk ticket created?",
        "@Bharat Rekha @Navdeep Grover @John Brandes I will take this to the various internal teams to determine what we have and how it relates to what we exists in Retail Assist and integrating what might exist. Will keep you posted.",
        "Sure @Tim Loewenstein, thank you!\nplease create zendesk ticket or email us the requirements."
    ],
    "spaces/AAAABcXBTWI/threads/YXrhgaWI9G0": [
        "FBlue would have all the different approaches to answer the question about updating the address within the same document. Not sure if business rules could work, but filtering or hiding certain chunks from that document may drop essential pieces of information from the document that might need to be considered to provide a proper answer."
    ],
    "spaces/AAAABcXBTWI/threads/zjCo9dhR034": [
        "May i confirm if those features are available now or not ? The first one in gray is Advanced SKU and green is Enterprise SKU",
        "That's a package differentiation - the Advanced package doesn't include the Enterprise RAG capabilities - you need to buy the Enterprise package and they're included",
        "Thank you.. so, Answer caching, multimedia content searching...are available in today enterprise sku release ?",
        "@Aditi Bhadouria",
        "@Sunny Lun No they are not yet available. \n\nAnswers cache can be used in Search AI standalone via PS effort",
        "@Aditi Bhadouria what is \"extraction of table (Advanced)\" in Enterprise SKU compared with \"Extract of Table\" in Advanced SKU",
        "\"In addition to the text, extract the original tables, images, graphs and charts to present them as answers for relevant questions\"",
        "@Sunny Lun which sheet are you referring to? In the Master sheet there is a column that gives a short description for each row. You can refer that, and if you have any more questions, I can answer them here",
        "Tab 1.4",
        "The Master sheet has descriptions(Column H) for tab 1.4 as well"
    ],
    "spaces/AAAABcXBTWI/threads/QUpTekUJdMQ": [
        "I'm getting a 502 Bad Gateway message when accessing SearchAssist: https://demo-searchassist.kore.ai/accounts/",
        "Maybe Restarting??",
        "It fixed itself eventually.  But now the project I had in that login is missing.   Ugh",
        "Hi @Tim Burke, We have brought the  application to latest version. Please create a new application there was a breaking change as the demo instance is in old version. @Riyaz Ahmed is validating the setup and update here.\n\nPlease let me /  @Riyaz Ahmed know if you notice any issues while creating new application."
    ],
    "spaces/AAAABcXBTWI/threads/DdurDzkbuRk": [
        "Team, is SearchAI available as PLG model?"
    ],
    "spaces/AAAABcXBTWI/threads/O-y1epkYyUQ": [
        "Hi Team,\n\nWe attempted to upgrade the demo instance today. However, due to its very old version, we were unable to upgrade it and had to perform a manual fresh installation instead.\n\nWe attempted to migrate the existing applications but encountered difficulties in bringing the old applications online. This issue arose due to the instance being an outdated version, which presents significant challenges in upgrading to the latest version.\n\nMoving forward, we will ensure to communicate planned maintenance activities and risks in advance.\n\nI apologize for the inconvenience caused and am here to assist in resolving any issues you face while building apps. Please let us know how we can help.\n\n @Riyaz Ahmed - for unblocking if incase of any issues while creating the apps."
    ],
    "spaces/AAAABcXBTWI/threads/kojbf7yd1CI": [
        "is there a reason we can't invite members to a SearchAssist instance using Google's account+ email format (curtis.swartzentruber+demo@kore.com). This works for all other products and we use this a lot to keep tenants separate based on demo requirements.",
        "Hi @Curtis Swartzentruber,\n\nIs the above email  a valid one?",
        "it is a valid Google format",
        "all email platforms route it just fine",
        "Are you unable to create? What is the error you are referring to?",
        "Seems we are validating the special characters. We will have this change fixed in the next hotfix.",
        "@Sreekar choppalli - please check this.",
        "We can sign up using \"curtis.swartzentruber+demo@kore.com\"\nchecking for invite user",
        "No we cant invite a user in this case due to email validation which wont accept special characters",
        "like I said, this works with every other platform at Kore. we use it all the time with platform.kore.ai, bots.kore.ai, agentassist.kore.ai, smartassist.kore.ai.",
        "please change your validation"
    ],
    "spaces/AAAABcXBTWI/threads/ZLuBBjE7N3A": [
        "Frontier is trying to set up Azure key for Search AI and have the following questions: \n1) for security reasons we would like to white list the source ip addresses. Can you provide that list?\n2) we need to deploy a model, do you use a specific model aka gpt4. Etc\n3) do you have an estimate of tokens you will consume?\n\nCan someone from the Search team help answer these questions please? I can set up a call with the customer if needed",
        "@Neeraj Kumar please work with @Sai Krishna Dasari for the IP addresses"
    ],
    "spaces/AAAABcXBTWI/threads/1RzBjmJboqs": [
        "Are there any issues with current production instance with Search Asssist? I am seeing anomalous behavior through the application.",
        "@David Gwartney we do not see any issues. could you elaborate the issues you are seeing?"
    ],
    "spaces/AAAABcXBTWI/threads/0XzUYM4szec": [
        "SearchAssist team, why is there no way to explicitly \"publish\" changes in SearchAssist? there seems to be auto-publishing happening behind the scenes (for instance when setting up an App/API Scopes, training, etc. But it seems to fail a lot and there is no way to explicitly force your changes to be available to external components using SearchAssist (API calls, AgentAssist, etc.) this is highly problematic",
        "we have spent at least 5 hours just trying to get basic SearchAssist/AgentAssist functionality to work for a highly visible demo for Royal Bank of Canada and it's still not functioning properly."
    ],
    "spaces/AAAABcXBTWI/threads/rGhEh5T-lKc": [
        "SearchAssist On-Call Team can you please check? @Bharat Rekha"
    ],
    "spaces/AAAABcXBTWI/threads/NCnXDbFYmOM": [
        "@David Gwartney are you talking about Search AI standalone or in XO11?",
        "@Girish Ahankari SearchAssist itself. we are trying to use it with AgentAssist stand-alone (agentassist.kore.ai). it's related to my question around changes not getting published. we are seeing different results in the Preview inside SearchAssist than in the same query externally"
    ],
    "spaces/AAAABcXBTWI/threads/JvziahsBsuc": [
        "@Neeraj Kumar estimate of tokens depend on the implementation, model can be 3.5 or 4 or any custom LLM.. Please work with SEAL or Implementation partner for the estimates as it depends on the solution design"
    ],
    "spaces/AAAABcXBTWI/threads/hHPSmpUKqIU": [
        "Thank you Girish!"
    ],
    "spaces/AAAABcXBTWI/threads/PwmFFynK0R4": [
        "@Aditi Bhadouria - What all API scopes need to be enabled for SearchAI to work inside of AA ? I want to get it documented on AA page. Thanks",
        "@Madhuluck Kumar \n\nFor Advanced Search API, this is hte reference\n\nhttps://docs.kore.ai/searchassist/public-apis/searchassist-apis-list/#Advanced_Search_API"
    ],
    "spaces/AAAABcXBTWI/threads/3W21vg6mCXI": [
        "what would cause the behavior of Generative answer (snippets) being returned inconsistently? We are having major issues on the RBC demo with this. sometimes they work, sometimes they don't. we are getting web file results, so SearchAssist is returning something. we want the snippet result, could care less about the web file result for this demo. is this a timeout issue or over quota issue? using OpenAI GPT-4 as the provider. @Girish Ahankari @Santhosh Kumar Myadam @Madhuluck Kumar we really need this to work consistently, it is causing a lot of problems in multiple demos.",
        "Are we noticing that the prompt is the same and the chunks are same while the answers are different?",
        "@Curtis Swartzentruber \n\nCan you please check the Debug Logs of SearchAssist by testing different scenarios? I am assuming you are primarily testing from AgentAssist. \n\nTry testing directly from SearchAssist to ensure that right chunks are getting qualified consistently. If that is the case, then it could be an issue with model or model call. Either case, the Response tab in Debug Logs will provide the error reasons."
    ],
    "spaces/AAAABcXBTWI/threads/fLqRJvPFet8": [
        "no, the problem is the Generative Answer is not returned a lot of the time at all. The problem is latency on GPT-4. I think it's just timing out a lot of the time. How long does the platform wait on an Answer Snippet response?",
        "Default timeout is 15 seconds",
        "Hi Curtis, it must be due to the limits on the deployment id, please check and modify the limits or please switch to 3.5 turbo.",
        "@Curtis Swartzentruber as per Prasanna's email, we should be using 4o everywhere - @Girish Ahankari",
        "yes, 4o needs to be native in the platform and we need to remove 3.5 and 4. 3.5 is not an option, the results are terrible relative to 4o.",
        "then we need to understand why the SearchAssist APIs are just not sending Answer Snippets then",
        "We are sending the 4o in July to configure.",
        "@Curtis Swartzentruber can we add 4o as custom and use it for now?",
        "that's what we did. but it's problematic that the default options in the platform right now are not working consistently",
        "either way, what is going on with answer generation? where is the timeout happening? there is no logging visible to help us debug these issues.",
        "@Curtis Swartzentruber there isn't much SearchAssist can do if the problem is at the LLM's end. We can suggest configuration changes if the issue is with retrieval",
        "that's a cop out. if the feature doesn't work with that provider consistently, why is it there in the first place? how are we supposed to use the product if there is no consistent behavior?",
        "Have you used the answer debug? https://docs.kore.ai/searchassist/test-app/answer-debug/",
        "we can try that, but 2 things. 1. the answer will often generate inside the platform, but not when called externally. that's what I mean about needing better logging. 2) I have tried the Answer Snippets simulator and with gpt-4 it just throws errors. I've never gotten it to work.",
        "and see my other thread on the problem with only having implicit publishing where it's not deterministic that changes you make are actually available outside the platform",
        "FYI, Answer Snippet simulator and Answer debug are different",
        "i understand that",
        "Yes, we don't have versioning in SearchAssist, but you can create multiple indexes, experiment with the configuration and then change the default index to start using it in production bot",
        "but answer debug doesn't help when we are getting exactly the response we want when testing inside the platform, but not outside",
        "I would like to have a way to explicitly publish, with real logging around whether publishing succeeds. this is similar to issues we have with auto-publish in SmartAssist. sometimes it silently falls on one step or another, particularly around gateway configuration. but in that case we can still force publish the instance bot. so there is a workaround.",
        "yesterday alone we wasted probably 5 hours trying to get one simple index to work in AgentAssist. we switched from pilot to production, we enable/disabled the web channel, etc. when things don't work, it's not clear why. were the changes published or not? is there a timeout somewhere? is this just an API issue? etc. these are things the demo team struggles with on every single demo we create that uses SearchAssist.",
        "@Curtis Swartzentruber \n\nApologies for the issues you are facing with the setup. We will discuss internally about all the aspects that you have highlighted and provide a definite plan on how we we are going to address them. \n\n @Aditi Bhadouria  @Bharat Rekha We need to understand the root cause of these issues and improve the logging wherever applicable. If these are not something that we can address via the product, then we should try and document all the relevant details. \n\n @Girish Ahankari",
        "thanks @Santhosh Kumar Myadam my intention is not to simply complain, I'm trying to point out real pain points we are facing in the field. thanks."
    ],
    "spaces/AAAABcXBTWI/threads/ZvYeCFdQEKo": [
        "How do we manage information in a sharepoint connector for example, so that information that is only available to some users is not available to all?",
        "Hi @Amy Jeschke, \n\nWe are working on RACL support for Sharepoint. So the permissions from the sharepoint are honoured."
    ],
    "spaces/AAAABcXBTWI/threads/VVtdcNSXKUA": [
        "RE: SearchAssist Pilot Env - Sharepoint Connector\nI am unable to select Save & Sync. Any suggestions?",
        "Are we having issues with the SharePoint connector in the Pilot environment? I have no issues clicking the Save & Sync button in the production environment."
    ],
    "spaces/AAAABcXBTWI/threads/5XnBNMl_NEA": [
        "Team, we're going to make a 2nd attempt to pitch Search AI at Yahoo. When we demo'd a year ago, they had asked about LumApps. I see our connector roadmap through Nov.  Any plans to add LumpApps on the horizon, so that we can set the right expectation?",
        "@Chiti Musonda \n\nWe haven't heard of LumApps from any other customer or prospect. We will need to analyze the feasibility and it might take another couple of weeks to do that. \n\nMeanwhile, we have started R&D on a Custom Connector framework that can be used with any content repository. This will be a generic feature to support any source without we explicitly building specific connectors. This request has come from.multiple stakeholders and we are aiming to do this in the next 3 to 4 months. \n\n@Aditi Bhadouria",
        "@Mounika vemula - FYI",
        "Terrific, I like the sound of a custom connector framework! Thanks for the update."
    ],
    "spaces/AAAABcXBTWI/threads/hX_HPf1VlZY": [
        "Hi team,\nWe have a customer in the JP region experiencing the same issue as described in the following Jira ticket. Since the delivery deadline for this project is approaching, it is imperative that we resolve this issue promptly. Can we attempt to connect to this customer's SharePoint using the SharePoint connector in the staging environment?\n\nhttps://koreteam.atlassian.net/issues/PLAT-30686",
        "Hi @Ichiro Fukuyama,\n We are working on this, we will update you on this. \n\n@Mani Kumar Nadella - please expedite the issue closure.",
        "Hello @Bharat Rekha , @Mani Kumar Nadella \nThank you for your support! \nWe want to ensure that our customer is indeed encountering this issue, so we would like to test the connection in the staging environment before the version with the fix is released.",
        "There were couple of issues reported and these issues are fixed and deployed to pilot and prod. As this requires customer specific validation because of heavy data dependency, can you please let us know the active issues that you are facing in pilot?",
        "@Bharat Rekha , \nThe customer successfully connected to SharePoint using the SharePoint Connector in their JP Region environment. \nHowever, when they clicked on \"Synchronized content now,\" a 504 error occurred, preventing the enumeration of the target SharePoint site. The customer mentioned that they have many SharePoint sites, so it is highly likely that this issue corresponds to the problem described in this Jira ticket.",
        "Is customer able to validate this pilot?",
        "@Bharat Rekha I am considering asking the customer to log in to this staging environment and attempt the connection and \"Synchronized content now\" action. Are there any concerns regarding this approach? Should we obtain the connection information from the customer and verify it ourselves instead?",
        "Sure, we can validate if we have the connection details. @Vaishali Addala please help to validate.",
        "@Bharat Rekha \nThank you for the good information.\n@Vaishali Addala \nI'm looking forward the information for validation.\n\nBest regards.",
        "Hi @Ichiro Fukuyama - Could you please share the app with me... so that I can quick check the issue",
        "Hi @Vaishali Addala ,  thank you for your help! I just added you to the application. The application's name is \"Johnson and Johnson\".",
        "@Ichiro Fukuyama - We already fixed this kind of issue in the Pilot instance. Could you please connect the SharePoint connector in the Pilot instance and check whether you can reproduce this problem?\n\nNote: This fix is yet to be deployed to the JP instance.\n\nCC:  @Bharat Rekha",
        "@Vaishali Addala Thank you. Yes, could you please provide the URL of the pilot instance?\nIs it https://staging-bots.idp.korebots.com?",
        "Pilot Instance: https://searchassist-pilot.kore.ai/auth/",
        "@Vaishali Addala  Thank you for the URL. I confirmed I was able to login the instance. I'll discuss the customer and try it."
    ],
    "spaces/AAAABcXBTWI/threads/MYn77tbqthM": [
        "Do we have a known gap/functionality document for Search AI which compares XO10 to XO11?",
        "FYI @Hannah Gore"
    ],
    "spaces/AAAABcXBTWI/threads/BH77bM31RzA": [
        "+1 I would like to see a document that specifically compares functionality in XO10 and XO11, what are the gotchas, etc.. It is my understanding that a customer cannot utilize XOGPT for Search in XO10."
    ],
    "spaces/AAAABcXBTWI/threads/3jUlNDgR9ZI": [
        "@Melissa Prince @Paul Chaigne \n\nYes, there are a few gaps and we are actively working on bridging this gap. We are aiming to close all of them by end of Aug/Sep 2024. However, if there are any specific gaps that are blocking a customer/prospect, we can expedite. \n\nWe do have an internal document, will clean it up in a day or two and share it with you. \n\nMeanwhile, do let us know any specific features that the customer/prospect is looking forward to. \n\n @Aditi Bhadouria  @Bharat Rekha",
        "@Santhosh Kumar Myadam @Aditi Bhadouria @Bharat Rekha are you in a position to share the internal document with the Search AI gaps please?",
        "Looping back on this, have you been able to prepare the document highlighting the gaps?",
        "@Paul Chaigne \n\nHere is the comparison between standalone SearchAssist (XO10) and Search AI in XO 11\n\nhttps://docs.google.com/spreadsheets/d/1pQXarKUGs3X2hnqYsvfTF966naEUbcwVg-G6dSl95W0/edit?gid=1090277526#gid=1090277526\n\nPlease note that this is a running document and should NOT shared with any external parties. You may use this data for internal evaluation purposes. \n\n @Aditi Bhadouria"
    ],
    "spaces/AAAABcXBTWI/threads/zO7ma232wQo": [
        "What is the ETA when customers can bring their own vector database?"
    ],
    "spaces/AAAABcXBTWI/threads/0e4GCERqeC4": [
        "Where can I get info about the IP Addresses / domain names of SearchAI production instance to whitelist on the client side? A sitemap is failing while I tried to ingest it in https://searchassist.kore.ai/",
        "Hi Navdeep, you can find the list of IPs here https://community.kore.ai/t/list-of-kore-ai-saas-ips-outgoing-by-regions/3512\nCan you please let me know for which client are we facing the issue?",
        "Keysight, I reached out to support too."
    ],
    "spaces/AAAABcXBTWI/threads/T8LwL9n5PVU": [
        "Hi Team,\n\nThis question is for a customer who needs Search AI solution\n\nLet‚Äôs say If the customer has got 2 different Set of documents\n\nA) Simple Q&A pairs structured documents \n\nB) Documents with text, Tables, images etc which needs LLM /GenAI to answer from paragraphs, paraphrase etc\n\nNow, our document ingestion fee- does it apply for both A & B set of documents the customer uploads?\n\n2) What is the cost effective model that we can suggest, if the customer has to frequently make changes in few sections or pages of the documents from the above categories A & B. Let‚Äôs say like change in 10 pages out of a 500 pages document?",
        "Not sure who is the right person to answer this, but pls help tagging the right person",
        "Hi @Rakesh Bathini, \n\nCan you please send en email for this? It becomes handy to ask questions or to discuss. \n\n@Riyaz Ahmed"
    ],
    "spaces/AAAABcXBTWI/threads/3OrMIese7Bg": [
        "@Richard Passavant"
    ],
    "spaces/AAAABcXBTWI/threads/q4nZCNudRpw": [
        "For A), I guess @Rakesh refer to  our traditional extractive model but not generative model."
    ],
    "spaces/AAAABcXBTWI/threads/vqgBFaEYyX8": [
        "To add, if I use my own vector db or use Api to create chunks instead of document upload, do I need to pay for document ingestion fee ? @Richard Passavant",
        "That's why I asked Rakesh to bring the question here, I don't have the answer!\n\n @Santhosh Kumar Myadam  or  @Girish Ahankari ?"
    ],
    "spaces/AAAABcXBTWI/threads/WMXOT3qyIgI": [
        "Thanks Bharat. Dropped you an email"
    ],
    "spaces/AAAABcXBTWI/threads/9L1jn19VL2o": [
        "We could all benefit from the answer.  I encourage you to craft a summary answer that can be posted in this space for later reference.  The Search feature in GChat isn't as good as SearchAssist, but it helps.   And eventually,  maybe we can craft a virtual assistant to answer internal process questions... imagine that!  üôÇ"
    ],
    "spaces/AAAABcXBTWI/threads/hdLOSRPwjR0": [
        "Hi all - I'm working with a current customer that would like to pilot Search Assist.  They are currently on XO10, with no definitive plans to migrate to XO11 in the near future.  They would like to use Gen AI in this pilot and were hoping to utilize XOGPT, but we recently found out that it is not available in XO10 for Search Assist specifically.  Would it be possible to set up a sandbox in XO11 for them to test Gen AI functionality with XOGPT.",
        "XOGPT is totally available in XO 10.  If you login to BotBuilder you can see the use cases it can be used for.    SearchAssist (not SearchAI) does not currently use XOGPT.  Which is fine because currently XOGPT only handles 4 use cases for conversation management, not RAG (more use cases are on the roadmap).  GenAI is supported in XO10",
        "I meant Search Assist.  It's my understanding that XOGPT is not included for Search Assist in XO10",
        "That may not be a problem for you.  If you are using XO10 to handle conversations, the XOGPT is used there.   The answers are surfaced up to the conversation from SearchAssist in the background.  You are likely not creating the \"channel\" that the users are interacting with in SearchAssist... but more likely, in XO10 web, voice, MSTeams, etc.    So you can use both!   XOGPT in XO and a commercial or fine tuned model in SearchAssist (see pic).",
        "And customers bring their own license of the LLM of choice... so if they are already licensing MS AZure OpenAI (for example), it can just use their existing license and agreements with that provider.",
        "@Corey Erkes",
        "Documentation on XO GPT (notice, its called XO for a reason :-) \nhttps://developer.kore.ai/docs/bots/nlp/kore-xo-gpt-model/",
        "UPDATE:  I see what you are asking for.  In SearchAI XO 11  XOGPT can be used for SearchAI functionality.  It has two additional use cases that it provides (Conversation Summary and Vector Generation).  If those features are important, than yes... get them an XO11 sandbox to be able to test those features. \nXO GPT 11 documentation link: https://docs.kore.ai/xo/generative-ai-tools/xo-gpt-module/?h=xo+gpt",
        "Thanks for your help @Tim Burke.  Appreciate you taking the time to hop on a call and explain this to me."
    ],
    "spaces/AAAABcXBTWI/threads/IHNYTFbwUQs": [
        "Dear team,\nOur customer wants to use the SharePoint connector in SearchAssist to crawl the content of specific sites. However, when they enable the checkboxes for the sites they want to crawl and disable the checkboxes for the other sites, the settings are saved with the checkboxes in the opposite state (the checkboxes for the target sites are off, and the checkboxes for the other sites are on).\n\nNote: Please refer to the following video.\nhttps://www.loom.com/share/30e2bf17658242099bf8b2623264c7e4?sid=cfa926cf-47a1-486b-8491-5d7f810852ed\n\nThe customer mentioned that there are over 1000 sites in this tenant.\nHas anyone experienced this issue? Is there a solution?",
        "Hello Ichiro Fukuyama, Sorry for that. We have fixed this issue. Soon it will be shipped in the upcoming release."
    ],
    "spaces/AAAABcXBTWI/threads/lYdoY2uOJog": [
        "Hello @Rushivar takhur \nThank you for your prompt response. This customer is using SearchAssist v2 and is setting up a production environment. In which version will this issue be fixed? Additionally, is there any workaround available?"
    ],
    "spaces/AAAABcXBTWI/threads/Lg47_sOd4a8": [
        "Currently there is no workaround. It will be available in the  Version 2.1.0",
        "Hi @Ichiro Fukuyama, Could you please create ticket for this issue for tracking purpose?",
        "Hi @Bharat Rekha @Rushivar takhur \nThank you for your help. I just filed a new support ticket as following. Please take a look it.\nhttps://support.kore.ai/hc/en-us/requests/46252",
        "@Rushivar takhur @Bharat Rekha Do we have any JIRA for this?",
        "No, we don't have",
        "So shall I create a JIRA and assign it to you for tracking purpose. Once the functionality is released, assign it back to us so that we can convey the same to the customer? Does this work?",
        "yes @Pruthvi Senapathi, please do. Thank you",
        "Hello @Rushivar takhur @Bharat Rekha @Pruthvi Senapathi \nThank you for your continuous support. I  updated the Jira ticket.\nhttps://koreteam.atlassian.net/browse/PLAT-31732\n\nI confirmed that SearchAssist in the JP region was upgraded to version 2.1.0 on 7/28. However, this issue remains unresolved despite the upgrade.\n\nAs the project‚Äôs Go Live schedule is approaching, could you urgently take a look at this issue again?",
        "Hello @Ichiro Fukuyama , Sorry for that.  There was an one scenario missed, I will unblock you via API. Can I do that?",
        "Hi @Rushivar takhur , does that mean I can solve this issue by calling the API for SearchAssist by myself? If so, could you share  it with me?",
        "We have your app, Can I do it now?",
        "Yes, please.",
        "Done. Could you please check the app",
        "Hi  @Rushivar takhur \nThank you very much. We had a meeting with the customer, and we confirmed together that this issue has been resolved. We were able to check, crawl, and search only the target site of the customer.\nWe greatly appreciate your prompt & great help."
    ],
    "spaces/AAAABcXBTWI/threads/WkyICU2a-T0": [
        "Team, is there a migration plan on how we move the customer from Search Assist to SearchAI",
        "Hi Rakesh\n\nWe do plan to migrate all our existing SearchAssist customers to XO 11 Search AI. However, it may not be an automatic path. May I know the customer details?"
    ],
    "spaces/AAAABcXBTWI/threads/4uc8cpHa8rE": [
        "I get two responses from SearchAI, when Rephrase Dialog Responses capability in GenAI features is enabled ..  Is that a normal behaviour? a follow-up contextual Q is fine but it should not answer the amount of devices I can trade up in the follow-up response, when I already received an info in the first one, from the ingested .pdf.",
        "@Navdeep Grover \n\nIs it from XO v11? \n\nIdeally, it should not show 2 responses. Can you share a little more details about what is the flow",
        "Yes, XO v11. I created a high bill use case for telco, ingested a .pdf in SearchAI. Anytime I ask a Q. during high bill chat conversation, it throws 2 messages with Rephrase Dialog Response capability turned on. It responds with the first msg, if I disable it. Its only with SearchAI responses, rest all works fine. @Santhosh Kumar Myadam"
    ],
    "spaces/AAAABcXBTWI/threads/Gkecp4TIov4": [
        "Does anybody know if we did any implementation of Search Assist with Guardian Litigation?"
    ],
    "spaces/AAAABcXBTWI/threads/DCFLg9klCY4": [
        "Greetings Team,\n\n @Kevin Mullay  @Colin Federle and I have just had a conversation with the Government of British Columbia. There is an initiative for handling indigenous languages. What is necessary within Search AI to allow for the consumption of content in these languages and allow results to be processed.",
        "Please share the list of languages you are looking for, we will check and get back to you"
    ],
    "spaces/AAAABcXBTWI/threads/fk_gzYmo2Ig": [
        "Do we let customers utilize their preferred Vector DB and are not forced to use a specific Vector DB defined by Kore.ai?",
        "Bringing this back to the top - I believe this is not an option today but is planned to be in the future?\nOption to swap the SearchAI module with an internally built semantic search API - Here the idea is that the Kore solution (SaaS or internally hosted) is modular to be able to allow us to switch to our search endpoint at some point.\n @Alex DiSette  @Todd Lewis  @Aayush Mediratta  @Matt Panaccione"
    ],
    "spaces/AAAABcXBTWI/threads/myE_f8od3qo": [
        "Any known issues with respect to the Full Search API truncating answers from the API response?"
    ],
    "spaces/AAAABcXBTWI/threads/dx2KFsu19Ck": [
        "Is anyone else experiencing issues with SearchAssist Web Crawls just sitting in queue?",
        "Yes!\n\n- Delete the crawler url\n- Changes the wait time to 9 seconds\n- Disables Javascript rendering\n- Run the crawler again"
    ],
    "spaces/AAAABcXBTWI/threads/aOkbAZ_dNt0": [
        "I'm working in XO 10's version.... because I'm about to demo an Assist Solution..."
    ],
    "spaces/AAAABcXBTWI/threads/KIxClc8DM1o": [
        "I'm going to switch to XO 11 as I can do that there"
    ],
    "spaces/AAAABcXBTWI/threads/q2nlrswlNYI": [
        "We have an eBay compliance requirement to delete Search query data more than 30 days: https://koreteam.atlassian.net/browse/PLAT-29822. I believe we have a KE ticket for this but eBay shared feedback that some data >30 days is still showing.",
        "@Neeraj Kumar we are checking the pending job cleanup related to searchai. \n\nFYI - Ideally it is good to have separate tickets for each team.",
        "@Bharadwaj please expedite this.",
        "@Bharat Rekha Sure",
        "Thank you @Bharat Rekha @Bharadwaj"
    ],
    "spaces/AAAABcXBTWI/threads/grH-TzEKtE8": [
        "Can you please help expedite this @Bharat Rekha \ncc:  @Girish Ahankari"
    ],
    "spaces/AAAABcXBTWI/threads/y098q2vc86U": [
        "What is the target for RACL for Google Drive?",
        "Hi @Andy Pham, The beta version is available now in PROD.",
        "@Bharat Rekha is this true for ServiceNow as well?",
        "Correct.",
        "@Bharat Rekha @Aditi Bhadouria Do we have any documentation around configuring ACLs over ServiceNow integration?",
        "Hi @Navdeep Grover, This is released very recently, let me check and revert back if the drafted version went live. \n\nFYI:  @Shruti Kukkar",
        "It will go live in a day or two. Apologies for the delay",
        "@Aditi Bhadouria @Bharat Rekha Besides Google Drive and Service now, are there others?",
        "@Andy Pham \n\nThe following article will have full details \n\nRoadmap (next 2-3 months) includes the following - Confluence Cloud, Sharepoint, and will keeping adding more based on the priority. \n\n @Aditi Bhadouria"
    ],
    "spaces/AAAABcXBTWI/threads/ApM3Bv-XTIs": [
        "Hi team, Im getting 410 url expired Error once i click on the Reference link even for the first time.",
        "Hi Team, we are also trying this bot on Google Chat.\nYesterday, the link expired even for the first time clicking, tried like 5 times.\nI'm assuming it is because the SandBox opens the link before showing to us and that makes the link expired?\nIs there any work-around for that situation?"
    ],
    "spaces/AAAABcXBTWI/threads/dCr8_ax3ckw": [
        "Hi @Shoho Shiraichi / @Su Hyeok Seong , The one time url validation can be disabled. @Mounika vemula - please share this config. \n\n @Vamsi Lankisetty - please check this issue and raise a bug for one time urls.",
        "Hi @Shoho Shiraichi / @Su Hyeok Seong, to disable this one time url validation please add below custom configuration in search settings.\n\"Single Use Url\" : \"false\"",
        "@Mounika vemula thank you so much"
    ],
    "spaces/AAAABcXBTWI/threads/F1rDAlElqwQ": [
        "@Aditi Bhadouria @Surendra Subhash Salke can you help?",
        "This is in our roadmap. It is not currently available."
    ],
    "spaces/AAAABcXBTWI/threads/z3uIkdUmDQo": [
        "What is the ETA for supporting Zendesk cases?"
    ],
    "spaces/AAAABcXBTWI/threads/-ATcgJTHTyc": [
        "Hello Team, I received the following benchmarking metrics request from Capital One that are crucial for gathering executive support of our program. Your assistance in gathering the answers is greatly appreciated. The use case Capital One is focused on is for their AWS Engineering team, searching Sharepoint for solutions to common engineering challenges helping their support organization get engineers the accurate answers the need fast.    Performance Rate:¬†Number of correct answers divided by the number of total active sessions (a correct answer is an answer suggested by the bot and clicked by the user in case of multiple choices ‚Äì or opened instantly in case of strong semantic matching).\nSelf-service Rate:¬†Percentage of user sessions that did not end with human agent escalation after using the bot.\nSatisfaction Rate:¬†Average grade given when evaluating the chatbot‚Äôs answers.\nBot Experience Score‚ÄØ(BES):¬†The BES is based on an analysis of all conversations over a given period of time and reduces the score for negative experience signals that are common in all virtual agents.\nAgent Experience Score:¬†metric that looks at signals within conversation data such as agent abandonment, wait time, handle time, and sentiment.\nFalse Positive Rate:¬†is a measure of the rate that an utterance is classified by the model incorrectly although the model gives it a high confidence level.\nNLU Rate:¬†Measure of the rate that a classifier can match an utterance to a known intent at a given confidence level.\nAverage Response Time: Quantifies the duration between a user's query and the chatbot's reply.",
        "@Girish Ahankari who can help us with this?",
        "@Sathya Priya Turaga @Bharat Rekha can you take this up please",
        "Sure @Girish Ahankari. @Sathya Priya Turaga lets syncup internally on this.",
        "Sure Girish."
    ],
    "spaces/AAAABcXBTWI/threads/9XMItYeDnrY": [
        "Dear All,\n\nSurendra Salke would be on a long leave from today, hence, Effective immediately, Bharat Rekha will be the point of contact for engineering at SearchAI (SearchAssist).¬†\n\nBharat has been leading multiple initiatives in SearchAssist for a year now and am confident that he can carry the responsibilities smoothly.\n\nFor any product-related inquiries, please continue to reach out to Aditi Bhadouria. She will continue to have the Office hours regularly as being done currently.\n\nFor questions regarding SearchAI implementation, kindly contact Sathya Priya Turaga.\nWe have started having monthly sessions with the CS leadership and team and regular connects with the CS team to track each account and their implementations. This should start yielding results in a month.\nSathya will also be having regular sessions along with Bharat with the SEAL team.\n\nThank you for your understanding.",
        "Thank you  @Girish Ahankari for the trust and confidence you've placed in me. Hi everyone, I am stepping in as the point of contact for engineering at SearchAI (SearchAssist). Please feel free to reach out to me with any engineering-related questions or concerns. I look forward to continuing our progress and working closely with you."
    ],
    "spaces/AAAABcXBTWI/threads/lxE8u5fz57I": [
        "Hi Team. My training in UXO 11 is in Queue for more than 6 hours",
        "We are looking in to it @Sathish Ramachandran",
        "@Venkata Naresh Divi Whats the update on this?",
        "Its working status changed around 4 hours back",
        "@Girish Ahankari We have only one worker for data indexing in USProd due to which all the jobs were in queue caused the delay.\n\nWe have raised a KE to increase the worker count which solves the problem",
        "Is it done or waiting for approval?",
        "It's waiting for RV approval Girish",
        "Please ping him separately and request for approval",
        "Sure Girish",
        "Is this done ? Please make sure you provide an update",
        "Sure, Prasanna. We are currently coordinating with the DevOps team and will provide an update soon. Apologies for the delays; it was missed in tracking, to get the necessary approvals then to expedite the process with DevOps.",
        "It was done last night @Prasanna Arikala. We have validated the issue and it's working fine"
    ],
    "spaces/AAAABcXBTWI/threads/bBck-NH6-PU": [
        "In V11 SearchAI, is there any way that I can have the pre-processor/event  before it passes to RAG? My use case will be like that: Users ask a question and some terms in the utterance are too vague. I need to prompt the users to provide the details and hence will change the utterance before passing to the RAG. For example, my question is \"What is the availability of top floor units in XXXX\". I will ask users to confirm what is the meaning of top floor. If users said 37F. I will change the utterance to \"What is the availability of 37F units in XXXX\". I",
        "@Sunny Lun \n\nIt is a good use case but has a lot of scenarios to handle. One of the ways to solve this is to use GenAI node to disambiguate the user input to collect additional information when required. The prompt needs to be tweaked to handle various scenarios. Post capturing of GenAI node entities, we can make call to search. \n\nAlso, we are adding a Search Node as part of the Dialog Builder and should be available in the next few weeks. It makes it much more easier to invoke search. \n\n @Prathyusha Gopavaram  @Aditi Bhadouria"
    ],
    "spaces/AAAABcXBTWI/threads/vkQV4j6oPC4": [
        "What is the process to increase the file size limit to 35MB?",
        "The SharePoint connector allows me to upload files larger than 25MB. What is the maximum file size limit?"
    ],
    "spaces/AAAABcXBTWI/threads/kqHR1U-WPNU": [
        "I am getting ready to do some troubleshooting for CBRE and saw these enhancements. Thank you so much!"
    ],
    "spaces/AAAABcXBTWI/threads/ZnHs7YIkcEw": [
        "PDF files synced from SharePoint aren‚Äôt being chunked. I tested this in both the production and pilot environments. However, if I manually upload the pdf file, it chunked correctly. Please advise.",
        "I also tried with a new app. That did not help. cc: @Melissa Prince",
        "This is a known issue @Andy Pham",
        "The hotfix for this issue is going to be rolled in and around August 10",
        "@Pruthvi Senapathi Could you please share the plat for tracking?\n\n @Rohan Chaurasia",
        "https://koreteam.atlassian.net/browse/PLAT-32036\n\n @Bharat Rekha  @Rohan Chaurasia"
    ],
    "spaces/AAAABcXBTWI/threads/EncUpFWLprE": [
        "How do we handle this, looks like they are asking for feedback loop (employee giving feedback that the response / info is outdated/incorrect)- ‚Äúhow does the chatbot (using SearchAI) handle situations where the information it has access to may be conflicting or outdated? Does the chatbot try to determine the most accurate and up-to-date answer, and if so, how does it express the level of confidence in its response?‚Äù @Aditi Bhadouria @Bharat Rekha",
        "Hi Navdeep \n\nApp Developer can check the feedback and comments for answers in analytics (Search AI Standalone) and update configs/sources as required. If you're looking for an automated process, we can take advantage of Caching. Please note caching will require orchestration to be performed, it is not fully available OOTB",
        "For caching to work, do subsequent utterances have to be identical to those in the cache?",
        "@Aditi Bhadouria",
        "Thanks Aditi! Can you please elaborate on the orchestration piece?",
        "You would need 2 apps. 1st app would contain all the documents and data to search over. 2nd app would contain the cached questions and answers. We would need the approved (either based on positive feedback or manual process) questions and answers to be ingested in the 2nd search app. Once the cache is built, the end-user SDK should point to the 2nd app. If we don't get answer from 2nd app only then we go to the first app",
        "Thanks!!",
        "Aditi - in the 2nd app, are the ‚Äúcached‚Äù q&a stored as FAQs?"
    ],
    "spaces/AAAABcXBTWI/threads/rboungACbJ0": [
        "I'm looking for an in depth, deep dive recorded demo of Search AI specifically on ow to use business rules, result ranking, different configuration items, etc... Do we have anything like that?",
        "@Curtis Swartzentruber or @Aayush Mediratta",
        "@Melissa Prince i have not seen it yet - is the documentation not enough? https://docs.kore.ai/xo/searchai/business-rules/",
        "https://www.loom.com/spaces/All-Koreai-1226564/folders/SearchAssist-3103d4b447e745a4a54c74a19670307b"
    ],
    "spaces/AAAABcXBTWI/threads/uxEI_orQ0H4": [
        "look under \"Videos\" in the legacy resource portal - https://resourceportal.kore.ai/view-searchassist-details/?param=SASB&cid=3638",
        "There are a number of detailed videos for SearchAssist in there.  XO10 version.",
        "@Melissa Prince"
    ],
    "spaces/AAAABcXBTWI/threads/rQ0rUV10ra8": [
        "Hi @Andy Pham \n\nWe can increase the limit up to 35 MB for an app, it has to be manually updated in the backend currently. But we do not allow this for cloud customers, as it impacts our services. If the customer is on-prem you can raise a support ticket and team will do the necessary",
        "If I read it correctly, the option is only available for on-prem customers. Do you know why I was able to upload a 25MB file via the SharePoint connector? Is it a bug or a feature?",
        "cc @Melissa Prince",
        "@Aditi Bhadouria",
        "You should not be able to ingest files more than 15 MB in SearchAssist even if you have uploaded them in Sharepoint. If you are able to we must have increased it from the backend for a demo request"
    ],
    "spaces/AAAABcXBTWI/threads/eHMntShFZeo": [
        "Team, the field is in need of a detailed explanation of document ingestion breakdown. We are using vernacular that is foreign to our prospects, like \"pages\" rather than file size or number of documents. This is difficult for our prospects to grasp or to categorize. Furthermore, we need to be able to provide our prospects with a \"best practice sheet\" that outlines were the sweet spot is for total number of documents ingested. A lot of prospects say that have millions of documents to ingest but we know that there is a critical mass point where too many is no longer effective in generating valuable responses. What are the best practices for data categorization? Things like newest in, oldest out, etc? We really need this addressed as most of us are having these conversations (at this level) on a weekly basis.",
        "Hey team, just wanted to follow up on the earlier request about breaking down document ingestion in a way that‚Äôs easier for prospects to understand. I‚Äôm facing similar challenges, especially when it comes to explaining things like file size versus pages and finding the \"sweet spot\" for the number of documents ingested. A best practices sheet and some guidelines on data categorization (like newest in, oldest out) would be super helpful. Is this something you can provide to the sales team by early next week?"
    ],
    "spaces/AAAABcXBTWI/threads/rUKfZiqOo-8": [
        "Do we have plans to integrate Search AI with Google Big Query as a Connector?\n\nUlta Beauty just completed a large Data Ecosystem migration.",
        "@Aditi Bhadouria @Bharat Rekha"
    ],
    "spaces/AAAABcXBTWI/threads/a3DHQXELVho": [
        "@Aron Kurzinski & @Louie Garrovillo - let's partner with product to document this\n\n @Melissa Prince - unlikely by early next week unless @Santhosh Kumar Myadam or someone on his team has someone already working on such a document",
        "Appreciate the help and collaboration @Richard Passavant and team!",
        "@Richard Passavant, @Melissa Prince I have reached out to Aditi to discuss this and see if we can come up with a quick sheet for best practices using search assist- to echo Richard, I dont think we will have one by this week given the other projects we are trying to complete - but added this to priority list",
        "@Marcel Korst - here's the original ask\n\n @Aditi Bhadouria - FYI"
    ],
    "spaces/AAAABcXBTWI/threads/gD3o-83H-L4": [
        "@Bharat Rekha  is this an architecture your team are investigating? \nhttps://www.linkedin.com/posts/cobusgreyling_a-recent-direction-in-rag-architecture-is-activity-7227675808427880448-7ThU?utm_source=share&utm_medium=member_desktop",
        "@Tim Burke yes we are working on this. This could be a usecase of cases where we dont have to respond within second or two.. and can run in background using Agentic Search.. We are actively working on a POC and productize the same."
    ],
    "spaces/AAAABcXBTWI/threads/IH3gH84OYeY": [
        "I have a prospect with employees outside of the U.S., where their benefits, such as PTO, vary based on location. Assuming the user‚Äôs location is assigned to the XO context variable, how do I pass this information to SearchAI to ensure the response is specific to the location? Is it possible?",
        "@Andy Pham \n\nThere are 2 parts to it. \n\n1 - The content should be tagged to know if it applies to all employees or employees from specific region.  This can be done via workbench. We do not have manual tagging at the moment. \n\n2 - Employee's location can be passed to SearchAI via Advanced Search API ad additional parameters.  \n\n@Aditi Bhadouria",
        "Andy I can show you.",
        "I just did a demo on passing user context and injecting it into the prompt",
        "And it works great",
        "@Andy Pham",
        "@Gurpreet Singh could you record a short vid, or write a few lines on how you did it?",
        "Sure. I was going to record it yesterday.. but ran out of time. But yea I can do that!!",
        "Here is the vid. Lmk if things are unclear and I can help explain further. Thanks to Aditi for the knowledge sharing.\nhttps://www.loom.com/share/074aa02537de4aafb7bdccf2a609d454",
        "@Lacey Emery - a VERY related discussion to your MD Billing question"
    ],
    "spaces/AAAABcXBTWI/threads/VB0fXJUneHI": [
        "@Pankaj Sharma, Please add your search AI queries here"
    ],
    "spaces/AAAABcXBTWI/threads/B_lGLtsWfG4": [
        "Hi, Customer have Salesforce documents(not as knowledge article) which we need to ingest into SearchAssist, and Do we have any API to achieve this."
    ],
    "spaces/AAAABcXBTWI/threads/N635G_NeY0E": [
        "@Aditi Bhadouria is it not possible to assign the owner role to another user that an App is shared with, i.e. like Bot Owner vs Developer in XO 10?",
        "Yes, you currently can not change app owner role in Search AI standalone. But you can assign them the role of \"member\" which will have the same permissions as the owner.",
        "Thanks @Aditi Bhadouria. Does a member have the ability to invite NEW members to that App?",
        "Yes, they can",
        "Thank you so much"
    ],
    "spaces/AAAABcXBTWI/threads/GJaT-R1dlxQ": [
        "@Aditi Bhadouria is there a way to have a workspace in XO 10 that has an Enterprise license but that does not give the same license level in SearchAssist?\n\nI'm trying to understand how / if we the two are mutually exclusive and have two separate \"licenses\".",
        "They refer the same license. It's not possible currently",
        "Okie Dokie. That's what I needed to know.",
        "Thank you @Aditi Bhadouria",
        "@Paul Chaigne related to what we were speaking about a while back."
    ],
    "spaces/AAAABcXBTWI/threads/BSSkEuGo46w": [
        "SearchAI Team - do we have recommendations on what documentation format would be easiest to chunk and ingest into the searchAI index? I recall seeing a document 1-2 years ago, but with the   Advancements of extraction models, maybe we have some new guidelines? FloridaBlue is looking to re-do their documentation for the agents and want our guidance, as they are committed to using SearchAI.",
        "For example, maybe a guideline would be to avoid using tables, or tables within tables (which they currently have). Advice on this would help them get started with creating a format best suited for ingestion and ultimately answer retrieval.",
        "@Aron Kurzinski @Richard Passavant maybe you guys can include this in the best practices items while you work with @Aditi Bhadouria My client FloridaBlue wants this immediately.",
        "We need this immediately for CBRE as well. @Andy Pham",
        "@Gurpreet Singh @Melissa Prince @Erick Waggoner I messaged you with a rough draft - would like input to see if its answering the questions we have / what we may need to add",
        "Thanks Aron. I see some mention about the latest extraction models able to parse html tables. Do we know what models these are and where I can find the deeper capabilities for each? But more importantly, I need general guidance / recommendations on how documents should be formatted, or what to avoid (like tables within tables).",
        "Adding to this channel my comments from email response. This revision of our previous process is very much inline with the conversations I am having. I do have a couple of follow up questions about our client classification process and what is expected of them to deliver to us.\n\nFor example, many clients have various drives storing this information. This information has many file types. You outlined the file types well in this document. They are able to usually¬†determine the size and the file type for data categorization but this still represents all of their content and not just the most relevant or current information.\n\nWhat can we say to these prospects about Data Classification and Categorization Best Practices? In other words, for optimal performance, this is what you need to bring to us for ingestion."
    ],
    "spaces/AAAABcXBTWI/threads/Hfd72PsbCms": [
        "Team, I previously uploaded an Arabic document in SearchAssist, and the training index completed successfully (chunks were created), allowing me to generate answers using the generative model with a multilingual prompt. However, today, I uploaded a new Arabic document in the same format, but the training is failing. Any idea what might be causing this?",
        "@Zaher Awada is this happening even now? @Bharat Rekha please check"
    ],
    "spaces/AAAABcXBTWI/threads/p7caJHFAaOQ": [
        "Tool is already available to be run offline. Have you tried it?",
        "No Girish. How can I get access to it?"
    ],
    "spaces/AAAABcXBTWI/threads/ISpRSFrPeAo": [
        "When do we plan to support this feature: \"AI Re-Ranking - Learn to Rank - AI models analyze the feedback provided by the end-users and dynamically re-rank the results to improve the relevancy and answer quality\". it says Later in the roadmap slidedeck with no mention of timelines. Some prospects mentioned it is a basic feature and our competitors have it already. They want SearchAI to learn automatically, from customer's feedback and improve responses or deliver correct ones.",
        "This is applicable only for search results and not for Answers. Can you list the prospects and their usecases please?",
        "Mars (working on RFP) /  Keysight (working on a PoC plan).. Ring Central (had couple calls, they are still taking time to make a decision).. Use Case is to enhance information search experience to help employees find it easily via precise / relevant responses over natural language.",
        "@Navdeep Grover so is the experience a Search results experience which is being expected here?",
        "@Girish Ahankari Answers.."
    ],
    "spaces/AAAABcXBTWI/threads/0FSz7NtqPSc": [
        "@Navdeep Grover \n\nHere is the link:\n\nhttps://github.com/Koredotcom/SearchAssist-Toolkit\n\n @Bharat Rekha",
        "@Girish Ahankari we need to setup a page within the product that points to this tool with description",
        "Ok"
    ],
    "spaces/AAAABcXBTWI/threads/E9zIHb2n9lo": [
        "I have a customer who is interested in using XO GPT for Answers Generation instead of using commercial LLMs. This is on XO v11. \nI did a quick test and unable to get it to work. Here are my configurations\n1) Under Generative AI Tools -> Model LIbrary -> selected Kore.ai XO GPT -> enabled Fine-tuned embeddings model and Fine-tuned model for Answer Generation. \n2) Under Prompt Library - Answer Generation - Assigned \"Kore.ai XO GPT\"\n3) Under Search AI -> Answer configuration -> Generative  Answers -> it shows LLM Model as \"Kore.ai XO GPT\"\n4) Under Index -> Vector model shows -> Kore XO GPT - MPNet Embeddings \n5) Clicked on \"Train\" and completed. \n\nUpon my testing, I am getting an error as shown below. Any help to fix this issue?\n @Aditi Bhadouria  @Bharat Rekha",
        "Hi @Raman Srinivasan , we're currently experiencing some challenges with the Kore XO GPT Answering model as it has been undeployed. Please give us a couple of hours to re-deploy it, and we'll keep you updated. Thanks",
        "@Thirupathi Bandam we need to have this monitored. Why it got undeployed? Please set up all the operational procedures @Ravi Rachannavar",
        "I am speaking with @Thirupathi Bandam now. He will first increase the limit. We will add monitoring on this and look for an unlimited limit option for some models.",
        "@Ramesh Srinivasan who is the customer? Can you update the details to @Sathya Priya Turaga so that she can track the progress?",
        "@Prasanna Arikala currently in GALE we have a usage limitation in hours for every model we deployed due to infrastructure pricing. We have requested the team to increase the limit to indefinite for some accounts",
        "@Girish Ahankari Frontier communications is the customer, they wanted to try Search with Kore GPT on v11",
        "@Raman Srinivasan we have re-deployed the model and now Kore XO GPT answers are working. Please check and let us know if any challenges",
        "Thanks @Ramesh Srinivasan please keep @Sathya Priya Turaga copied in all communication related to this work",
        "Hi Prasanna, This model is in Venkata Divi's account. We show number of credits remaining in the account in GALE dashboard. But we need to have alerts for credits based on some thresholds. I will speak to Murali on this. Thanks",
        "@Venkata Naresh Divi , It works now. Thank you"
    ],
    "spaces/AAAABcXBTWI/threads/YlNg_cnRS9g": [
        "https://docs.google.com/document/d/1l7zX55tEP_oT3XeCx0SOBllqt4QlGnOlr_FDlEWCutw/edit?usp=sharing",
        "Thats a Gold mine of good information!  Thank you for sharing",
        "@Sathya Priya Turaga can we add more latest information to this please",
        "Sure Girish."
    ],
    "spaces/AAAABcXBTWI/threads/wPQ8NkFBYEM": [
        "Hi @Zaher Awada,\n\nWe are checking this in our QA applications. To expedite the resolution, could you please create a Zendesk ticket and share the app access with us? Feel free to attach this message to the ticket and route it to us directly.\n\nCC:  @Ravinder Bheesam - please route the ticket to Searchai team.",
        "@Zaher Awada Could you please create a support ticket and share the reference number here?"
    ],
    "spaces/AAAABcXBTWI/threads/QkRb6jtt834": [
        "Would you have any thoughts on this result? I don‚Äôt see the word bonds in the resulting chunk or the pdf document."
    ],
    "spaces/AAAABcXBTWI/threads/PVwK1c7aNzc": [
        "Although the answer mentions the Advantage Portfolio fund, the citation refers to a completely different mutual fund.",
        "@Andy Pham \n\nI am assuming that the chunks sent to LLM might have this information but the model did not return those chunks as 'used for answering'. Is it possible to share the JSON (JSNO View) for both these results?",
        "@Santhosh Kumar Myadam, I have since removed one of the two PDF files, leaving only the PDF for the Advantage Portfolio fund. For some reason, it‚Äôs having trouble finding the investment approach. The JSON_View is attached.",
        "The answer wasn‚Äôt a part of any of the chunks.",
        "@Aditi Bhadouria @Sathya Priya Turaga can you check and help here please",
        "This can be caused by multiple reasons\n1. To render citations for generative answers, we depend on the LLM to generate the response in a fixed format along with the chunk IDs. If the LLM has used another chunk for generating the answer but did not list it as a reference, this can happen. Please check if the chunks sent to LLM contain the information that is part of the answer\n\n2. If the LLM response does not follow the format specified it can lead to issues in rendering. You can check the LLM response tab to check that scenario. \n\n3. The LLM could have used multiple chunks to infer some information but only used one of the chunks to actually generate the answer. Eg: Who is the CEO of Apple? \nChunk A: Tim Cook replaced Steve Jobs in 2011\nChunk B: Steve Jobs was the CEO of apple until 2011\n\n4. LLM is generating incorrect citations\n\nFor all of them you will need to fine tune the prompt. \n\n\nCould you please verify which scenario is this? If it isn't any of the above we will have to debug further to find the root cause",
        "I went through the JSON for the second scenario you shared. I can see that the LLM did not find any specific information about the advantage portfolio in the chunks, so it mentioned the same in the response. Additionally, LLM has responded with Risk considerations for a portfolio since this is partially related to the question. \n\nThe information is part of the chunks and the citation is also correct in this scenario"
    ],
    "spaces/AAAABcXBTWI/threads/NrlPkgV7B2M": [
        "Is dev_Chunk_Extraction_Method=layout still a supported Custom Config? \n\nI've followed the steps mentioned here:  Beta Features in SearchAssist \n\n1 PDF uploaded directly. Retrained. No chunks extracted.",
        "@Sathya Priya Turaga please check this. @Sai Dheeraj Arikala for learning",
        "This should work.. Can you send the document? Is it extractable?",
        "@Laurence Schoultz Have you tried REPLY Document for Inpost?",
        "@Laurence Schoultz",
        "Have tried the Reply doc yeah",
        "Could you please add a workbench stage to add a field named \"sys_file_type\" with value as \"pdf\" for all pdf files. then it should work.",
        "Retrain after the changes",
        "We are working on to remove the workbench dependency, as a workaround please configure a field mapping stage in workbench"
    ],
    "spaces/AAAABcXBTWI/threads/AhcG2NHnlbA": [
        "Is the $3,500 data ingestion free one time or annual?",
        "@Aditi Bhadouria @Santhosh Kumar Myadam please confirm",
        "Yes ;-)\n\nIt‚Äôs not ingestion anymore, it‚Äôs storage volume. \n\nThe base package includes 1GB / yr\n\nEach additional GB is $3,500 / yr",
        "1gb of data for $3500? - Does that include anything else other than storage?",
        "Just looking at standard list pricing on AWS website a gb of data (for the first 500 tb) is $.023/ gb",
        "@Richard Passavant",
        "Is that for RAG-based search @Adam Warshaw ? or just general cloud storage in AWS?",
        "I‚Äôll have to let @Aditi Bhadouria explain what‚Äôs included, but I believe that‚Äôs also the ingestion, chunking, etc‚Ä¶\n\nAnd allows for 3x turnover annually",
        "Team, I do need to get back to the customer on what the $3,500 includes.  Can we please get clarification?",
        "For Enterprise edition, is the base storage also 1 GB ?",
        "Yes",
        "@Melissa Prince Will share a detailed writeup in the next few hours. \n\n @Aditi Bhadouria",
        "Thank you!  Appreciate the help!",
        "@Santhosh Kumar Myadam please share the doc with me as well, or here in this Google space.",
        "@Richard Passavant This is 1 gb per license sold, correct?  It cant be that if I as a customer by 1 license for Search AI or buy 1m i get 1 gb . . .",
        "@Santhosh Kumar Myadam can you please share this doc?  I do need to get back to the customer today to breakdown this cost.  This deal is pending for this quarter and it's important we articulate what they are paying for.  Appreciate the help.",
        "I believe it‚Äôs per customer, not related to Sessions - not sure if the customer buys both Automation Enterprise and SearchAI Enterprise if they get 2 GB (1 each)",
        "Not sure that makes much sense - SMB get 1 gb for their 1000 sessions and Apple would get 1 gb for hundreds of millions of sessions purchased.  Probably should rethink this a bit",
        "Essential and Advanced get 100MB / 300MB respectively. \n\nIt‚Äôs not storage for the users, and the number of sessions doesn‚Äôt change the number of source docs. \n\nYou could just as easily have the inverse, an SMB with thousands of documents (say SOP docs from vendors) and an XXL with a hundred standard docs supporting millions of employees. \n\n(note - not defending simply explaining a different position)",
        "@Santhosh Kumar Myadam @Aditi Bhadouria We could really use this document you committed to having several hours ago.",
        "@Santhosh Kumar Myadam ...may I have the document?",
        "Sorry for the delay. Is it okay if we update by tomorrow?\n\nEssentially, there are 2 parts \n\n1 - Indexing cost - This will be based total document size in disk.  This is a per year cost.  SMB SKUS have 100 and 300 builtin. For enterprise, we have to charge based on the anticipated usage. Do note that the 'total size of docs' includes initial sync and sync of any ongoing content refreshes. \n\n2 - usage. This will be based I. The session consumed.",
        "Thanks, @Santhosh Kumar Myadam.  We are selling an Enterprise SKU to a Fortune 500 company with several business units who all have different requirements in terms of documentation.  This could lead to TB's of storage and this fee will far exceed the license cost.  I'm getting a lot of push back on $3,500/year/1 GB.",
        "@Richard Passavant @Santhosh Kumar Myadam can we please get an update on pricing for storage?  I need to get back to the customer.",
        "@Melissa Prince Apologies for the delay. This is the document please go through it and let me know if anything is not clear, will update it if required. Comprehensive Guide to Search AI Pricing Structure",
        "@Peter Wulfraat Chain is here"
    ],
    "spaces/AAAABcXBTWI/threads/G7gw-eemXHU": [
        "one time"
    ],
    "spaces/AAAABcXBTWI/threads/WxBicUo1D6c": [
        "Is caching a feature that will be released in the fall, per this slide, or is it a custom PS effort? Our client Columbia Sportswear is asking (cc @Kevin Mullay )",
        "Yes, it will be inbuilt feature, planned for Oct'24 as of now. Note that this will still go to LLM for the first time and every similar query from next time will be responded from the cache. No coding required by the PS team. Only configuration changes."
    ],
    "spaces/AAAABcXBTWI/threads/pEHGWhy0t0A": [
        "Thanks for the quick reply @Girish Ahankari.  And when you reference LLM, my sense is that OpenAI is highly recommended but XO GPT could be sufficient depending on customer requirements.",
        "Yes, LLM could be OpenAI, Claude etc. XOGPT Answers is being planned for Sept/Oct but initially it will be only for English language."
    ],
    "spaces/AAAABcXBTWI/threads/Ra9-5ZmxE08": [
        "Can we perform additional authentication? For example, some of the help documentation and access require a unique login that is not tied to the initial login to the web portal. Is it possible to ask for authentication if a user‚Äôs question requires additional authentication?",
        "@Andy Pham \n\nIt is not possible via Search AI\n\nHowever, what criteria determines that additional authentication is required?",
        "The document the user tries to access."
    ],
    "spaces/AAAABcXBTWI/threads/bWeD04p3jzg": [
        "This document details the pricing structure of Search AI for everyone's reference. Please go through it and let me know if you have any questions. https://docs.google.com/document/d/1zXB3VpDcLZabpj6y9fI8VQOeH0V7-2ZDpbLVyFH0mS0/edit",
        "Thank you @Aditi Bhadouria - Has anyone done the math on our own content?  What if Kore wanted to deploy SearchAI for our customers to leverage in finding product documentation?  What would this cost from a storage perspective?"
    ],
    "spaces/AAAABcXBTWI/threads/9PU26RCUoMw": [
        "I crawled our documentation https://docs.kore.ai/xo/home/\n\nThis resulted in around ~400 MB of data being ingested. This is for 1371 webpages. Since this is documentation, there is a lot of text available to ingest. Other websites will generally be of lesser size",
        "Right but thats sites, what about physical documents?",
        "PDF, excel, etc",
        "For physical documents, it is the size of the documents on disk."
    ],
    "spaces/AAAABcXBTWI/threads/EE8s0uC6Xvg": [
        "If we are ingesting say 500 articles via a SNOW connector and are using filters to index only a portion of them, what is the best way to confirm how many articles has the content been indexed (chunks created) from? @Bharat Rekha",
        "Hi @Navdeep Grover,\n\nThis is not supported today. Any modifications made in the workbench to exclude a document are not directly visible in the sources. As @Shantanu Ghorai mentioned, this can be verified in the chunk browser.\n\nIn XO11 we enhancing this experience introducing the document browser along with chunk browser, this scenario can be covered here. \n\n CC: @Aditi Bhadouria,  @Santhosh Kumar Myadam"
    ],
    "spaces/AAAABcXBTWI/threads/i4DsXKtDxhM": [
        "@Navdeep Grover if you have written exclusion workbench stage, in the chunk browser you can search for those documents to ensure there are no chunks from excluded document",
        "Thanks @Shantanu Ghorai ! I know thats possible however the prospect wants to know the count of the docs from where the content is indexed or chunks are created. To put it into a perspective, we've ingested around 560 articles from SNOW, and are using a Workbench stage with filters. They want to ensure that the content is only ingested from 117 articles and wanted to confirm this count in SearchAI."
    ],
    "spaces/AAAABcXBTWI/threads/wapwI_kf-4k": [
        "Team - Is it true that we can now use XOGTP on xo11's SearchAI to generate answers? I saw that I was able to select XOGTP. What model is under the hood that is generating answers? What are the limitations compared to a commercial mode such as GTP-4o?",
        "@Ravi Rachannavar @Santhosh Kumar Myadam   please share the xo gpt answers model documentation . @Aditi Bhadouria we need to publish a summarize version of it in our docs and have the detailed version shareable to SEs and customers",
        "@Gurpreet Singh \n\nHere is the XO GPT model documentation:\n\n Kore.ai - XO GPT - Answer Generation Model",
        "Thank you üôè"
    ],
    "spaces/AAAABcXBTWI/threads/TtgqZhsDTQo": [
        "@Gurpreet Singh Were you able to learn anything further off-line?"
    ],
    "spaces/AAAABcXBTWI/threads/Z6xejp6hk6A": [
        "@Girish Ahankari @Aditi Bhadouria Here are the SearchAssist specifications for CBRE‚Äôs initial phase. Would we encounter issues supporting 72GB with an average file size of 2MB on the SaaS environment? Also, when will CSV, PNG, and JPEG formats be supported? cc: @Melissa Prince",
        "@Andy Pham \n\nIs it about presenting png/jpeg as part of responses or is it about extracting content from png/jpeg and used that for answering? Or, is it both?\n\nAlso, there is a change in the way we should calculate price for enterprise SKU for SearchAssist. Can I assume that it is factored into the overall quote? \n\n Comprehensive Guide to Search AI Pricing Structure",
        "Extracting content and use that for answering",
        "@Santhosh Kumar Myadam we need to know if we can support this file size.  Please let us know",
        "- CSV, PNG, JPEG Q4 2024\n- RACL for sharepoint will be released this weekend",
        "For the content ingestion limit question, are they going to use on-prem, VPC, or cloud?",
        "Cloud",
        "I‚Äôll check and get back to you",
        "Please get back us as soon as you can.  The prospect needs a straight answer for us on what our limitation are and is getting very frustrated.",
        "Yes we can support it @Melissa Prince",
        "Thank you for confirming @Aditi Bhadouria.  @Andy Pham",
        "@Melissa Prince @Andy Pham \n\nIs it possible to get a few files from the customers where they are expecting to answer from CSV, PNG, JPEG etc. \n\nCSV extraction is generally straight forward but we have to ve careful about the kind of questions that they are expecting us to answer. For e.g., from 'order details' csv, are they going to ask questions like   what is the average deal size per year? \n\nPNG, JPEG will have challenges in extracting the content correctly. Answering from extracted content may also have certain challenges. \n\nWe need to understand the requirement in more detail before setting the expectation with the customer that we will fully support CSV, JPEG and PNG. \n\nPls help with the sample files and the kind of questions they are going to ask. Without this assessment, this can become a blocker during implementation stage. \n\n @Aditi Bhadouria  @Girish Ahankari",
        "For JPEG, PNG files, are they ok to use commercial LLMs ? The newer models have very good capabilities to extract. It‚Äôs matter of writing a custom extractor/ connector for this type of files outside the platform and ingest the output into the platform @Santhosh Kumar Myadam",
        "@Prasanna Arikala @Santhosh Kumar Myadam They are using Azure OpenAI."
    ],
    "spaces/AAAABcXBTWI/threads/_ZjZlvJMhY0": [
        "I am getting an internal server error when using the SharePoint connection in the v11 environment.",
        "Hi @Andy Pham, \nIs the authorization successful?",
        "Yes! Also, I have no issue using SearchAssist. This only happens when I use v11.",
        "Got it. Is it failing post authorization and the immediate screen or at sync?",
        "I got the error when I clicked on Select Content.",
        "Can you double check if the credentials are correct once? \nAnyway, I will have this checked on Monday IST as a first item. \n\n@Mani Kumar Nadella - please check this.",
        "The credential is correct. Also, the status is connected."
    ],
    "spaces/AAAABcXBTWI/threads/gEV7A0Mhv6E": [
        "Is docx supported? It is not listed at the bottom. Also, I tried, and it didn‚Äôt recognize the docx document.",
        "We could see a defect with docx files not getting recognised. This has been identified already."
    ],
    "spaces/AAAABcXBTWI/threads/21CRQgWSvsk": [
        "RE: Search AI \nI spent many hours today on something I thought would be simple, but without success. First, I couldn‚Äôt crawl the prospect‚Äôs FAQ website due to an SSL error. Asking the prospect to enable deprecated TLS versions as a workaround isn‚Äôt reasonable. So, I saved the site as a PDF, but the chunking looked strange, and I couldn‚Äôt search for any answers. I even tried copying and pasting each FAQ question and saving it as a docx and PDF document, but that didn‚Äôt work either. I finally gave up and went back to SearchAssist, and it worked on the first try using the same PDF file with SharePoint integration.",
        "Thanks @Andy Pham for the feedback\n\n1. @Bharat Rekha @Parth Sureshchandra Suthar check why we are using depreciated TLS. We might have to support both latest TLS and deprecated.\n2. @Venkata Naresh Divi please check the chunking issue with PDF"
    ],
    "spaces/AAAABcXBTWI/threads/RX1U2mvbE7w": [
        "How can I make the bot response \"I cannot find the answer. Please reach out to our support team\" if nothing is returned from the LLM (ie Used for Answer = 0). Our prospect does not want to show the Files. I guess it may need to change the prompt but any suggestion / recommendation is appreciated.",
        "@Sunny Lun Please update the prompt, that will address this scenario",
        "any example ?",
        "@Aditi Bhadouria",
        "There is a section in the prompt that instructs the LLM to respond with \"I don't know\". You just need to replace this with the sentence of your choice. https://docs.kore.ai/searchassist/concepts/personalizing-results/generative-model/#Guidelines_for_Prompt_Customization"
    ],
    "spaces/AAAABcXBTWI/threads/lMDe5irbg34": [
        "Another question, in the past, if I asked a question in non-English (eg Japanese), the SearchAssist will translate to English internally and matches the chunk, send to LLM to generate the GenAI answer. The answer will be in that language (Japanese). I found the response is in English now instead of Japanese. Is there something changed?",
        "@Sunny Lun SearchAssist/Search AI standalone does not support translation OOTB. If you want you could take advantage of the translation capabilities offered by XO Platform. \n\nPlease refer documentation to understand how multilingual search works in more detail. https://docs.kore.ai/searchassist/manage-indices/index-languages/\n\nThe language the response is generated in depends on the prompt. Please read this to understand this in more detail https://docs.kore.ai/searchassist/concepts/personalizing-results/generative-model/#Multilingual_Support_for_Generative_Snippets"
    ],
    "spaces/AAAABcXBTWI/threads/7MtC8sJiIvU": [
        "@Aditi Bhadouria , will SearchAI in v11 have facets, interface options(Search bar, chatbot) just like SearchAssist? Thanks",
        "@Sandeep Singh Rana Yes it is part of our backlog, we don't have a definite ETA yet",
        "@Aditi Bhadouria , thank you! this feature(Web Search UI, facets) is currently used by our customers and they like it in future to move them from v10 to v11 this will be important.",
        "@Sandeep Singh Rana May I know the customers who are using facets? Will help in better planning while moving to XO11",
        "@Santhosh Kumar Myadam , NSSOL and few other are using facets. Even a prospect(Daiwa Securities) introduced by NSSOL  wants to use facets and Search UI. Facets and Search UI is very similar to other search products in the local markets."
    ],
    "spaces/AAAABcXBTWI/threads/J1KLGGnArr0": [
        "do we have any plans to support Chinese as an index language in SearchAssist?"
    ],
    "spaces/AAAABcXBTWI/threads/bxLK5iQ6NKQ": [
        "@Sunny Lun yes we do, however its lower in priority as of now as there are no customers in pipeline",
        "@Rakesh Bathini ... fyi",
        "Assuming, this is around ingesting the documents in Chinese language and facilitating search for everything - Search Results, Extractive Snippets as well as Answer Snippets (this can anyways be supported via LLM) in Chinese - how much of the lead time is needed to enable Chinese language? Mars, whom we just had a session, asked it."
    ],
    "spaces/AAAABcXBTWI/threads/suHAYu2x-Ts": [
        "do we have any searchassist instance in Australia AWS?",
        "@Sunny Lun SearchAssist is not yet available in AU region\n\n  @Bharat Rekha",
        "Thanks @Santhosh Kumar Myadam what do we require to stand up an instance in Australia? We are currently scoping an SOW for this and requirement may likely be to host in AU",
        "Why can‚Äôt they use the public SaaS instance ?",
        "This is a lot of investment. Both infrastructure and people",
        "Thanks @Prasanna Arikala in the SOW we are specifying SaaS and not constraining to AU. I had understood that the AU instance(s) are still public SaaS... just provisioned within AWS ap-southeast-2 for data residency requirements",
        "@Richard Oldham Prasanna meant US deployment of our SaaS when he quoted public SaaS"
    ],
    "spaces/AAAABcXBTWI/threads/LsnJ7t3NYk8": [
        "I have a SearchAI POC for Southwire via partner Pronix that is not returning results (XO11).  I'm getting: \n\"generativeChunksCount\": 21,\n    \"retrieverUsed\": \"vector_search\",\n    \"extractiveChunks\": [],\n    \"chunksSentToLLM\": 0,\n    \"chunksUsedInAnswer\": 0",
        "@Tim Burke looks like the chunks are not qualifying. Please use hybrid search and play around with the threshold",
        "That got me some different results but no answer: \n\"answeredBy\": \"generative_model\",\n    \"extractiveChunks\": [],\n    \"chunksSentToLLM\": 5,\n    \"chunksUsedInAnswer\": 0",
        "@Tim Burke Lets connect once."
    ],
    "spaces/AAAABcXBTWI/threads/Awnefk5rG9w": [
        "I have a retail prospect who wants to search for products and product information across 3 different facets. The search results will be displayed with product images (carousel, list or grid). Is there also a way to identify the facet associated with each search result by displaying an additional \"facet\" image with the result?",
        "@Michelle Winston Lets connect. We have a lot of what you are asking for in Retail Assist Product Search and Search.AI combined."
    ],
    "spaces/AAAABcXBTWI/threads/k01aehuCZ3Q": [
        "Can this SearchAI roadmap deck be shared with a prospect (will convert into .pdf)?  @Aditi Bhadouria @Bharat Rekha Search AI - Product Roadmap - Updated August",
        "@Navdeep Grover \n\nWe are in the middle of relooking at the timelines for some of the items in this presentation. We are also going to add a few more items. \n\nIf it is urgent, pls make a copy and move all the dates by a quarter before sharing."
    ],
    "spaces/AAAABcXBTWI/threads/eisfjXlsEto": [
        "Another Q. - Is there any way, to achieve all the above via documents ingested in English i.e. end users asks Qs. in Chinese language and see Search Results, Extractive Snippets along with the document translated to Chinese too (silly Q. still wanted to check) when they click / open the source link? Here's the challenge - Mars have a large corpus of content in English and they want to support end user queries in 34 languages. Translating these docs is an enormous task and they're looking for ideas to best achieve the above ask easily. May be we can position GALE (they are a  Microsoft shop and should be open for LLMs). @Girish Ahankari",
        "To add support for a language and perform testing end to end it would take 1 release cycle, i.e a month to enable a new language. \n\nPlease note this highly depends on the type of language, if the request is to add a language that is less widely used it would take more time to enable it. \n\nAdditionally the above estimate is only for development, testing and release. It does not take into account existing commitments and roadmap items, based on which the actual ETA would differ.",
        "Thanks @Aditi Bhadouria Its for Chinese, as mentioned in my Q.",
        "@Corey Erkes @Robert Villacis ^^ for Mars SearchAI standalone"
    ],
    "spaces/AAAABcXBTWI/threads/jy371tayIg8": [
        "Can XO 10 Search Assist use XO GPT for summarization?\n\nI see it natively available in XO 11 but not in XO 10.",
        "@Jon McCain \n\nYes, it is available on demand. \n\nCan be enabled for specific customers on need basis.",
        "@Dalton Trout ^^ See Above ^^",
        "That's great @Santhosh Kumar Myadam. Thank you so much.",
        "@Matt Panaccione  @Kevin Mullay  @John Brandes \n\n @Santhosh Kumar Myadam we need to understand how XO GPT compares to Azure OpenAI for Summarization and Generation from Chunks?\n\nWe just built out a Proof of Technology using OpenAI... But, the CIO is wanting to make sure a strategy is in place to lessen the usage of those commercial models with either our XO GPT AND Caching... which I don't believe we have available as an out of the box feature yet, right?\n\nWhat are the steps to enable XO GPT enabled for the space we built this POT in so we can compare results.",
        "@Jon McCain \n\nXO GPT - Can be enabled for specific customers in standalone SearchAssist. Please send an email to take this forward\nComparison of XO GPT performance against OpenAI - There are various dimensions to be considered to define 'comparison' and 'benchmark/. We recently created a document that explains the full XO-GPT framework for Answer Generation model. Here it is: https://docs.google.com/document/d/1Ek-BQCWCMYG7MnSA4h4c6CfqEW2xdbusfpqHAC1JJFA/edit?tab=t.0#heading=h.jmtdqob0nzbv\nCaching - It is not yet available out of the box. With some set up effort, customers can implement the flow.",
        "We were planning to release XO GPT for answers for Shell in DE region. Is that thread still active? @Komal Joshi @Santhosh Kumar Myadam @Girish Ahankari"
    ],
    "spaces/AAAABcXBTWI/threads/C0WhK2iaFv8": [
        "We have a question from  a Credit union customer/partner:\n\nCan our Search Assist Bot integrate Out of the Box with Microsoft Dynamics CRM?",
        "@Jordan Bostick",
        "@Rohini Lingambhotla We don‚Äôt have Microsoft Dynamics CRM part of our connector roadmap, I can add it to the backlog. \n\nCould you detail the use case for the same? What type of content are we looking to ingest? Is it structured or unstructured?\n\nPlease note: Custom connector will be made available in September. This can also be used to connect to any connector in case Microsoft Dynamics CRM is not prioritized in the near future.",
        "Thank you @Aditi Bhadouria i will get back with the details."
    ],
    "spaces/AAAABcXBTWI/threads/F3b6tcSlL9A": [
        "To achieve this following approach can be explored. \n\n1. Ingest documents in English and set up the search app\n2. Set up a XO bot and link it to Search AI\n3. Set up language rules and translation in the XO bot. \n4. For every end-user query, XO will identify the language and translate it into English. This english query then should be fed to Search via the Advanced Search API. \n5. For the answer returned by Search AI, XO can then again translate it to the correct language and return it to the user. \n\nThis would only cover the answer generation part, though. The documents and, hence, citations will continue to be in English. If the user wants to generate the documents in 34 languages, that is something that has to be handled outside of the product. \n\nWe are working on an approach to handle similar multi-lingual scenarios OOTB. We will keep you posted on the development. \n\n @Nimisha Joseph"
    ],
    "spaces/AAAABcXBTWI/threads/lroL_i25DwM": [
        "Is there a recommended video demo for Search that sales can share with a prospect ahead of next meeting?  A prospect is asking to see something.  Thanks.",
        "There are some videos in here: https://kore.seismic.com/app/#/collection/detail/2bddf01c-9c47-40c8-9df3-0816137e984e?mode=view&search=%257B%2522keyword%2522%253A%2522%2522%252C%2522properties%2522%253A%255B%255D%257D"
    ],
    "spaces/AAAABcXBTWI/threads/zcO9RKiZDm0": [
        "Can we use Search Assist as Product Advisor, Customer will provide Structured data of their products and its details. Through XO can we look for SearchAssist to respond with products based on User request. Also Do we need LLM for this search? if not then what extra we can achieve with LLM. If you have use case or Demo please share",
        "Is the customer looking for new products or support on existing products?\n\nSearching for new products based on requirements sounds more like a RetailAssist use case than Search AI\n\nWe did this with LG",
        "It is for new product. Also they are existing customer, bot developed on standard Bot. Currently they are doing the search through their algorithm where we call their API and based on response showing the products. They are checking if their ask is doable through SearchAssist which needs less changes rather moving to retail assist.",
        "@Richard Passavant Please share LG use case document if you have.",
        "@Tim Loewenstein Is your guy for RetailAssist, agree with Richard - likely more of a RetailAssist type of solution.",
        "@Pankaj Sharma I have setup a call to discuss. Product Advisor aka product search is a combination of product search and document search.  I can address your questions.",
        "Sure, Thanks @Tim Loewenstein",
        "@Pankaj Sharma was this for Pandora? Did @Tim Loewenstein review the CSV Pandora submitted?",
        "Yes @Laurence Schoultz . I believe csv not being reviewed yet.",
        "We're discussing this in the meeting right now.",
        "I am on a train right now, can‚Äôt join. Can you get the Search team to review. From my understanding it would require manual workbench configuration to extract the csv values into search index fields."
    ],
    "spaces/AAAABcXBTWI/threads/sPWAFMXOars": [
        "@Aditi Bhadouria where can I find the Search ID in v11 SearchAI? I need to call the Search API for integration from other apps. FYI, i captured the Search ID that I referred to in v10 as below",
        "@Sunny Lun Could you describe the use case a bit more? Currently we don't have search ID visible in XO 11, I can probably find an alternate solution for it. \n\nFor integration via API, the stream ID/ app ID should be enough, which is visible in the App settings> Dev Tools.",
        "@Aditi Bhadouria . i need to create a dialog task to support the translation and rephrase the queries of the users based on some logic. After that, I will send the query to the SearchAI. In v11, when I asked a question, it will be picked by the SearchAI to answer it and I have no way to modify the question and pass to the SearchAI.",
        "@Sunny Lun for now, we cannot view the search id in the app but from the network tab under dev console of the browser, there is a way. Access the dev console, clear the logs and click on any button within search ai (probably websites or document), and then on the network logs window once they are loaded, click on a resouce probably a list resource and within Preview, if you choose the drop down, you should be able to find the search id or sidx.",
        "@Sunny Lun you don't need the search ID to accomplish this. You can explore following options \na) Use the search node and configure the input as well as response configurations \nb) Use a service node to call the advanced search API. (In case the bot and search AI content are in different apps) similarly input the translated query in the API",
        "https://docs.kore.ai/xo/automation/use-cases/dialogs/node-types/working-with-the-searchai-node/"
    ],
    "spaces/AAAABcXBTWI/threads/Jz2Olyyg_Zc": [
        "Team - I have a client that wants to know if we can use their own middleware API gateway to do the following with SearchAI:\n\n1) Leverage their own vector database for chunking and chunk retrieval\n\n2) Leverage an LLM for answer generation (using the retrieved chunks)",
        "@Gurpreet Singh could you elaborate the use case a bit more? \n\nIf I understood correctly, the client wants to ingest data via Search AI, but extract and index separately? Search AI would then come into play for retrieval only? Is there any specific reason they want to chunk and index the content outside of Search AI? \n\nAnswering the questions below\n\n1. Currently, this is not possible. The database is not configurable. Using custom extraction could be achieved via structured data but would require an external utility. \n\n2. Yes this is currently possible via the advanced search API, or the custom LLM integration.",
        "Thanks Aditi. What if the customer wanted to bring their own vector db, already chunked only to use for retrieval? Is there any scenario where we can allow customers to use their own vector database?",
        "@Aditi Bhadouria",
        "@Gurpreet Singh \n\nWe did see similar request before but there wasn't much traction after that. \n\nIt can be a roadmap item. \n\nMay I know what is the use case for the customer to bring their own vector DB?",
        "@Santhosh Kumar Myadam @Gurpreet Singh @Aditi Bhadouria I had a meeting with Bouygues Telecom on Wednesday, they've also asked when we'll have this capability. \n\nCC:  @Marenza Douglas",
        "@Laurence Schoultz May I know the use case for this?",
        "They have their own postgre vector store database hosted on AWS RDS holding chunked and indexed knowledge."
    ],
    "spaces/AAAABcXBTWI/threads/NK3rqpm_lfE": [
        "Team, do we have documentation that outlines the differences between SearchAssist v10 and SearchAI v11? It would be helpful to clearly understand what features will be missing in v11 when customers migrate from v10.",
        "Here is the sheet shared earlier \n\nhttps://docs.google.com/spreadsheets/d/1pQXarKUGs3X2hnqYsvfTF966naEUbcwVg-G6dSl95W0/edit?gid=1090277526#gid=1090277526\n\nPlease note that this is a running document and should NOT shared with any external parties. You may use this data for internal evaluation purposes.",
        "@Aditi Bhadouria , thank you and understood that its internal only.",
        "@Aditi Bhadouria let's add this document to Seismic as well"
    ],
    "spaces/AAAABcXBTWI/threads/u2uimzbiUR4": [
        "how can i change the Proximity Threshold ?"
    ],
    "spaces/AAAABcXBTWI/threads/0gU7TARvHY4": [
        "it is disabled"
    ],
    "spaces/AAAABcXBTWI/threads/0EDrD7P26vM": [
        "Please enable it to edit the settings",
        "Is this option only for Vector Retrieval but not Hybrid Retrieval ?",
        "It's for both",
        "oh.. my resolution is not high enough and can't find the switch before. I got it now. than kyou"
    ],
    "spaces/AAAABcXBTWI/threads/94998fnmsrw": [
        "@all - do we have a few numbers from customers on the impact of using SearchAI/Answers in terms of time saved maintaining KG, amount of data that was made available etc.\nBelow is what I am thinking: \nhttps://docs.google.com/presentation/d/1EXZMwvFKq9pzbHJZvC6TbzE9VS0ZCPdDgjxYEegUtS8/edit#slide=id.p",
        "@Josh Porter \n\nThis will be a very helpful asset to create.",
        "@Kyle Rogers similar to what you were looking for.",
        "Yes, @Amit Baweja"
    ],
    "spaces/AAAABcXBTWI/threads/HhR4ryj5MQQ": [
        "Team, the response generated from the structured data in Arabic is missing some information, even though the answer is complete in the corresponding chunk. Do you know how I can adjust the search results to display the full description in the JSON format (Highlighted in Yellow)? Two additional lines at the end of the description are not being displayed in the generated response",
        "Hi @Zaher Awada \n\nI couldn't understand what exactly you are looking for. Could you also share a screenshot of the end user experience and what is missing there?",
        "Hi @Aditi Bhadouria, As discussed in our email, I converted a few Arabic data files into structured data in JSON format. However, the two lines highlighted in green in the content of the structured data are missing from the response generated for the end user. The requirement is to display the full content. Attached screenshots for more details",
        "@Zaher Awada Please use this configuration https://docs.kore.ai/searchassist/configuration/custom-configurations/#Response_Size",
        "By default for extractive answers the response length is set to 150 characters, that might be the cause",
        "Thanks @Aditi Bhadouria ,I was looking for a way to increase the token length. I have one more question: I manually created structured data for a few files for testing purposes. However, the customer has shared 10,000 text files in arabic for the POC. Is there a way to manually create structured data in bulk? If not, what is the best approach to upload these files into SearchAssist?",
        "You can use the public API to ingest the content. Please refer this for more details https://docs.kore.ai/searchassist/public-apis/searchassist-apis-list/#Ingest_Data_API"
    ],
    "spaces/AAAABcXBTWI/threads/FB_2xoblWb4": [
        "@Santhosh Kumar Myadam \nCan Search AI respond to questions outside the knowledge we feed it if were using XO GPT.\n\nIf I ask it how to do a VLOOKUP, what is the weather today, etc. Can it engage those topics?\n\nI know we can implement a commercial model but the customer is looking for cost savings here and XO GPT is (included)",
        "@Jon McCain \n\nXO-GPT Models are meant only for specific conversational AI use cases, for e.g., answer generation. \n\nWe do not intend to expose them for any other general topics.",
        "@Santhosh Kumar Myadam XO GPT was planned to be the default for answers as well in the future, right?",
        "Thank you @Santhosh Kumar Myadam"
    ],
    "spaces/AAAABcXBTWI/threads/tKq6-Y5IQg8": [
        "@Aditi Bhadouria can you please share the curl that is being used for ServiceNow connector - we may have to write a custom connector for BSMH and need help with the table apis which we are invoking for ServiceNow.",
        "@Venkata Naresh Divi Could you please help here and share any dev documentation we have?",
        "Hi @Shantanu Ghorai, sorry for the late reply\n\ncurl --location 'https://<SERVICENOW_ACCOUNT_ID>/api/now/table/<TABLE_NAME>?sysparm_limit=1&sysparm_offset=100&sysparm_query=ORDERBYsys_created_on' \\\n--header 'Authorization: Bearer <BEARER_TOKEN>'",
        "This is the curl for fetching data from any table from ServiceNow Connector.\n\nPlease check and let me know if any help is needed"
    ],
    "spaces/AAAABcXBTWI/threads/GuS44JsLgek": [
        "Structured Data XO11 SearchAI\n\nTeam, this document suggests structured data will be available as a source in September. Are we on course to deliver this by end of month?  [Strictly for Internal] Feature Parity and Availability - SearchAssist (Standalone/X10) vs. Search AI (XO11)",
        "@Bharat Rekha can you provide any input here?",
        "Hi @Laurence Schoultz, \n\nPart of this feature is being released in September, allowing you to upload the JSON via the interface. The public API will be available in October."
    ],
    "spaces/AAAABcXBTWI/threads/bpz78rGnCxI": [
        "Does Search AI support custom LLM models?",
        "Yes. https://docs.kore.ai/searchassist/concepts/managing-indices/custom-llm-prompts/"
    ],
    "spaces/AAAABcXBTWI/threads/U9VA5rGBpR4": [
        "that is SearchAssist"
    ],
    "spaces/AAAABcXBTWI/threads/4F32RofqUk4": [
        "Search AI in XO11",
        "Yes, we do support\n\nPlease refer to the table here:\n\nhttps://docs.kore.ai/xo/generative-ai-tools/dynamic-conversations-features/#__tabbed_1_2",
        "thank you"
    ],
    "spaces/AAAABcXBTWI/threads/ETOdkjM0IGs": [
        "I am not able to paginate files that I have uploaded:\n\nhttps://app.screencast.com/HxD9IDXB4y7ly",
        "@Vaishali Addala Please analyze this.",
        "Sure @Santhosh Kumar Myadam"
    ],
    "spaces/AAAABcXBTWI/threads/xCebIhGyqfU": [
        "The search results, accuracy, and presentations using the bot versus Search AI Test Answers are very different. Here is an example. What adjustments are available to resolve this issue?",
        "@Colin Federle",
        "@Andy Pham The template differences are just in the application. Currently this can not be configured. The template you see in test bot is the one users will see for SDK channel. For Teams and Slack there is a pre-configured template, other channels will have a plain text template.",
        "But the accuracy should not be different. You should get the same accuracy in Test Search AI and Test bot, assuming that there hasn't been any changes in the sources and configurations when it was tested. \nCould you please confirm if the difference is due to LLM response or the qualified chunks itself are different?"
    ],
    "spaces/AAAABcXBTWI/threads/smm2eE-aK3Y": [
        "Team, does the ServiceNow connector periodically crawl and update the KB data, or does it only respond based on the data fetched during the initial setup when the connector was enabled?\n\nThis question arises because, unlike the SharePoint connector, which includes a scheduling feature, the ServiceNow connector appears to lack this functionality.",
        "I see the configuration in the XO 11 platform for the SNOW Connector:",
        "Hi @David Gwartney , thanks I see v11 is having this feature but Searchassit on v10 doesnt. Thanks for sharing",
        "@Sandeep Singh Rana SearchAssist and XO 11 both have this feature available for all connectors.  Please check"
    ],
    "spaces/AAAABcXBTWI/threads/3JrwH_57aqY": [
        "Client: Frontier Communication - Search AI PoC Issue - Assistance Required\nWe have provided a XO 11 instance for the client's PoC on Search AI, utilizing Kore XO GPT to generate answers. We ingested content from their website (https://frontier.com/helpcenter/), fully incorporating their help center, and can confirm that the content is visible in the chunk browse.\nHere is the document detailing the Search AI configuration: Search AI Configuration.\nIssue: The client has reported that several Search queries are not returning results when they ask specific FAQ questions listed on their help center website.\nCould we get assistance in investigating this?  @Aditi Bhadouria",
        "Team, despite extensive fine-tuning and effort over the past month, we are still encountering suboptimal results which have become a significant concern for Frontier.  It is crucial that these issues are resolved as soon as possible, as we have a Q3 deal in progress and a successful POC would allow us to secure this budget from the incumbent for the upcoming year."
    ],
    "spaces/AAAABcXBTWI/threads/0ccVevqLP6g": [
        "I am in the process of setting up another trial for a prospect who has requested the ingestion of many files, primarily scanned PDFs and DOC files. Are we planning to support DOC files? Regarding the scanned PDF documents, I have enabled the layout-aware extraction strategy; however, it has not yielded the desired results.\nBesides converting doc files to PDFs, I would greatly appreciate your thoughts or feedback on these challenges.  @Aditi Bhadouria",
        "@J.D. Maloney"
    ],
    "spaces/AAAABcXBTWI/threads/dvevTYZzHZo": [
        "@Girish Ahankari @Santhosh Kumar Myadam @Corey Erkes"
    ],
    "spaces/AAAABcXBTWI/threads/zMq5UR7qSsU": [
        "@Raman Srinivasan @Melissa Prince \n\nMay I know which fine-tuning is referring to? I see that they are using XO-GPT Model. Are they using fine-tuned embeddings? \n\nAlso, do we know if the issue is primarily in retrieval or answer generation. \n\nIf it is retrieval, please try the newly introduced BG M3 embeddings for indexing, expected to give better performance. \n\nIf it is answer generation by XO-GPT model, please share at least 10-15 results (user input, qualified chunks and answer). We will look into further optimizing the answer generation model. We do have a better version of this already in progress.   @Ravi Rachannavar",
        "@Santhosh Kumar Myadam -\nThanks for your attention to this request \n\nFor the Frontier POC, they are not using any fine-tuned embeddings, instead we have configured using Kore XO GPT - MPNet Embeddings ( which is the default). \n\nAll that they want us to do is to webcrawl their helpcenter pages and answer from the content. \n\nThe issue seems to be specific to FAQs. I dont see any FAQs from their websites are crawled/ingested.  Could there be any specific reason why FAQs on their websites are skipped?",
        "Hi @Raman Srinivasan, \n\nWe have released BGE-M3 recently, all new apps are using this embedding model. To enable BGE-m3 please set below custom config and retrain the application. \n\ndev_embedding_model: bge\n\nPlease share the results post this change. Also please create a ticket for  better tracking purposes.",
        "Thank you. Will make the changes, test it in the morning and let you know.",
        "@Raman Srinivasan the custom configuration is applicable for SearchAssist. For XO 11 please go to Gen AI tools and select BGE model for the vector generation feature, or you can also select it in Vector Configuration under Search AI.",
        "Thank you @Aditi Bhadouria \nyes i found it under Vector Model and have selected \"Kore XO GPT - BGE - M3 Embeddings\" and have initiated \"training\".",
        "Please conduct RCA and see if the issue is with the chunks extracted, retrieval or LLM. Based on which you can change the extraction settings or/and vector configurations. Additionally please use Hybrid retrieval if not being used already",
        "also have initiated the webcrawl post my changes.. \nSure I will test it and let you know on my findings",
        "@Santhosh Kumar Myadam @Aditi Bhadouria \nAfter doing the suggested configuration changes, same issue still persists\na) FAQs from the websites are not crawled (no chunks)\nb) The number of pages in under Websites shows 240/1247; where-as when i open the details it shows 2082\nc) Extrative answers - The chunk presented under \"Test Ansewrs\" are not matching the right chunks. It is showing incorrect chunks\nd) Generative Answers - The answers are not generating for the same query that shows output when tested with \"Extractiive answers\" (screen show below)",
        "@Aditi Bhadouria Thank you for taking the time to join our meeting. Together we reviewed all the configurations, tested a few queries, and demonstrated the issue we're encountering. I've invited you to the platform so you can take a closer look. We‚Äôll reconnect on Monday to discuss any findings from your side."
    ],
    "spaces/AAAABcXBTWI/threads/xMioDPNl2dc": [
        "@Melissa Prince @Ramesh Srinivasan these statements are very generic. \nplease share the \n1. Ticket details which were raised for this.\n2. Solution architecture document eliciting the requirements, solution design\n3. Share the test cases prepared for testing\n4. What finetuning was done? Share the documentation on this.",
        "@Raman Srinivasan"
    ],
    "spaces/AAAABcXBTWI/threads/Feph_bBAGPs": [
        "Team , can answers in SearchAssist documents be highlighted when using the GenAI extractive model? Also, is there a way to translate an HR document processed in Arabic into English when providing answers, with a link to the translated document? I understand that highlighting the answer is currently not supported if the answer snippet is generated by the generative AI model",
        "Translation is not possible and is not in the roadmap"
    ],
    "spaces/AAAABcXBTWI/threads/uMtVrLLAlaA": [
        "What would be the reason for getting these odd responses.  Two different responses to the same question.  Each with \"Some relevant answer\" but the first one (below) at least has some chunk responses included.  My second query did not.",
        "The second query:",
        "and the second attempt at the query had only two chunks versus the three original.  This was only a minute later, with no settings changes to Search Assist.",
        "@Tim Burke surprising . In the second attempt the top result from the first attempt is missing",
        "Can you share the app with One of us to debug?",
        "Hi  @Girish Ahankari,\n \n@Hari Guptha Anbalagan / @Navya Sree Aluri Can help on this if required. @Tim Burke please share the app.",
        "Will do.  Thanks.  It was a quick demo to BCBS of KC to be used in a call today 3pm EST.  I can simply avoid this question during the demo call, but it might be good for us to look at why this happens.",
        "Shared with Hari and Navya"
    ],
    "spaces/AAAABcXBTWI/threads/l-gkuOdJXuo": [
        "Hi @Tim Burke, we have added some custom configurations to enhance the answer quality. Please check it once and let me know how it performs. If needed, we can tweak the configuration for better results"
    ],
    "spaces/AAAABcXBTWI/threads/4akIr0grg24": [
        "Great!  Thank you for the assistance."
    ],
    "spaces/AAAABcXBTWI/threads/WR0viC7yhQo": [
        "@Hari Guptha Anbalagan can you document what changes you did? Is this recommendation already available in any of our Docs or blogs?",
        "Hi @Girish Ahankari \n\nI am not sure about the configurations we have added for Tim, but the documentation for custom configurations is available here https://docs.kore.ai/searchassist/configuration/custom-configurations/  \n @Hari Guptha Anbalagan please let me know if the documentation needs to be updated",
        "Hi @Girish Ahankari, we have implemented the custom configurations from the document Aditi shared, we have used Rerank Chunks, Chunk Retrieval Strategy, and Chunk Token Size config to enhance retrieval and answer quality. Additionally, we have reduced the Similarity Score to 30 to address chunk qualification issues",
        "@Matt Panaccione ^^. This is the config changes the Search team made that may help your project too.  I still get a few differences between responses to the same query but they are minor in terms of a demo or POC.",
        "thanks for this, I was going to ask for what customization was added as it may be relevant to other demos",
        "@Karthik Challa ^^"
    ],
    "spaces/AAAABcXBTWI/threads/qRFX-dZYQoY": [
        "@Gaurav Mathur you can ask your search questions here."
    ],
    "spaces/AAAABcXBTWI/threads/poYdhHcZ030": [
        "Which FS institutions are using Search (other than Morgan Stanley)?",
        "and for which use cases?"
    ],
    "spaces/AAAABcXBTWI/threads/uSLd--Gp6Vk": [
        "Different answers based on whether or not question mark (?) is present\n\nTeam, please see the screenshot below. The app is working well except for this specific scenario: the exact same question is asked, but the correct answer is only given when we exclude '?'. \n\nEven stranger is that the incorrect answer (the 2nd answer) is incorrectly referenced - the content shown is not located in that document at all, it's in a second document. \n\nCan anyone spare some time to troubleshoot?",
        "I saw the same issue in one of our bots, assumed it was a fluke and just removed the question mark using JavaScript in the XO10 bot but good to know someone else encountered this"
    ],
    "spaces/AAAABcXBTWI/threads/GoaMaRl3Xbo": [
        "I have a customer that has provided JSON versions of their documents. Is it possible to upload and ingest this format into Search? If not, is there a tool for conversion you'd suggest? Thx",
        "https://docs.kore.ai/searchassist/manage-content-sources/managing-structured-data/",
        "In XO11 this is facilitated through the JSON connector",
        "Good callout Matt ^^^ .  In Search Assist (XO 10) there was a menu for Structured data and in XO 11 SearchAI, it is using a Jason Connector (bottom of list above).  I need to remember this...",
        "We're doing this in XO10",
        "See their sample JSON file in the next step."
    ],
    "spaces/AAAABcXBTWI/threads/UI0DCBWPiZI": [
        "Heres a sample doc in JSON format."
    ],
    "spaces/AAAABcXBTWI/threads/DkxuBVuGqcU": [
        "Although I chose OpenAI's GPT-4o for the generative model, I am seeing version gpt-3.5.",
        "@Vamsi Lankisetty Could you please look into this defect, it's reproducible for me as well",
        "Checking Aditi",
        "Thanks",
        "Aditi.. i tried from my side. I am getting correct model. If possible could you please share the app to me",
        "@Vamsi Lankisetty @Aditi Bhadouria Any feedback on this issue? Thanks",
        "Hi @Andy Pham - We have tried with Old Apps & new Apps, we are getting the latest model. If possible could you please share the app with us."
    ],
    "spaces/AAAABcXBTWI/threads/Pvg6kzP4pv8": [
        "After SearchAssist release last night the banner which the team added looks like this on JP env.\nPlease fix!",
        "Sure @Sandeep Singh Rana . Will fix and changes will reflect in next release."
    ],
    "spaces/AAAABcXBTWI/threads/HUTN7b8g_vo": [
        "Inside the app the banner to enable BGE Model looks like this"
    ],
    "spaces/AAAABcXBTWI/threads/dzvwO_DB_G4": [
        "Hi all... have customer on XO10. For \"Answers from Documents\" (LLM) feature, it now states \"This feature is now in legacy status and will not receive further updates or support. For enhanced functionality, please use Answer Generation\". I presume this requires XO11?",
        "@Richard Oldham Yes.",
        "or use SearchAssist",
        "Pretty sure we don't have SearchAssist in AU but I'm checking",
        "Answers from Documents was more of a demo type of thing. it was never meant to be used as a primary method of configuring search in a production implementation. at least that is my understanding. in XO 10 using SearchAssist is the preferred method"
    ],
    "spaces/AAAABcXBTWI/threads/adNMK-Ehm_U": [
        "Team, during 'Test Answers,' we receive the document URL, but when we test the same on the chatbot, it doesn't appear. Do we know why this happens? \n\nIn SearchAssist (v10), we provide the doc URL. Providing the URL is very helpful for users making queries.",
        "hi  @Aditi Bhadouria , is this a bug or or I am missing some settings? can someone from the team respond?",
        "The URL should be visible in test bot also. This could be because LLM has not responded in the correct format or there is some issue on our end",
        "Aditi, I can see the JSON and it is getting all the info like URL etc but not displaying. I will raise this on v11 feedback channel and get it checked by the engineer. Thanks"
    ],
    "spaces/AAAABcXBTWI/threads/J12b21avQZg": [
        "Hi Team, do you know how to fight this error? I cant add other kore members to my SearchAssist app:",
        "@Anton Bolkhovitin the image is not clear can you share what the error is?",
        "whenever I try to add a member to any app in my SearchAssist prod , it gives me an error message that says \"invalid UserID or email address\"",
        "I just checked if there is an issue, I wasn't able to reproduce it. \n\nCould you please cross-check to make sure there isn't any space in the beginning/end, that might cause this error. If that doesn't work please raise a support ticket so team can investigate"
    ],
    "spaces/AAAABcXBTWI/threads/bIZU4nfkfT0": [
        "Hi team,\nI'm trying to login to the Search AI environment, but I'm receiving this error below.  Can someone please assist?",
        "Hi @Brady Knerr are you still unable to log in? We haven't noticed any issues on our end and are able to log in successfully.",
        "@Bharat Rekha Hi Bharat, Yes I was able to login.  Thank you for following up."
    ],
    "spaces/AAAABcXBTWI/threads/0vEvVnKRhkY": [
        "Can videos be used as sources? The title of the video will be used in the question/answer. For example, if a user asks, \"How do I schedule training?\" The video for this would be provided. Thanks",
        "Hi @Kevin Mullay,\n\nCurrently, video as a source is not supported. However, you can upload the transcription of the video as structured data and attach the video URL as a link. You can split the entire transcription into multiple chunks and link the video URL to each chunk.",
        "The other option would be to catalog the videos with some metadata in a PDF or similar and index that."
    ],
    "spaces/AAAABcXBTWI/threads/MfIOBA3hAmo": [
        "Team, I have created thousands of structured data entries using JSON for Arabic content in SearchAssist. However, during testing in the search preview, only one response is displayed initially. When clicking the \"Show More\" link, it reveals 15 additional responses (Fatwa 15-see screenshot highlighted in yellow). How can I display all 15 responses upfront along with the search score for each?",
        "Hi @Zaher Awada \n\nCan you share a screenshot of the Result Templates page?",
        "Hi @aditi here is the screenshot",
        "Please add the result template as data and set up the template. That should help.",
        "Thank you @Aditi Bhadouria  it is working now. Is there a way to display search score for each response? Also it is currently highlighting keywords in Bold , is it possible to highlight them in yellow?",
        "This isn't currently available @Zaher Awada. Feel free to raise a feature request if you feel this feature is important",
        "@Aditi Bhadouria are you referring to displaying the search score or highlighting in yellow or both?",
        "Both",
        "Although for the score you could use the advanced search API and present it to the end-user, as it will be part of the API response.",
        "@Aditi Bhadouria Is there any documentation that explains how the matching score is calculated and the logic behind it?",
        "This is based on retrieval strategy. You can find it here https://docs.kore.ai/searchassist/concepts/personalizing-results/about-answers/",
        "Thanks, @Aditi Bhadouria for sharing the document. The customer is requesting that the platform provide an explanation for the ranking score of each response to help them understand the logic behind the ranking and assess the relevance and accuracy of the responses. Additionally, I have a question: I'm using the search web SDK, is there a way to trigger an action (such as sending an email or creating a ticket) when no response is found?",
        "It might not be possible using just Search AI, but you can explore how to use Automation AI and achieve this",
        "@Aditi Bhadouria I can achieve this by linking the bot in XO to the SearchAssist app and handling it in the fallback task (triggering an email if no response is provided). However, the user would need to interact with the virtual assistant interface instead of the search interface(see attached screen shot). Is there a way to connect XO directly to the search interface? If not, can I include there a link to an external portal or a tip message for the user to follow in case no response is given? Apologies for all the questions‚ÄîI'm working on a PoC for a big customer on SearchAssist in Arabic that includes some complex requirements and features.",
        "@Aditi Bhadouria  a kind reminder on the above. Thank you",
        "Hi @Zaher Awada \n\nSorry for the late reply. Yes, there are two ways to integrate an XO bot with Search AI. 1st as you have described and you can find details of the 2nd option here https://docs.kore.ai/searchassist/manage-content-sources/linking-your-virtual-assistant/",
        "@Aditi Bhadouria Thank you that‚Äôs really helpful. I followed the instructions in the document to link XO to SearchApp, but I got stuck because I don‚Äôt have credit on the staging instance Kore.ai Bot Builder. Do you know who I should contact to upgrade my account to enterprise?",
        "You can just use the Kore Com workspace as it is enterprise",
        "@Aditi Bhadouria the searchapp is configured in Searchassist-pilot.kore.ai for the POC, when i click link bot in actions it redirects me to staging-bots.korebots.com instance and not https://bots.kore.ai",
        "Not sure how the credits work for XO 10 Automation AI. Sorry I assumed you were talking about XO 11. @Anil Kumar Reddy Mosali do you have any idea about this",
        "@Anil Kumar Reddy Mosali can you please assist with upgrading my workspace in the staging-bots.korebots.com environment? I am unable to publish the bot, and this is very urgent as we have a POC demo scheduled for Monday. Your support is greatly appreciated!",
        "I believe this is taken care now.",
        "i managed to link the bot to searchassist app , Thank you @Aditi Bhadouria  & @Santhosh Kumar Myadam",
        "@Aditi Bhadouria i created a dialog task in XO and it is now shown in searchassit in Action tab when the respective utterance is submitted by the user in the search widget, which is working as expected. Is there a way to trigger an action when there is no response in search, the requirement is when there is no search results returned then this should be routed to fallback task in XO. I have tested it, it is not triggering the fallback task when there is no response, it only triggers the respective dialog task in linked bot when there is a submitted utterance in search bar"
    ],
    "spaces/AAAABcXBTWI/threads/UpRlmKIFuSM": [
        "When is the BGE embedding model going to be released for DE environment, and MPNet and LaBSE models going to be deprecated?"
    ],
    "spaces/AAAABcXBTWI/threads/JfyZeLN_1Wc": [
        "Seeing a difference in the answer on the same query sent to US prod and DE prod environment. In US prod, it is showing the answer as well as search result while on DE its only showing the search result. All the settings are exactly the same. Tried to change the similarity score, prompt, etc.; the chunks are getting identified and sent to LLM, but not used for answers. Any ideas why this could be happening? This is causing issue in a customer go live, so any help is appreciated.",
        "@Amit Baweja This shouldn't happen ideally. I am assuming both apps have the exact same configuration. \n\nTo verify this could you share the index config for the apps in US and DE? Sharing screenshot for where to find the option to export it.",
        "Here you go",
        "Can you share the apps with me, the configurations look the same but I am noticing differences in the overall structure",
        "Added to the client app on DE, please let me know if any changes need to be made.",
        "@Andrei Zaharia can you add Aditi to the US app?",
        "@Aditi Bhadouria Please check, you should have access for both. Do let me know how to proceed.",
        "Any luck @Aditi Bhadouria",
        "I am not able to log in to DE environment. I would suggest creating a support ticket, if it‚Äôs urgent I can get on a call to check the apps configs just in case there is an issue there",
        "@Amit Baweja I was able to login just now and check the app. There is an issue with the Azure Open AI credentials, I checked with an Open AI key and I was able to get a response. \n\nBelow are the steps I performed to reach this conclusion.",
        "1. Checked if the content containing the answer was present in both apps. \n\n2. I checked if both apps were qualifying the same chunks for the same query\n\n3. I checked the prompt and response from LLM. I noticed in DE that the response tab was empty. Even if the content qualified is wrong LLM usually responds with \"I don't know\" which can be seen in the response tab. \n\n4. I checked with a Open AI model and was able to get a response",
        "The credentials are wrong you mean? How is the connection validated then?",
        "Is there any log to better¬†understand if and why there is no answer from LLM, or any error answer?",
        "The key looks fine, do you have another Azure Open AI GPT 4 key to do an apple to apple comparison? @Aditi Bhadouria",
        "@Aditi Bhadouria I tried with importing this index, still it doesn't work. Simulate also is not.",
        "Team will have to debug this further to comment",
        "We don't maintain logs for test queries. There are logs for the queries received through SDK or public API",
        "The problem is not with the configuration, so importing this won't work(Credentials are not part of import/export). You need to update the Axure credentials, can you try using the credentials Andrei has in the US app, since it is already working",
        "When I import & try it says: Sorry, we could not find any results. Doesn't even give search results.",
        "I'm trying to use that key, but I get the error: The API deployment for this resource does not exist. If you created the deployment within the last 5 minutes, please wait a moment and try again.",
        "@Aditi Bhadouria we checked with our key and looks like your assessment was right. Have told customer to fix theirs. Thanks.",
        "@Vaishali Addala - Can you please check this and create tracking bug to fix the experience issue for debugging?"
    ],
    "spaces/AAAABcXBTWI/threads/vqlsXl1_Dmc": [
        "Left side is US prod POC; right side is DE Prod."
    ],
    "spaces/AAAABcXBTWI/threads/Gee0JcLHJAY": [
        "Also, \"Simulate\" doesn't return any results on both environments"
    ],
    "spaces/AAAABcXBTWI/threads/GB3WUgqorao": [
        "SearchAI - XO11 - LaBSE embeddings training time \n\nRoughly how long should LaBSE take to vectorise a 3-page document?  'Training in progress' has been going for 20 minutes now... Is this a bug (visual/backend)?",
        "Hi @Laurence Schoultz \n\nAre you using layout aware model by any chance?",
        "@Aditi Bhadouria no, text extraction.",
        "This is most likely a defect",
        "To unblock you I would suggest you stop the current training process and re-start it. That should help"
    ],
    "spaces/AAAABcXBTWI/threads/8zrqCqHCgE8": [
        "Is there a limit to how many documents can be uploaded within SearchAssist?",
        "For enterprise accounts, we have a soft limit of 2000 documents per source, but this can be increased based on the customer's requirements"
    ],
    "spaces/AAAABcXBTWI/threads/q2qC4N8FejY": [
        "Are AWS S3 buckets as standard source connector coming on the roadmap? the office of the CTO at Dell is asking",
        "@John Brandes Yes, we plan to add S3 as a connector to Search AI. Initially we are only looking to ingest document formats stored in S3. Please let me know if there is a different requirement from the client/prospect.",
        "Thanks @Aditi Bhadouria -- any sense of timing, on when this might be on the roadmap for?",
        "We are currently targeting GA release by December. Will keep you posted if there is any update to the ETA"
    ],
    "spaces/AAAABcXBTWI/threads/Arzw4DkpFlc": [
        "Is there a reason I am getting the URL expired link error while others are not? We are all using the same Search AI app. Thanks"
    ],
    "spaces/AAAABcXBTWI/threads/YtJ3sdqXsAE": [
        "Hi @Kevin Mullay - We are having \"One Time URL\" feature in SearchAssist. For the first time, user able to access the URL link and from the second time onwards, when user clicks on the URL you will see the \"Expired link\" message.",
        "Is there a way to turn it off for testing?"
    ],
    "spaces/AAAABcXBTWI/threads/1VovQ-z4NWg": [
        "Yes.."
    ],
    "spaces/AAAABcXBTWI/threads/n8NZDrnmbho": [
        "Go to SearchSettings -> Custom Configurations -> and select Key as \"Single User URL\" and value as \"False\""
    ],
    "spaces/AAAABcXBTWI/threads/pZtU-O3vGO0": [
        "It will turn off the one time URL feature and you wont see any URL expiry",
        "Thank you!"
    ],
    "spaces/AAAABcXBTWI/threads/cOWnVrfneCw": [
        "Hi all‚Ä¶I need some guidance as to how to provision a SearchAssist environment for customer. I see that it‚Äôs different to bots in that you don‚Äôt invite customer users to a workspace but rather an individual app‚Ä¶ is that correct? If someone has the procedure for onboarding customer, would be appreciated",
        "@Richard Oldham Please post it in the XO CCAI group",
        "Ah man‚Ä¶ sorry @Santhosh Kumar Myadam I meant to say SearchAssist!!. Have edited",
        "SearchAssist and XO Platform share the common user management. \n\nIf the question is about setting a new workspace for a customer, then they can directly signup\nIf it is about inviting a new user to an existing workspace, then there are 2 ways - (a) Go to Admin Console and invite the user to the workspace. User will be part of the workspace but will not get access to any existing apps unless explciitly added to them (b) Go to a specific 'app' in SearchAssist and invite the user. Use will get access to workspace and that specific app",
        "Thanks @Santhosh Kumar Myadam. For (a) how do I navigate to the Admin Console? I‚Äôve logged in and presumed it was the same as bots and could be accessed via login/profile dropdown but no such option",
        "https://bots.kore.ai/Admin\n\nPlease use this URL to go to the Admin Console\n\nUser Management - Users - Invite User"
    ],
    "spaces/AAAABcXBTWI/threads/uJwuFqVuUd8": [
        "Team, I‚Äôm trying to use SearchAI in XO11 but encountering the error shown in the screenshot. Does anyone know who I should contact to update my subscription?"
    ],
    "spaces/AAAABcXBTWI/threads/THMiNa2yh10": [
        "Do we support custom query pipelines in SearchAssist?",
        "@Aditi Bhadouria @Bharat Rekha",
        "@Amit Baweja We do support query pipelines in standalone SearchAssist. What is the use case?",
        "When the user utterance is small, say \"cos'√® la scatola nera?\" translating to \"What is a black box?\", the VA responds with answer as well as search results. But when the same question is asked embedded in a large utterance, something like \" I was driving this morning and realised that my insurance costs have increased. I wonder what is a black box and if it can help.\" In this case, bot doesn't respond. \n\nSo what I was thinking if their is a way to use an LLM to summarize a query which essentially has the same intent, and use it for searching - yielding better results with less tuning efforts.\n\nHow can we enable this?",
        "If SearchAssit is used alongside the bot, then I am assuming SearchAssist called from a fallback flow. In that case, you use use the GenAI Prompt node in the fallback dialog get the revised query, and then make SearchAssist call.",
        "Its not fallback but primary task. Actually we are calling SearchAssist from AgentAI; from uploaded pdf's as the knowledge source.",
        "If the call is directly coming from prebuilt AgentAI to SearchAssist integration, then the above solution won‚Äôt work.",
        "I am trying to get more details about this, this might help\n\nhttps://docs.kore.ai/searchassist/configuration/custom-configurations/#Rewrite_Query\n\n @Nimisha Joseph",
        "Ok",
        "Let me know",
        "cc @Andrei Zaharia"
    ],
    "spaces/AAAABcXBTWI/threads/ecygZm8-oDQ": [
        "Do we have SearchAssist in EU Cloud?",
        "@Amit Baweja \n\nNo, we do not have standalone SearchAssist in EU. \n\nI suggest using XO11."
    ],
    "spaces/AAAABcXBTWI/threads/xNZjFuXsbHw": [
        "Team, example we are using ServiceNow or Sharepoint connector and have scheduled daily crawling. Do we require to start training manually of the SearchAssist App or the training is not required?",
        "Hi @Sandeep Singh Rana, Training is not required once the sync is completed the auto train will take care of this.",
        "@Bharat Rekha , thank you for your prompt response and clarification."
    ],
    "spaces/AAAABcXBTWI/threads/PhhOAUXwleA": [
        "Hi all... with SearchAI is there a mechanism for an end-user who is asking questions of the platform, to \"correct\" and/or \"update\" content during a conversation? I presume this can only be done via updating the knowledge articles that we're ingesting/connecting to.",
        "@Richard Oldham that's not a good idea - they could provide feedback -> which then goes to the admins who can review and moderate content.",
        "Thanks @Aayush Mediratta, yep.. great point - will raise this in the workshop. For providing feedback for admin review, I presume this will be outside Kore."
    ],
    "spaces/AAAABcXBTWI/threads/ObyZrEN9v78": [
        "Hi all‚Ä¶ am looking to assist our team in region. Does anyone have a project plan to deliver a pure SearchAI solution using only Generative Answers - trying to understand how we scope effort and hence PS price."
    ],
    "spaces/AAAABcXBTWI/threads/RDwN0NhOzok": [
        "Hi @Richard Oldham https://docs.google.com/spreadsheets/d/1UMwVOTzKzbzyGNbUv2BBnnas-zo9OikG/edit?usp=sharing&ouid=103158249691866739589&rtpof=true&sd=true is the sizing template for Search Assist Implementations. Please use the same to derive the Search Assist Implementation efforts.",
        "Thank you @Sathya Priya Turaga very much appreciated!"
    ],
    "spaces/AAAABcXBTWI/threads/zafvRBEXKbk": [
        "Hi. On XO11, when is the feature for data/document ingestion API going to be available? And is there a JIRA story to track this?"
    ],
    "spaces/AAAABcXBTWI/threads/CFnAO8SFcTw": [
        "Hi Team. I am working on a POC for Unifi (you may already be aware). They are comparing us against Yellow.ai. While our responses may be correct, they don‚Äôt provide the level of detail Unifi expects. Unifi gave us ~180 questions to test. I am halfway through the test, and the common theme is our responses are too short. Can I ask for your help with how we can be more expansive? In the sheet below, I flagged the issue (too short) for each question and also created a tab that compares our response to Yellow.ai. Getting our answers in a better state is critical to this POC. Thank you! cc: @Aayush Mediratta \n\nhttps://docs.google.com/spreadsheets/d/1B0cW2l1kel12Kl4I2IoTA_6gtgy8CjvR/edit?usp=sharing&ouid=102550579375122445198&rtpof=true&sd=true",
        "@Kevin Mullay please share the yellow bot link here too",
        "https://cloud.yellow.ai/liveBot/x1691127962148?region=r4",
        "This link will allow you to ask the questions in the sheet to the POC Yellow has delviered",
        "Hi @Kevin Mullay Finetuning the Prompt can solve this problem. Please share me the app so that I can have a look at it.",
        "You have been added. Thanks",
        "@Kevin Mullay Issue resolved. We are receiving descriptive answers now. please check this sheet, I have added couple of questions aswell. https://docs.google.com/spreadsheets/d/1pR5JUFgwl1wV7DJIipAqLnNlQiUAzCUG7Gumi5sk938/edit?usp=sharing",
        "can you share what you changed so the demo team can add this to our tuning options?",
        "New Prompt : [\n  {\n    \"role\": \"system\",\n    \"content\": \"You are an AI system designed to provide comprehensive, detailed answers based on user-provided context. Your responses should be thorough, well-structured, and include step-by-step explanations when appropriate. Follow these guidelines:\\n\\n1. ANSWER FORMAT:\\n- Break down complex information into clear, numbered steps or logical sections\\n- Include all relevant details from the context\\n- Use proper formatting (bullet points, numbering, paragraphs) for clarity\\n- Maintain a professional, instructional tone\\n- When applicable, describe the complete process from start to finish\\n\\n2. REFERENCE FORMAT:\\n- After each relevant piece of information, include the source reference as [chunk_id]\\n- Place chunk_ids only at the end of the relevant content\\n- Use only chunk_ids that are explicitly provided in the context\\n- Format: 'Detailed information here[chunk_id] Additional information here[chunk_id]'\\n\\n3. RESPONSE STRUCTURE:\\n- Begin with a brief overview or introduction when appropriate\\n- Present information in a logical sequence\\n- Include all necessary context and prerequisites\\n- Explain any important considerations or requirements\\n- Conclude with any relevant follow-up steps or confirmations\\n\\n4. IMPORTANT RULES:\\n- Never fabricate chunk_ids\\n- Only use information directly from the provided context\\n- If information is not available, respond with 'I don't know'\\n- Exclude irrelevant information or notes\\n- Respond in the same language as the user's query and context\\n- Always provide the most complete answer possible from the available context\\n\\n{{chunks}}\"\n  },\n  {\n    \"role\": \"user\",\n    \"content\": \"From the content that I have provided, solve the query: '{{query}}'\"\n  }\n]",
        "Just the Prompt change.",
        "thank you",
        "Thank you @Sathya Priya Turaga. I will review things later today.",
        "Also, I observed certain data is missing in the Kore app which is restricting us to limit our responses. Pls revisit the data ingested. Match it with yellow ai.",
        "Thank you. I will.",
        "Thanks for sharing"
    ],
    "spaces/AAAABcXBTWI/threads/CN4EKJrPHT0": [
        "Hi Everyone, \n\n have a quick technical question about Search AI, and I hope someone can help.\n\nI‚Äôm looking to enable Search (v11) to ask follow-up questions based on the answers it provides. In the previous \"Search Assist,\" we had a custom configuration called \"dev_Enable_Query_Rewrite_Type\" that allowed for this kind of interaction.\nNow, I‚Äôm curious if there‚Äôs a similar option available in XO11 Search AI to achieve the same functionality. Specifically, once Search provides an answer, I want to be able to prompt it to ask a follow-up question related to that answer and fully maintain the context.\n\nIf anyone has experience with this or knows where I might find the equivalent configuration in XO11 Search AI, would really appreciate your guidance!",
        "@Girish Ahankari @Santhosh Kumar Myadam - can you please help with this request?  This is for Frontier and pretty urgent.  Thanks!"
    ],
    "spaces/AAAABcXBTWI/threads/Y7SZyNvfqjA": [
        "@Raman Srinivasan i know this is possible based on discussions with @Girish Ahankari . while awaiting for an answer from him, please also consult @Shantanu Ghorai and lets document it. this is an often asked question. from what i recall we have an ability to use the conversation context and history to do query rephrasing using xo gpt and that should help give a more detailed input utterance that can lead to better search results but of course i dont claim to know how it is done. lets find out from the experts.",
        "@Curtis Swartzentruber is this what we need for Unifi?",
        "@Melissa Prince has an opportunity at Frontier to replace YEXT and this gap in product capability was identified during PoC. Sharing for context awareness as Frontier is a critical account for us."
    ],
    "spaces/AAAABcXBTWI/threads/qUCe9kVkoqo": [
        "As of today, Kore XO GPT (V11) enables query rephrasing via the BOT for search interactions. However, unlike XO10, it lacks direct context retention support within SearchAI in v11.",
        "@Santhosh Kumar Myadam @Girish Ahankari Why is that?"
    ],
    "spaces/AAAABcXBTWI/threads/oSU7vqRUl-0": [
        "@Prasanna Arikala In XO11, we expect the Platform to send the rewritten query to SearchAI",
        "Ok, so it is possible to have followup ??"
    ],
    "spaces/AAAABcXBTWI/threads/BgtnW07n2UI": [
        "as discussed earlier, today, platform is not considering the answer from SearchAI for rephrasing",
        "Sorry I did not understand. If that is that expectation, why is platform not considering it? Is it a bug in the platform or search ai or we have missed it completely to validate the proper integration?",
        "It needs json parsing",
        "Which was not done earlier",
        "Same is the problem with list of values entities case",
        "Sorry, I still did not understand. Can you please explain which component has the problem, who is working on it and when are they planning to resolve this?",
        "1. First request goes to search Ai\n2. SearchAI responds in JSON format\n3. XO uses the json to present the output.\n4. Follow-up query sent by user\n5. XO needs to take the chat history including the response given by search ai, rephrase and send it to Search [This is missing]",
        "Vamsi and team will be working on this in the first week of November",
        "Planning to release in mid November patch",
        "Why was it missed in the first place? Was this not part of the design for this integration?",
        "It was intentionally kept aside in the earlier design as a known issue. This involves case like List of values, JSON based message nodes etc as there was no immediate solution.\n\nNow we have decided to go with \"Alt\" field based approach where we expect the payload to contain an \"Alt\" field where the String present as value will be considered for rephrasing",
        "Wanted to expand on this to highlight some details. \n\nCurrent Query Rephrasing Capabilities in XO 11\nSearch AI can rephrase queries based on previous user questions only\nThis is equivalent to SearchAssist/XO 10 setting: Rewrite query = query \n\nUpcoming Enhancement (November)\n\nSearch AI will be able to rephrase queries based on both: previous user questions and answers received\nThis will be equivalent to SearchAssist/XO 10 setting: Rewrite query = conversation\n\nTechnical Background\n\nThe current limitation exists because Search AI responses are in JSON format\nIncluding complete JSON in conversation history can interfere with query rephrasing accuracy as:\nManaging context will be an issue\nCan cause hallucination due to presence of unnecessary data\n\n\nSolution\n\nWe will extract the answer from the JSON response\nOnly the extracted answer will be added to conversation history\nThis allows XO GPT to properly rephrase queries using the relevant context\n\n @Raman Srinivasan",
        "Hi @Aditi Bhadouria \nI tried your recommendation on enabling \"Rephrase User Query\" in XO11 and gave it a try. It did not work as expected. Need your help to check this out. \n\nI have documented my observation for your reference\nhttps://docs.google.com/document/d/17S4yEWflYW7amKxh1XNApxBv5T7u2AaJU3uW5nmhBHU/edit?usp=sharing",
        "@Aditi Bhadouria can you please check on this issue document and let me know?"
    ],
    "spaces/AAAABcXBTWI/threads/T4oPksHTkX0": [
        "this is being addressed by the platform nodejs team"
    ],
    "spaces/AAAABcXBTWI/threads/ZQ02GIKxhYE": [
        "sounds like it would work",
        "@Curtis Swartzentruber @Kevin Mullay So if we use XO10+SearchAssist - this can be implemented today?",
        "how do you determine the question is a follow-up vs a net new question?",
        "GenAI prompt (not node) out to an LLM to classify? I've done something similar for a demo to determine if the user is asking about a curated intent (Dialog Task) or a net new question which should be redirected to SearchAI."
    ],
    "spaces/AAAABcXBTWI/threads/b8fnsgpWryQ": [
        "We can do this using SearchAI standalone even today. From XO11, we will target to have this ready by 15th November"
    ],
    "spaces/AAAABcXBTWI/threads/r7-LpZSrmTI": [
        "as part of a Security questionnaire from our prospect Southwire.com via partner Pronix... they would like to know how long Kore intends to support version 10.x of the Search Assist solution.  Do we have a roadmap for when it may no longer be supported?  How should I respond to this?",
        "@Tim Burke \n\nWe are actively addressing the parity between standalone version and XO11 version of Search AI\nWe will close this by end of Nov\nWe will announce deprecation in Jan 2025. It will enter maintenance mode. No new features will be added. We will only provide defect fixes for another 2 quarters. \nWe will work with the customers to migrate to XO11 during this time\nPost that, we will announce discontinuation. \n\n @Girish Ahankari  @Bharat Rekha  @Aditi Bhadouria",
        "Thank you Santosh!  Very helpful."
    ],
    "spaces/AAAABcXBTWI/threads/L39Yaxkvc30": [
        "what is the maximum file size limit for JSON files in SearchAI?  I've found sources that say 15MB in regards to inherent connectors, but want to confirm that 15MB is the limit for JSON files also.",
        "@Aditi Bhadouria",
        "@David Martin yes the limit for uploading JSON files will be 15 MB. This can be increased if required",
        "How many more MB can we increase? @Aditi Bhadouria",
        "@Aditi Bhadouria our customer (carefirst) says that their max file size today is 60MB.  is that feasible if required?  this customer deployment is in our cloud.  this is a searchai deployment integrated with agentai."
    ],
    "spaces/AAAABcXBTWI/threads/Jr9s8CSm87w": [
        "Am getting errors when loading an app in SearchAssist as shown in following video (note, have removed the first 50 seconds when it's just the loading process - banner cycling at top). Anyone know what's going on? https://www.loom.com/share/72e1f61b545348f786e9ea5e719eea08?sid=b5b8d9a7-e3b9-4a57-a723-7fdad57b1aae",
        "@Vaishali Addala",
        "@Vaishali Addala - I have experienced this on a number of apps on searchassist.kore.ai",
        "I will quickly check and get back to you @Richard Oldham",
        "Hi @Vaishali Addala - any update?",
        "Developers are analysing that issue @Richard Oldham. Apart from that API remaining functionality is working as expected. Will let you know once the issue is resolved."
    ],
    "spaces/AAAABcXBTWI/threads/1Yj3LrArBQ0": [
        "Hi team,\nI‚Äôve found that our Enterprise account has soft limits, which are set internally but can be adjusted according to user requirements. \nWeb Crawl: 100k records\nFile Upload: 50k records\nFAQs: 50k records\nStructured Data: 50k records\nConnectors: 300k records\nCould you let me know the theoretical maximum for updating FAQs or Crawl records, if requested by customer ?",
        "@Aditi Bhadouria @Santhosh Kumar Myadam  can someone respond to this?",
        "Posting the response here as well for everyone's reference. \n\n1. Is there a hard limit on the number of FAQs we can upload?\nYes we have certain soft limits in place to avoid misuse of resources. For cloud environments it's very crucial to ensure few users are not overloading the resources as it can impact the performance for other users.¬†\n\n2. Is it possible to upload additional FAQs beyond the soft limit?\nYes, it is possible to increase the soft limit. We can increase it for a specific app based on the app ID.¬†¬†\n\n3. Can we increase the SearchAssist capacity for the Japan region?\nIncreasing this limit for JP environment may not be feasible. Please send a mail requesting for this for a specific app. Please mention the stream id/app id in the mail as the limit will be increased based on this. Additionally please ensure the correct approvals are in place. This is important so we can ensure the client is using the SearchAssist product according to the license agreement.¬†\n\n4. Could you let me know the theoretical maximum for updating FAQs or Crawl records if requested by the customer?\nThere isn't a specific limit for how much content can be ingested. We can support large quantities of data, but the performance would vary based on the client's budget and hardware provisions. As the content size increases we would recommend the customer to go for a on-prem or VPC setup that can be set up according to their requirements."
    ],
    "spaces/AAAABcXBTWI/threads/gnuf0FMarFQ": [
        "Team, I am working on a Searchapp , i have uploaded Arabic pdf docs in SearchAssist, and the training index completed successfully (chunks were created), allowing me to generate answers using the generative model with a multilingual prompt. However, today, I uploaded a new Arabic document in the same format, but the training is failing. Any help?",
        "Do you tried on production? Sometimens, in pilot, the team made some changes",
        "@Zaher Awada can you share the error details for this? It's shown on hover",
        "Hi @Aditi Bhadouria it says failed to train traits",
        "Team is working on resolving this. I will get back to you with a update soon.",
        "But this is not due to a specific document"
    ],
    "spaces/AAAABcXBTWI/threads/MEYNSQ1Hios": [
        "Hi @Martin Anibal Bonardi ,  i haven't tried it yet on prod. I am not sure if this is an environment issue, i recall i faced the same issue with arabic docs earlier and i had to redo the configs without being able to recognize what was the main reason causing the training to fail."
    ],
    "spaces/AAAABcXBTWI/threads/dwThFpRahiI": [
        "we should not be using pilot for demos"
    ],
    "spaces/AAAABcXBTWI/threads/xnLpfpCXS34": [
        "Hi SearchAI team.. does anyone know whether we have a customer case study based on a SearchAssist solution?",
        "These are in the case study gold deck in seismic",
        "Thanks @Basil Polsonetti"
    ],
    "spaces/AAAABcXBTWI/threads/gG4sW12vWPI": [
        "Were we working on a generic connector for knowledge base for SearchAI and if so, what is timeline?  Have a prospect using Dynamics for knowledge base and saw we did not have an out of the box connector to Dynamics 365 today",
        "@Aditi Bhadouria Plesse confirm when are we going to make the custom connector live."
    ],
    "spaces/AAAABcXBTWI/threads/Kg-XvBK9pF8": [
        "https://koreteam.atlassian.net/browse/FLY-12394"
    ],
    "spaces/AAAABcXBTWI/threads/bQE5RUdwh0A": [
        "@Amy Jeschke This will be deployed in the upcoming release over the weekend"
    ],
    "spaces/AAAABcXBTWI/threads/-KdAu9Km9Fg": [
        "would that be something to we could use for Dynamics?"
    ],
    "spaces/AAAABcXBTWI/threads/IgW2hQEyB5M": [
        "I‚Äôd think so. @Aditi Bhadouria can you confirm?",
        "@Amit Baweja \n\nCustom Connector provides a set of APIs as that can be used with any source to push the data to Search AI. \n\nDo note that orchestrating these APIs with source systems might require some custom development.",
        "@Aditi Bhadouria",
        "Custom connector will be available for XO 11 on Monday (4 Nov).",
        "It is available for XO 10/Search AI standalone, you can check it out",
        "In DE SearchAssist as well, right?",
        "Yes"
    ],
    "spaces/AAAABcXBTWI/threads/tZR5zSICqxI": [
        "Have a question on chunks... working with customer who are pulling in knowledge articles via Zendesk connector. Answer Snippets / Generative all enabled and search results (via Preview) are getting relevant answers. However... we see NO chunks and it still says \"Enable Answer Snippets to view the Chunks\". Should we be seeing chunks when using Zendesk Connector?",
        "Anyone know the answer to this?",
        "Hi @Richard Oldham \n\nIt shouldn't be possible to get answers without chunks. Chunks are created after you enable Answer Snippets and train the application.",
        "For more details you can refer https://docs.kore.ai/searchassist/concepts/personalizing-results/about-answers/",
        "https://docs.kore.ai/searchassist/concepts/personalizing-results/answer-snippets-support-across-content-sources/",
        "That may be true.. but we are getting answers",
        "Presume chunks are created and usual processing is happening‚Ä¶ just no chunks visible in the UI",
        "Thanks @Aditi Bhadouria - I‚Äôll submit a support ticket"
    ],
    "spaces/AAAABcXBTWI/threads/ca0xZYXNSwM": [
        "Answer Analytics and Dashboards are not populating data. I got a message \"Analytics API failed\" while the system continues on trying to fetch these insights. Cc @Brady Knerr",
        "@Andy Pham is this the same problem we've been having in the Applied Search instance for a week or two?\n\n @J.D. Maloney",
        "@Bharat Rekha / @Venkata Naresh Divi can somebody look into this?"
    ],
    "spaces/AAAABcXBTWI/threads/G0VxrS9pcsQ": [
        "Maybe! My issue was with Search AI."
    ]
}